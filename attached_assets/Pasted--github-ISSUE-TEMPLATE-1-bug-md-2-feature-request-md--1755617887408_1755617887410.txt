├── .github
    ├── ISSUE_TEMPLATE
    │   ├── 1-bug.md
    │   ├── 2-feature-request.md
    │   └── config.yml
    ├── PULL_REQUEST_TEMPLATE
    │   └── pull_request_template.md
    ├── scripts
    │   ├── add-new-checks.sh
    │   ├── add-size-labels.sh
    │   └── revalidate-all-prs.sh
    └── workflows
    │   ├── auto-update-pr.yaml
    │   ├── check-infrastructure-changes.yml
    │   ├── check-linked-issue.yml
    │   ├── check-pr-size.yml
    │   ├── check-pr-up-to-date.yaml
    │   ├── ci.yaml
    │   ├── publish.yml
    │   ├── revalidate-pr.yml
    │   └── validate_pr_template.yaml
├── .gitignore
├── .pre-commit-config.yaml
├── .pylintrc
├── CITATION.cff
├── CONTRIBUTING.md
├── Dockerfile
├── LICENSE
├── README.md
├── autoformat.sh
├── docs
    ├── _static
    │   ├── logo.svg
    │   ├── medication_entity.gif
    │   ├── medication_entity_re.gif
    │   ├── romeo_juliet_basic.gif
    │   └── romeo_juliet_full.gif
    └── examples
    │   ├── longer_text_example.md
    │   └── medication_examples.md
├── examples
    ├── custom_provider_plugin
    │   ├── README.md
    │   ├── langextract_provider_example
    │   │   ├── __init__.py
    │   │   ├── provider.py
    │   │   └── schema.py
    │   ├── pyproject.toml
    │   └── test_example_provider.py
    ├── notebooks
    │   └── romeo_juliet_extraction.ipynb
    └── ollama
    │   ├── .dockerignore
    │   ├── Dockerfile
    │   ├── README.md
    │   ├── docker-compose.yml
    │   └── quickstart.py
├── langextract
    ├── __init__.py
    ├── _compat
    │   ├── README.md
    │   ├── __init__.py
    │   ├── exceptions.py
    │   ├── inference.py
    │   ├── registry.py
    │   └── schema.py
    ├── annotation.py
    ├── chunking.py
    ├── core
    │   ├── __init__.py
    │   ├── base_model.py
    │   ├── data.py
    │   ├── exceptions.py
    │   ├── schema.py
    │   ├── tokenizer.py
    │   └── types.py
    ├── data.py
    ├── data_lib.py
    ├── debug_utils.py
    ├── exceptions.py
    ├── extraction.py
    ├── factory.py
    ├── inference.py
    ├── io.py
    ├── plugins.py
    ├── progress.py
    ├── prompting.py
    ├── providers
    │   ├── README.md
    │   ├── __init__.py
    │   ├── builtin_registry.py
    │   ├── gemini.py
    │   ├── ollama.py
    │   ├── openai.py
    │   ├── patterns.py
    │   ├── router.py
    │   └── schemas
    │   │   ├── __init__.py
    │   │   └── gemini.py
    ├── py.typed
    ├── registry.py
    ├── resolver.py
    ├── schema.py
    ├── tokenizer.py
    └── visualization.py
├── pyproject.toml
├── scripts
    └── create_provider_plugin.py
├── tests
    ├── .pylintrc
    ├── annotation_test.py
    ├── chunking_test.py
    ├── data_lib_test.py
    ├── extract_precedence_test.py
    ├── extract_schema_integration_test.py
    ├── factory_schema_test.py
    ├── factory_test.py
    ├── inference_test.py
    ├── init_test.py
    ├── progress_test.py
    ├── prompting_test.py
    ├── provider_plugin_test.py
    ├── provider_schema_test.py
    ├── registry_test.py
    ├── resolver_test.py
    ├── schema_test.py
    ├── test_live_api.py
    ├── test_ollama_integration.py
    ├── tokenizer_test.py
    └── visualization_test.py
└── tox.ini


/.github/ISSUE_TEMPLATE/1-bug.md:
--------------------------------------------------------------------------------
 1 | ---
 2 | name: Bug Report
 3 | about: Create a bug report to help us improve
 4 | title: 'Bug: <brief title of your issue>'
 5 | labels: 'bug', 'needs triage'
 6 | assignees: ''
 7 | ---
 8 | 
 9 | ## Describe the overall issue and situation
10 | 
11 | Provide a clear summary of what the issue is about, the area of the project you
12 | found it in, and what you were trying to do.
13 | 
14 | ## Expected behavior
15 | 
16 | Provide a clear and concise description of what you expected to happen
17 | 
18 | ## Actual behavior
19 | 
20 | Provide a clear and concise description of what actually happened.
21 | 
22 | ## Steps to reproduce the issue
23 | 
24 | Provide a sequence of steps we can use to reproduce the issue.
25 | 
26 | 1.  <First step...>
27 | 2.  <Second step...>
28 | 3.  <Third step...>
29 | 
30 | ## Any additional content
31 | 
32 | Describe your environment or any other set up details that might help us
33 | reproduce the issue.
34 | 


--------------------------------------------------------------------------------
/.github/ISSUE_TEMPLATE/2-feature-request.md:
--------------------------------------------------------------------------------
 1 | ---
 2 | name: Feature Request
 3 | about: Suggest an idea or improvement
 4 | title: 'Request: <brief title of your feature request>'
 5 | labels: 'enhancement', 'needs triage'
 6 | assignees: ''
 7 | ---
 8 | 
 9 | ## Describe the overall idea and motivation
10 | 
11 | Provide a clear summary of the idea and what use cases it's addressing.
12 | 
13 | ## Related to an issue?
14 | 
15 | Is this addressing a known / documented issue? If so, which one?
16 | 
17 | ## Possible solutions and alternatives
18 | 
19 | Do you already have an idea of how the solution should work? If so, document
20 | that here.
21 | 
22 | Also, if there are alternatives, please document those as well.
23 | 
24 | ## Priority and timeline considerations
25 | 
26 | Is this time sensitive? Is it a nice to have? Please describe what priority you
27 | feel this should have and why. We'll take this into advisement as we go through
28 | our internal prioritization process.
29 | 
30 | ## Additional context
31 | 
32 | Is there anything else to consider that wasn't covered by the above?
33 | 
34 | Would you like to contribute to the project and work on this request?
35 | 


--------------------------------------------------------------------------------
/.github/ISSUE_TEMPLATE/config.yml:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | # Allow users to create issues that don't follow the templates since they don't cover all use cases
16 | blank_issues_enabled: true
17 | 
18 | # Redirect users to other channels for general support or security issues
19 | contact_links:
20 |   - name: Community Support
21 |     url: https://github.com/google-health/langextract/discussions
22 |     about: Please ask and answer questions here.
23 |   - name: Security Bug Reporting
24 |     url: https://g.co/vulnz
25 |     about: >
26 |       To report a security issue, please use https://g.co/vulnz. The Google Security Team will
27 |       respond within 5 working days of your report on https://g.co/vulnz.
28 | 


--------------------------------------------------------------------------------
/.github/PULL_REQUEST_TEMPLATE/pull_request_template.md:
--------------------------------------------------------------------------------
 1 | # Description
 2 | 
 3 | Replace this with a clear and concise change description
 4 | 
 5 | <!--- Important: All PRs must be linked to at least one issue (except for
 6 |   extremely trivial and straightforward changes). --->
 7 | 
 8 | <!--- This issue (or issues) should document the motivation, context,
 9 |   alternatives considered, risks (such as breaking backwards compatibility), and
10 |   any new dependencies. --->
11 | 
12 | Fixes #[issue number]
13 | 
14 | Choose one: (Bug fix | Feature | Documentation | Testing | Code health | Other)
15 | 
16 | # How Has This Been Tested?
17 | 
18 | Replace this with a description of the tests that you ran to verify your
19 | changes. If executing the existing test suite without customization, simply
20 | paste the command line used.
21 | 
22 | ```
23 | $ python -m unittest discover ...
24 | ```
25 | 
26 | # Checklist:
27 | 
28 | <!--- Put an `x` in the box if you did the task -->
29 | 
30 | <!--- If you forgot a task please follow the instructions below -->
31 | 
32 | -   [ ] I have read and acknowledged Google's Open Source
33 |     [Code of conduct](https://opensource.google/conduct).
34 | -   [ ] I have read the
35 |     [Contributing](https://github.com/google-health/langextract/blob/master/CONTRIBUTING.md)
36 |     page, and I either signed the Google
37 |     [Individual CLA](https://cla.developers.google.com/about/google-individual)
38 |     or am covered by my company's
39 |     [Corporate CLA](https://cla.developers.google.com/about/google-corporate).
40 | -   [ ] I have discussed my proposed solution with code owners in the linked
41 |     issue(s) and we have agreed upon the general approach.
42 | -   [ ] I have made any needed documentation changes, or noted in the linked
43 |     issue(s) that documentation elsewhere needs updating.
44 | -   [ ] I have added tests, or I have ensured existing tests cover the changes
45 | -   [ ] I have followed
46 |     [Google's Python Style Guide](https://google.github.io/styleguide/pyguide.html)
47 |     and ran `pylint` over the affected code.
48 | 


--------------------------------------------------------------------------------
/.github/scripts/add-new-checks.sh:
--------------------------------------------------------------------------------
 1 | #!/bin/bash
 2 | # Copyright 2025 Google LLC.
 3 | #
 4 | # Licensed under the Apache License, Version 2.0 (the "License");
 5 | # you may not use this file except in compliance with the License.
 6 | # You may obtain a copy of the License at
 7 | #
 8 | #     http://www.apache.org/licenses/LICENSE-2.0
 9 | #
10 | # Unless required by applicable law or agreed to in writing, software
11 | # distributed under the License is distributed on an "AS IS" BASIS,
12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13 | # See the License for the specific language governing permissions and
14 | # limitations under the License.
15 | 
16 | # Script to add new required status checks to an existing branch protection rule.
17 | # This preserves all your current settings and just adds the new checks
18 | 
19 | echo "Adding new PR validation checks to existing branch protection..."
20 | 
21 | # Add the new checks to existing ones
22 | echo "Adding new checks: enforce, size, and protect-infrastructure..."
23 | gh api repos/:owner/:repo/branches/main/protection/required_status_checks/contexts \
24 |   --method POST \
25 |   --input - <<< '["enforce", "size", "protect-infrastructure"]'
26 | 
27 | echo ""
28 | echo "✓ New checks added!"
29 | echo ""
30 | echo "Updated required status checks will include:"
31 | echo "- test (3.10)                    [existing]"
32 | echo "- test (3.11)                    [existing]"
33 | echo "- test (3.12)                    [existing]"
34 | echo "- Validate PR Template           [existing]"
35 | echo "- live-api-tests                 [existing]"
36 | echo "- ollama-integration-test        [existing]"
37 | echo "- enforce                        [NEW - linked issue validation]"
38 | echo "- size                           [NEW - PR size limit]"
39 | echo "- protect-infrastructure         [NEW - infrastructure file protection]"
40 | 


--------------------------------------------------------------------------------
/.github/scripts/add-size-labels.sh:
--------------------------------------------------------------------------------
 1 | #!/bin/bash
 2 | # Copyright 2025 Google LLC.
 3 | #
 4 | # Licensed under the Apache License, Version 2.0 (the "License");
 5 | # you may not use this file except in compliance with the License.
 6 | # You may obtain a copy of the License at
 7 | #
 8 | #     http://www.apache.org/licenses/LICENSE-2.0
 9 | #
10 | # Unless required by applicable law or agreed to in writing, software
11 | # distributed under the License is distributed on an "AS IS" BASIS,
12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13 | # See the License for the specific language governing permissions and
14 | # limitations under the License.
15 | 
16 | # Add size labels to PRs based on their change count
17 | 
18 | echo "Adding size labels to PRs..."
19 | 
20 | # Get all open PRs with their additions and deletions
21 | gh pr list --limit 50 --json number,additions,deletions --jq '.[]' | while read -r pr_data; do
22 |     pr_number=$(echo "$pr_data" | jq -r '.number')
23 |     additions=$(echo "$pr_data" | jq -r '.additions')
24 |     deletions=$(echo "$pr_data" | jq -r '.deletions')
25 |     total_changes=$((additions + deletions))
26 | 
27 |     # Determine size label
28 |     if [ $total_changes -lt 50 ]; then
29 |         size_label="size/XS"
30 |     elif [ $total_changes -lt 150 ]; then
31 |         size_label="size/S"
32 |     elif [ $total_changes -lt 600 ]; then
33 |         size_label="size/M"
34 |     elif [ $total_changes -lt 1000 ]; then
35 |         size_label="size/L"
36 |     else
37 |         size_label="size/XL"
38 |     fi
39 | 
40 |     echo "PR #$pr_number: $total_changes lines -> $size_label"
41 | 
42 |     # Remove any existing size labels first
43 |     existing_labels=$(gh pr view $pr_number --json labels --jq '.labels[].name' | grep "^size/" || true)
44 |     if [ ! -z "$existing_labels" ]; then
45 |         echo "  Removing existing label: $existing_labels"
46 |         gh pr edit $pr_number --remove-label "$existing_labels"
47 |     fi
48 | 
49 |     # Add the new size label
50 |     gh pr edit $pr_number --add-label "$size_label"
51 | 
52 |     sleep 1  # Avoid rate limiting
53 | done
54 | 
55 | echo "Done adding size labels!"
56 | 


--------------------------------------------------------------------------------
/.github/scripts/revalidate-all-prs.sh:
--------------------------------------------------------------------------------
 1 | #!/bin/bash
 2 | # Copyright 2025 Google LLC.
 3 | #
 4 | # Licensed under the Apache License, Version 2.0 (the "License");
 5 | # you may not use this file except in compliance with the License.
 6 | # You may obtain a copy of the License at
 7 | #
 8 | #     http://www.apache.org/licenses/LICENSE-2.0
 9 | #
10 | # Unless required by applicable law or agreed to in writing, software
11 | # distributed under the License is distributed on an "AS IS" BASIS,
12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13 | # See the License for the specific language governing permissions and
14 | # limitations under the License.
15 | 
16 | # Revalidate all open PRs
17 | 
18 | echo "Fetching all open PRs..."
19 | PR_NUMBERS=$(gh pr list --limit 50 --json number --jq '.[].number')
20 | TOTAL=$(echo "$PR_NUMBERS" | wc -w | tr -d ' ')
21 | 
22 | echo "Found $TOTAL open PRs"
23 | echo "Starting revalidation..."
24 | echo ""
25 | 
26 | COUNT=0
27 | for pr in $PR_NUMBERS; do
28 |     COUNT=$((COUNT + 1))
29 |     echo "[$COUNT/$TOTAL] Triggering revalidation for PR #$pr..."
30 |     gh workflow run revalidate-pr.yml -f pr_number=$pr
31 | 
32 |     # Small delay to avoid rate limiting
33 |     sleep 2
34 | done
35 | 
36 | echo ""
37 | echo "All workflows triggered!"
38 | echo ""
39 | echo "To monitor progress:"
40 | echo "  gh run list --workflow=revalidate-pr.yml --limit=$TOTAL"
41 | echo ""
42 | echo "To see results, check comments on each PR"
43 | 


--------------------------------------------------------------------------------
/.github/workflows/auto-update-pr.yaml:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | name: Auto Update PR
 16 | 
 17 | on:
 18 |   push:
 19 |     branches: [main]
 20 |   schedule:
 21 |     # Run daily at 2 AM UTC to catch stale PRs
 22 |     - cron: '0 2 * * *'
 23 |   workflow_dispatch:
 24 |     inputs:
 25 |       pr_number:
 26 |         description: 'PR number to update (optional, updates all if not specified)'
 27 |         required: false
 28 |         type: string
 29 | 
 30 | permissions:
 31 |   contents: write  # Required for updateBranch API
 32 |   pull-requests: write
 33 |   issues: write
 34 | 
 35 | jobs:
 36 |   update-prs:
 37 |     runs-on: ubuntu-latest
 38 |     concurrency:
 39 |       group: auto-update-pr-${{ github.event_name }}
 40 |       cancel-in-progress: true
 41 |     steps:
 42 |       - name: Update PRs that are behind main
 43 |         uses: actions/github-script@v7
 44 |         with:
 45 |           script: |
 46 |             const prNumber = context.payload.inputs?.pr_number;
 47 | 
 48 |             // Get list of open PRs
 49 |             const prs = prNumber
 50 |               ? [(await github.rest.pulls.get({
 51 |                   owner: context.repo.owner,
 52 |                   repo: context.repo.repo,
 53 |                   pull_number: parseInt(prNumber)
 54 |                 })).data]
 55 |               : await github.paginate(github.rest.pulls.list, {
 56 |                   owner: context.repo.owner,
 57 |                   repo: context.repo.repo,
 58 |                   state: 'open',
 59 |                   sort: 'updated',
 60 |                   direction: 'desc'
 61 |                 });
 62 | 
 63 |             console.log(`Found ${prs.length} open PRs to check`);
 64 | 
 65 |             // Constants for comment flood control
 66 |             const UPDATE_COMMENT_COOLDOWN_DAYS = 7;
 67 |             const COOLDOWN_MS = UPDATE_COMMENT_COOLDOWN_DAYS * 24 * 60 * 60 * 1000;
 68 | 
 69 |             for (const pr of prs) {
 70 |               // Skip bot PRs and drafts
 71 |               if (pr.user.login.includes('[bot]')) {
 72 |                 console.log(`Skipping bot PR #${pr.number} from ${pr.user.login}`);
 73 |                 continue;
 74 |               }
 75 |               if (pr.draft) {
 76 |                 console.log(`Skipping draft PR #${pr.number}`);
 77 |                 continue;
 78 |               }
 79 | 
 80 |               try {
 81 |                 // Check if PR is behind main (base...head comparison)
 82 |                 const { data: comparison } = await github.rest.repos.compareCommits({
 83 |                   owner: context.repo.owner,
 84 |                   repo: context.repo.repo,
 85 |                   base: pr.base.ref,  // main branch
 86 |                   head: `${pr.head.repo.owner.login}:${pr.head.ref}`  // Fully qualified ref for forks
 87 |                 });
 88 | 
 89 |                 if (comparison.behind_by > 0) {
 90 |                   console.log(`PR #${pr.number} is ${comparison.behind_by} commits behind ${pr.base.ref}`);
 91 | 
 92 |                   // Check if the PR allows maintainer edits
 93 |                   if (pr.maintainer_can_modify) {
 94 |                     // Try to update the branch
 95 |                     try {
 96 |                       await github.rest.pulls.updateBranch({
 97 |                         owner: context.repo.owner,
 98 |                         repo: context.repo.repo,
 99 |                         pull_number: pr.number
100 |                       });
101 | 
102 |                       console.log(`✅ Updated PR #${pr.number}`);
103 | 
104 |                       // Add a comment
105 |                       await github.rest.issues.createComment({
106 |                         owner: context.repo.owner,
107 |                         repo: context.repo.repo,
108 |                         issue_number: pr.number,
109 |                         body: `🔄 **Branch Updated**\n\nYour branch was ${comparison.behind_by} commits behind \`${pr.base.ref}\` and has been automatically updated. CI checks will re-run shortly.`
110 |                       });
111 |                     } catch (updateError) {
112 |                       console.log(`Could not auto-update PR #${pr.number}: ${updateError.message}`);
113 | 
114 |                       // Determine the reason for failure
115 |                       let failureReason = '';
116 |                       if (updateError.status === 409 || updateError.message.includes('merge conflict')) {
117 |                         failureReason = '\n\n**Note:** Automatic update failed due to merge conflicts. Please resolve them manually.';
118 |                       } else if (updateError.status === 422) {
119 |                         failureReason = '\n\n**Note:** Cannot push to fork. Please update manually.';
120 |                       }
121 | 
122 |                       // Notify the contributor to update manually
123 |                       await github.rest.issues.createComment({
124 |                         owner: context.repo.owner,
125 |                         repo: context.repo.repo,
126 |                         issue_number: pr.number,
127 |                         body: `⚠️ **Branch Update Required**\n\nYour branch is ${comparison.behind_by} commits behind \`${pr.base.ref}\`.${failureReason}\n\nPlease update your branch:\n\n\`\`\`bash\ngit fetch origin ${pr.base.ref}\ngit merge origin/${pr.base.ref}\ngit push\n\`\`\`\n\nOr use GitHub's "Update branch" button if available.`
128 |                       });
129 |                     }
130 |                   } else {
131 |                     // Can't modify, just notify
132 |                     console.log(`PR #${pr.number} doesn't allow maintainer edits`);
133 | 
134 |                     // Check if we already commented recently (within last 7 days)
135 |                     const { data: comments } = await github.rest.issues.listComments({
136 |                       owner: context.repo.owner,
137 |                       repo: context.repo.repo,
138 |                       issue_number: pr.number,
139 |                       since: new Date(Date.now() - COOLDOWN_MS).toISOString()
140 |                     });
141 | 
142 |                     const hasRecentUpdateComment = comments.some(c =>
143 |                       c.body?.includes('Branch Update Required') &&
144 |                       c.user?.login === 'github-actions[bot]'
145 |                     );
146 | 
147 |                     if (!hasRecentUpdateComment) {
148 |                       await github.rest.issues.createComment({
149 |                         owner: context.repo.owner,
150 |                         repo: context.repo.repo,
151 |                         issue_number: pr.number,
152 |                         body: `⚠️ **Branch Update Required**\n\nYour branch is ${comparison.behind_by} commits behind \`${pr.base.ref}\`. Please update your branch to ensure CI checks run with the latest code:\n\n\`\`\`bash\ngit fetch origin ${pr.base.ref}\ngit merge origin/${pr.base.ref}\ngit push\n\`\`\`\n\nNote: Enable "Allow edits by maintainers" to allow automatic updates.`
153 |                       });
154 |                     }
155 |                   }
156 |                 } else {
157 |                   console.log(`PR #${pr.number} is up to date`);
158 |                 }
159 |               } catch (error) {
160 |                 console.error(`Error processing PR #${pr.number}:`, error.message);
161 |               }
162 |             }
163 | 
164 |             // Log rate limit status
165 |             const { data: rateLimit } = await github.rest.rateLimit.get();
166 |             console.log(`API rate limit remaining: ${rateLimit.rate.remaining}/${rateLimit.rate.limit}`);
167 | 


--------------------------------------------------------------------------------
/.github/workflows/check-infrastructure-changes.yml:
--------------------------------------------------------------------------------
  1 | name: Protect Infrastructure Files
  2 | 
  3 | on:
  4 |   pull_request_target:
  5 |     types: [opened, synchronize, reopened]
  6 |   workflow_dispatch:
  7 | 
  8 | permissions:
  9 |   contents: read
 10 |   pull-requests: write
 11 | 
 12 | jobs:
 13 |   protect-infrastructure:
 14 |     if: github.event_name == 'workflow_dispatch' || github.event.pull_request.draft == false
 15 |     runs-on: ubuntu-latest
 16 | 
 17 |     steps:
 18 |       - name: Check for infrastructure file changes
 19 |         if: github.event_name == 'pull_request_target'
 20 |         uses: actions/github-script@v7
 21 |         with:
 22 |           github-token: ${{ secrets.GITHUB_TOKEN }}
 23 |           script: |
 24 |             // Get the PR author and check if they're a maintainer
 25 |             const prAuthor = context.payload.pull_request.user.login;
 26 |             const { data: authorPermission } = await github.rest.repos.getCollaboratorPermissionLevel({
 27 |               owner: context.repo.owner,
 28 |               repo: context.repo.repo,
 29 |               username: prAuthor
 30 |             });
 31 | 
 32 |             const isMaintainer = ['admin', 'maintain'].includes(authorPermission.permission);
 33 | 
 34 |             // Get list of files changed in the PR
 35 |             const { data: files } = await github.rest.pulls.listFiles({
 36 |               owner: context.repo.owner,
 37 |               repo: context.repo.repo,
 38 |               pull_number: context.payload.pull_request.number
 39 |             });
 40 | 
 41 |             // Check for infrastructure file changes
 42 |             const infrastructureFiles = files.filter(file =>
 43 |               file.filename.startsWith('.github/') ||
 44 |               file.filename === 'pyproject.toml' ||
 45 |               file.filename === 'tox.ini' ||
 46 |               file.filename === '.pre-commit-config.yaml' ||
 47 |               file.filename === '.pylintrc' ||
 48 |               file.filename === 'Dockerfile' ||
 49 |               file.filename === 'autoformat.sh' ||
 50 |               file.filename === '.gitignore' ||
 51 |               file.filename === 'CONTRIBUTING.md' ||
 52 |               file.filename === 'LICENSE' ||
 53 |               file.filename === 'CITATION.cff'
 54 |             );
 55 | 
 56 |             if (infrastructureFiles.length > 0 && !isMaintainer) {
 57 |               // Check if changes are only formatting/whitespace
 58 |               let hasStructuralChanges = false;
 59 |               for (const file of infrastructureFiles) {
 60 |                 const additions = file.additions || 0;
 61 |                 const deletions = file.deletions || 0;
 62 |                 const changes = file.changes || 0;
 63 | 
 64 |                 // If file has significant changes (not just whitespace), consider it structural
 65 |                 if (additions > 5 || deletions > 5 || changes > 10) {
 66 |                   hasStructuralChanges = true;
 67 |                   break;
 68 |                 }
 69 |               }
 70 | 
 71 |               const fileList = infrastructureFiles.map(f => `  - ${f.filename} (${f.changes} changes)`).join('\n');
 72 | 
 73 |               // Post a comment explaining the issue
 74 |               await github.rest.issues.createComment({
 75 |                 owner: context.repo.owner,
 76 |                 repo: context.repo.repo,
 77 |                 issue_number: context.payload.pull_request.number,
 78 |                 body: `❌ **Infrastructure File Protection**\n\n` +
 79 |                       `This PR modifies protected infrastructure files:\n\n${fileList}\n\n` +
 80 |                       `Only repository maintainers are allowed to modify infrastructure files (including \`.github/\`, build configuration, and repository documentation).\n\n` +
 81 |                       `**Note**: If these are only formatting changes, please:\n` +
 82 |                       `1. Revert changes to \`.github/\` files\n` +
 83 |                       `2. Use \`./autoformat.sh\` to format only source code directories\n` +
 84 |                       `3. Avoid running formatters on infrastructure files\n\n` +
 85 |                       `If structural changes are necessary:\n` +
 86 |                       `1. Open an issue describing the needed infrastructure changes\n` +
 87 |                       `2. A maintainer will review and implement the changes if approved\n\n` +
 88 |                       `For more information, see our [Contributing Guidelines](https://github.com/google/langextract/blob/main/CONTRIBUTING.md).`
 89 |               });
 90 | 
 91 |               core.setFailed(
 92 |                 `This PR modifies ${infrastructureFiles.length} protected infrastructure file(s). ` +
 93 |                 `Only maintainers can modify these files. ` +
 94 |                 `Use ./autoformat.sh to format code without touching infrastructure.`
 95 |               );
 96 |             } else if (infrastructureFiles.length > 0 && isMaintainer) {
 97 |               core.info(`PR modifies ${infrastructureFiles.length} infrastructure file(s) - allowed for maintainer ${prAuthor}`);
 98 |             } else {
 99 |               core.info('No infrastructure files modified');
100 |             }
101 | 


--------------------------------------------------------------------------------
/.github/workflows/check-pr-size.yml:
--------------------------------------------------------------------------------
  1 | name: Check PR size
  2 | 
  3 | on:
  4 |   pull_request_target:
  5 |     types: [opened, synchronize, reopened]
  6 |   workflow_dispatch:
  7 |     inputs:
  8 |       pr_number:
  9 |         description: 'PR number to check (optional)'
 10 |         required: false
 11 |         type: string
 12 | 
 13 | permissions:
 14 |   contents: read
 15 |   pull-requests: write
 16 |   issues: write
 17 | 
 18 | concurrency:
 19 |   group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.run_id }}
 20 |   cancel-in-progress: true
 21 | 
 22 | jobs:
 23 |   size:
 24 |     runs-on: ubuntu-latest
 25 |     steps:
 26 |       - name: Get PR data for manual trigger
 27 |         if: github.event_name == 'workflow_dispatch' && github.event.inputs.pr_number
 28 |         id: get_pr
 29 |         uses: actions/github-script@v7
 30 |         with:
 31 |           result-encoding: string
 32 |           script: |
 33 |             const { data } = await github.rest.pulls.get({
 34 |               owner: context.repo.owner,
 35 |               repo: context.repo.repo,
 36 |               pull_number: ${{ github.event.inputs.pr_number }}
 37 |             });
 38 |             return JSON.stringify(data);
 39 | 
 40 |       - name: Evaluate PR size
 41 |         if: github.event_name == 'pull_request_target' || (github.event_name == 'workflow_dispatch' && github.event.inputs.pr_number)
 42 |         uses: actions/github-script@v7
 43 |         env:
 44 |           PR_JSON: ${{ steps.get_pr.outputs.result }}
 45 |         with:
 46 |           script: |
 47 |             const pr = context.payload.pull_request || JSON.parse(process.env.PR_JSON || '{}');
 48 |             if (!pr || !pr.number) {
 49 |               core.setFailed('Unable to resolve PR data. For workflow_dispatch, pass a valid pr_number.');
 50 |               return;
 51 |             }
 52 | 
 53 |             // Check for draft PRs and bots
 54 |             const isDraft = !!pr.draft;
 55 |             const login = pr.user.login;
 56 |             const isBot = pr.user.type === 'Bot' || /\[bot\]$/.test(login);
 57 | 
 58 |             if (isDraft || isBot) {
 59 |               core.info('Draft or bot PR – skipping size enforcement');
 60 |               return;
 61 |             }
 62 | 
 63 |             const totalChanges = pr.additions + pr.deletions;
 64 |             core.info(`PR contains ${pr.additions} additions and ${pr.deletions} deletions (${totalChanges} total)`);
 65 | 
 66 |             const sizeLabel =
 67 |               totalChanges < 50   ? 'size/XS' :
 68 |               totalChanges < 150  ? 'size/S'  :
 69 |               totalChanges < 600  ? 'size/M'  :
 70 |               totalChanges < 1000 ? 'size/L'  : 'size/XL';
 71 | 
 72 |             // Re-fetch labels to avoid acting on stale payload data
 73 |             const { data: freshIssue } = await github.rest.issues.get({
 74 |               ...context.repo,
 75 |               issue_number: pr.number
 76 |             });
 77 |             const currentLabels = (freshIssue.labels || []).map(l => l.name);
 78 | 
 79 |             // Remove old size labels before adding new one
 80 |             const allSizeLabels = ['size/XS', 'size/S', 'size/M', 'size/L', 'size/XL'];
 81 |             const toRemove = currentLabels.filter(name => allSizeLabels.includes(name) && name !== sizeLabel);
 82 | 
 83 |             for (const name of toRemove) {
 84 |               try {
 85 |                 await github.rest.issues.removeLabel({
 86 |                   ...context.repo,
 87 |                   issue_number: pr.number,
 88 |                   name
 89 |                 });
 90 |               } catch (_) {
 91 |                 // Ignore if already removed
 92 |               }
 93 |             }
 94 | 
 95 |             await github.rest.issues.addLabels({
 96 |               ...context.repo,
 97 |               issue_number: pr.number,
 98 |               labels: [sizeLabel]
 99 |             });
100 | 
101 |             // Check if PR author is a maintainer
102 |             let authorPerm = 'none';
103 |             try {
104 |               const { data } = await github.rest.repos.getCollaboratorPermissionLevel({
105 |                 owner: context.repo.owner,
106 |                 repo: context.repo.repo,
107 |                 username: pr.user.login,
108 |               });
109 |               authorPerm = data.permission || 'none';
110 |             } catch (_) {
111 |               // User might not have any permissions
112 |             }
113 | 
114 |             core.info(`Author permission: ${authorPerm}`);
115 |             const isMaintainer = ['admin', 'maintain'].includes(authorPerm); // Stricter maintainer definition
116 | 
117 |             // Check for bypass label (using fresh labels)
118 |             const hasBypass = currentLabels.includes('bypass:size-limit');
119 | 
120 |             const MAX_LINES = 1000;
121 |             if (totalChanges > MAX_LINES) {
122 |               if (isMaintainer || hasBypass) {
123 |                 core.info(`${isMaintainer ? 'Maintainer' : 'Bypass label'} - allowing large PR with ${totalChanges} lines`);
124 |               } else {
125 |                 core.setFailed(
126 |                   `This PR contains ${totalChanges} lines of changes, which exceeds the maximum of ${MAX_LINES} lines. ` +
127 |                   `Please split this into smaller, focused pull requests.`
128 |                 );
129 |               }
130 |             }
131 | 


--------------------------------------------------------------------------------
/.github/workflows/check-pr-up-to-date.yaml:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | name: Check PR Up-to-Date
16 | 
17 | on:
18 |   pull_request:
19 |     types: [opened, synchronize]
20 | 
21 | permissions:
22 |   contents: read
23 |   pull-requests: write
24 | 
25 | jobs:
26 |   check-up-to-date:
27 |     runs-on: ubuntu-latest
28 |     # Skip for bot PRs
29 |     if: ${{ !contains(github.actor, '[bot]') }}
30 |     concurrency:
31 |       group: check-pr-${{ github.event.pull_request.number }}
32 |       cancel-in-progress: true
33 |     steps:
34 |       - name: Checkout repository
35 |         uses: actions/checkout@v4
36 |         with:
37 |           fetch-depth: 2  # Sufficient for rev-list comparison
38 | 
39 |       - name: Check if PR is up-to-date with main
40 |         id: check
41 |         run: |
42 |           # Fetch the latest main branch
43 |           git fetch origin main
44 | 
45 |           # Check how many commits behind main
46 |           BEHIND=$(git rev-list --count HEAD..origin/main)
47 | 
48 |           echo "commits_behind=$BEHIND" >> $GITHUB_OUTPUT
49 | 
50 |           if [ "$BEHIND" -gt 0 ]; then
51 |             echo "::warning::PR is $BEHIND commits behind main"
52 |             exit 0  # Don't fail the check, just warn
53 |           else
54 |             echo "PR is up-to-date with main"
55 |           fi
56 | 
57 |       - name: Comment if PR needs update
58 |         if: ${{ steps.check.outputs.commits_behind != '0' }}
59 |         uses: actions/github-script@v7
60 |         with:
61 |           script: |
62 |             const behind = ${{ steps.check.outputs.commits_behind }};
63 |             const COMMENT_COOLDOWN_HOURS = 24;
64 |             const COOLDOWN_MS = COMMENT_COOLDOWN_HOURS * 60 * 60 * 1000;
65 | 
66 |             // Check for recent similar comments
67 |             const { data: comments } = await github.rest.issues.listComments({
68 |               owner: context.repo.owner,
69 |               repo: context.repo.repo,
70 |               issue_number: context.payload.pull_request.number,
71 |               per_page: 10
72 |             });
73 | 
74 |             const hasRecentComment = comments.some(c =>
75 |               c.body?.includes('commits behind `main`') &&
76 |               c.user?.login === 'github-actions[bot]' &&
77 |               new Date(c.created_at) > new Date(Date.now() - COOLDOWN_MS)
78 |             );
79 | 
80 |             if (!hasRecentComment) {
81 |               await github.rest.issues.createComment({
82 |                 owner: context.repo.owner,
83 |                 repo: context.repo.repo,
84 |                 issue_number: context.payload.pull_request.number,
85 |                 body: `📊 **PR Status**: ${behind} commits behind \`main\`\n\nConsider updating your branch for the most accurate CI results:\n\n**Option 1**: Use GitHub's "Update branch" button (if available)\n\n**Option 2**: Update locally:\n\`\`\`bash\ngit fetch origin main\ngit merge origin/main\ngit push\n\`\`\`\n\n*Note: If you use a different remote name (e.g., upstream), adjust the commands accordingly.*\n\nThis ensures your changes are tested against the latest code.`
86 |               });
87 |             }
88 | 


--------------------------------------------------------------------------------
/.github/workflows/publish.yml:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | name: Publish to PyPI
16 | 
17 | on:
18 |   release:
19 |     types: [published]
20 | 
21 | permissions:
22 |   contents: read
23 |   id-token: write
24 | 
25 | jobs:
26 |   pypi-publish:
27 |     name: Publish to PyPI
28 |     runs-on: ubuntu-latest
29 |     environment: pypi
30 |     permissions:
31 |       id-token: write
32 |     steps:
33 |       - uses: actions/checkout@v4
34 | 
35 |       - name: Set up Python
36 |         uses: actions/setup-python@v5
37 |         with:
38 |           python-version: '3.11'
39 | 
40 |       - name: Install build dependencies
41 |         run: |
42 |           python -m pip install --upgrade pip
43 |           pip install build
44 | 
45 |       - name: Build package
46 |         run: python -m build
47 | 
48 |       - name: Verify build artifacts
49 |         run: |
50 |           ls -la dist/
51 |           pip install twine
52 |           twine check dist/*
53 | 
54 |       - name: Publish to PyPI
55 |         uses: pypa/gh-action-pypi-publish@release/v1
56 | 


--------------------------------------------------------------------------------
/.github/workflows/revalidate-pr.yml:
--------------------------------------------------------------------------------
  1 | name: Revalidate PR
  2 | 
  3 | on:
  4 |   workflow_dispatch:
  5 |     inputs:
  6 |       pr_number:
  7 |         description: 'PR number to validate'
  8 |         required: true
  9 |         type: string
 10 | 
 11 | permissions:
 12 |   contents: read
 13 |   pull-requests: write
 14 |   issues: write
 15 |   checks: write
 16 |   statuses: write
 17 | 
 18 | jobs:
 19 |   revalidate:
 20 |     runs-on: ubuntu-latest
 21 |     steps:
 22 |       - name: Get PR data
 23 |         id: pr_data
 24 |         uses: actions/github-script@v7
 25 |         with:
 26 |           script: |
 27 |             const { data: pr } = await github.rest.pulls.get({
 28 |               owner: context.repo.owner,
 29 |               repo: context.repo.repo,
 30 |               pull_number: ${{ inputs.pr_number }}
 31 |             });
 32 | 
 33 |             core.info(`Validating PR #${pr.number}: ${pr.title}`);
 34 |             core.info(`Author: ${pr.user.login}`);
 35 |             core.info(`Changes: +${pr.additions} -${pr.deletions}`);
 36 | 
 37 |             // Store head SHA for creating status
 38 |             core.setOutput('head_sha', pr.head.sha);
 39 | 
 40 |             return pr;
 41 | 
 42 |       - name: Create pending status
 43 |         uses: actions/github-script@v7
 44 |         with:
 45 |           script: |
 46 |             await github.rest.repos.createCommitStatus({
 47 |               owner: context.repo.owner,
 48 |               repo: context.repo.repo,
 49 |               sha: '${{ steps.pr_data.outputs.head_sha }}',
 50 |               state: 'pending',
 51 |               context: 'Manual Validation',
 52 |               description: 'Running validation checks...'
 53 |             });
 54 | 
 55 |       - name: Validate PR
 56 |         id: validate
 57 |         uses: actions/github-script@v7
 58 |         with:
 59 |           script: |
 60 |             const pr = ${{ steps.pr_data.outputs.result }};
 61 |             const errors = [];
 62 |             let passed = true;
 63 | 
 64 |             // Check size
 65 |             const totalChanges = pr.additions + pr.deletions;
 66 |             const MAX_LINES = 1000;
 67 |             if (totalChanges > MAX_LINES) {
 68 |               errors.push(`PR size (${totalChanges} lines) exceeds ${MAX_LINES} line limit`);
 69 |               passed = false;
 70 |             }
 71 | 
 72 |             // Check template
 73 |             const body = pr.body || '';
 74 |             const requiredSections = ["# Description", "Fixes #", "# How Has This Been Tested?", "# Checklist"];
 75 |             const missingSections = requiredSections.filter(section => !body.includes(section));
 76 | 
 77 |             if (missingSections.length > 0) {
 78 |               errors.push(`Missing PR template sections: ${missingSections.join(', ')}`);
 79 |               passed = false;
 80 |             }
 81 | 
 82 |             if (body.match(/Replace this with|Choose one:|Fixes #\[issue number\]/i)) {
 83 |               errors.push('PR template contains unmodified placeholders');
 84 |               passed = false;
 85 |             }
 86 | 
 87 |             // Check linked issue
 88 |             const issueMatch = body.match(/(?:Fixes|Closes|Resolves)\s+#(\d+)/i);
 89 |             if (!issueMatch) {
 90 |               errors.push('No linked issue found');
 91 |               passed = false;
 92 |             }
 93 | 
 94 |             // Store results
 95 |             core.setOutput('passed', passed);
 96 |             core.setOutput('errors', errors.join('; '));
 97 |             core.setOutput('totalChanges', totalChanges);
 98 |             core.setOutput('hasTemplate', missingSections.length === 0);
 99 |             core.setOutput('hasIssue', !!issueMatch);
100 | 
101 |             if (!passed) {
102 |               core.setFailed(errors.join('; '));
103 |             }
104 | 
105 |       - name: Update commit status
106 |         if: always()
107 |         uses: actions/github-script@v7
108 |         with:
109 |           script: |
110 |             const passed = ${{ steps.validate.outputs.passed }};
111 |             const errors = '${{ steps.validate.outputs.errors }}';
112 | 
113 |             await github.rest.repos.createCommitStatus({
114 |               owner: context.repo.owner,
115 |               repo: context.repo.repo,
116 |               sha: '${{ steps.pr_data.outputs.head_sha }}',
117 |               state: passed ? 'success' : 'failure',
118 |               context: 'Manual Validation',
119 |               description: passed ? 'All validation checks passed' : errors.substring(0, 140),
120 |               target_url: `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
121 |             });
122 | 
123 |       - name: Add validation comment
124 |         if: always()
125 |         uses: actions/github-script@v7
126 |         with:
127 |           script: |
128 |             const pr = ${{ steps.pr_data.outputs.result }};
129 |             const passed = ${{ steps.validate.outputs.passed }};
130 |             const totalChanges = ${{ steps.validate.outputs.totalChanges }};
131 |             const hasTemplate = ${{ steps.validate.outputs.hasTemplate }};
132 |             const hasIssue = ${{ steps.validate.outputs.hasIssue }};
133 |             const errors = '${{ steps.validate.outputs.errors }}'.split('; ').filter(e => e);
134 | 
135 |             let body = `### Manual Validation Results\n\n`;
136 |             body += `**Status**: ${passed ? '✅ Passed' : '❌ Failed'}\n\n`;
137 |             body += `| Check | Status | Details |\n`;
138 |             body += `|-------|--------|----------|\n`;
139 |             body += `| PR Size | ${totalChanges <= 1000 ? '✅' : '❌'} | ${totalChanges} lines ${totalChanges > 1000 ? '(exceeds 1000 limit)' : ''} |\n`;
140 |             body += `| Template | ${hasTemplate ? '✅' : '❌'} | ${hasTemplate ? 'Complete' : 'Missing required sections'} |\n`;
141 |             body += `| Linked Issue | ${hasIssue ? '✅' : '❌'} | ${hasIssue ? 'Found' : 'Missing Fixes/Closes #XXX'} |\n`;
142 | 
143 |             if (errors.length > 0) {
144 |               body += `\n**Errors:**\n`;
145 |               errors.forEach(error => {
146 |                 body += `- ❌ ${error}\n`;
147 |               });
148 |             }
149 | 
150 |             body += `\n[View workflow run](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`;
151 | 
152 |             await github.rest.issues.createComment({
153 |               owner: context.repo.owner,
154 |               repo: context.repo.repo,
155 |               issue_number: pr.number,
156 |               body: body
157 |             });
158 | 


--------------------------------------------------------------------------------
/.github/workflows/validate_pr_template.yaml:
--------------------------------------------------------------------------------
 1 | name: Validate PR template
 2 | 
 3 | on:
 4 |   pull_request_target:
 5 |     types: [opened, edited, synchronize, reopened]
 6 |   workflow_dispatch:
 7 | 
 8 | permissions:
 9 |   contents: read
10 |   pull-requests: read
11 | 
12 | jobs:
13 |   check:
14 |     runs-on: ubuntu-latest
15 | 
16 |     steps:
17 |       - name: Check PR author permissions
18 |         id: check
19 |         if: github.event_name == 'pull_request_target' && github.event.pull_request.draft == false
20 |         uses: actions/github-script@v7
21 |         with:
22 |           github-token: ${{ secrets.GITHUB_TOKEN }}
23 |           script: |
24 |             const pr = context.payload.pull_request;
25 |             const {owner, repo} = context.repo;
26 |             const actor = pr.user.login;
27 |             const authorType = pr.user.type;
28 | 
29 |             // Check if PR author is a bot (e.g., Dependabot)
30 |             if (authorType === 'Bot') {
31 |               core.setOutput('skip_validation', 'true');
32 |               console.log(`Skipping validation for bot-authored PR: ${actor}`);
33 |               return;
34 |             }
35 | 
36 |             // Get permission level
37 |             try {
38 |               const { data } = await github.rest.repos.getCollaboratorPermissionLevel({
39 |                 owner, repo, username: actor
40 |               });
41 | 
42 |               const permission = data.permission; // admin|maintain|write|triage|read|none
43 |               console.log(`Actor ${actor} has permission level: ${permission}`);
44 | 
45 |               // Check if user has write+ permissions
46 |               if (['admin', 'maintain', 'write'].includes(permission)) {
47 |                 core.setOutput('skip_validation', 'true');
48 |                 console.log(`Skipping validation for maintainer: ${actor} (${permission})`);
49 |               } else {
50 |                 core.setOutput('skip_validation', 'false');
51 |                 console.log(`Validation required for: ${actor} (${permission})`);
52 |               }
53 |             } catch (e) {
54 |               // If we can't determine permissions, require validation
55 |               core.setOutput('skip_validation', 'false');
56 |               core.warning(`Permission lookup failed: ${e.message}`);
57 |             }
58 | 
59 |       - name: Validate PR template
60 |         if: |
61 |           github.event_name == 'pull_request_target' &&
62 |           github.event.pull_request.draft == false &&
63 |           steps.check.outputs.skip_validation != 'true'
64 |         env:
65 |           PR_BODY: ${{ github.event.pull_request.body }}
66 |         run: |
67 |           printf '%s\n' "$PR_BODY" | tr -d '\r' > body.txt
68 | 
69 |           # Required sections from the template
70 |           required=( "# Description" "Fixes #" "# How Has This Been Tested?" "# Checklist" )
71 |           err=0
72 | 
73 |           # Check for required sections
74 |           for h in "${required[@]}"; do
75 |             grep -Fq "$h" body.txt || { echo "::error::$h missing"; err=1; }
76 |           done
77 | 
78 |           # Check for placeholder text that should be replaced
79 |           grep -Eiq 'Replace this with|Choose one:' body.txt && {
80 |             echo "::error::Template placeholders still present"; err=1;
81 |           }
82 | 
83 |           # Also check for the unmodified issue number placeholder
84 |           grep -Fq 'Fixes #[issue number]' body.txt && {
85 |             echo "::error::Issue number placeholder not updated"; err=1;
86 |           }
87 | 
88 |           exit $err
89 | 
90 |       - name: Log skip reason
91 |         if: |
92 |           github.event_name == 'pull_request_target' &&
93 |           (github.event.pull_request.draft == true ||
94 |            steps.check.outputs.skip_validation == 'true')
95 |         run: |
96 |           echo "Skipping PR template validation. Draft: ${{ github.event.pull_request.draft }}; skip_validation: ${{ steps.check.outputs.skip_validation || 'N/A' }}"
97 | 


--------------------------------------------------------------------------------
/.gitignore:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | # Byte-compiled / Cache files
 16 | __pycache__/
 17 | *.py[cod]
 18 | *$py.class
 19 | 
 20 | # Distribution / Packaging
 21 | build/
 22 | dist/
 23 | *.egg-info/
 24 | .eggs/
 25 | eggs/
 26 | 
 27 | # Virtual Environments
 28 | .env
 29 | .venv
 30 | env/
 31 | venv/
 32 | ENV/
 33 | 
 34 | # Test & Coverage Reports
 35 | .pytest_cache/
 36 | .tox/
 37 | htmlcov/
 38 | .coverage
 39 | .coverage.*
 40 | 
 41 | # Generated Output & Data
 42 | # LangExtract outputs are defaulted to test_output/
 43 | /test_output/
 44 | 
 45 | # Sphinx documentation build output
 46 | docs/_build/
 47 | 
 48 | # IDE / Editor specific
 49 | .idea/
 50 | .vscode/
 51 | *.swp
 52 | *.swo
 53 | *~
 54 | .*.swp
 55 | .*.swo
 56 | 
 57 | # OS-specific
 58 | .DS_Store
 59 | Thumbs.db
 60 | ehthumbs.db
 61 | Desktop.ini
 62 | $RECYCLE.BIN/
 63 | *.cab
 64 | *.msi
 65 | *.msm
 66 | *.msp
 67 | *.lnk
 68 | 
 69 | # Development tools & environments
 70 | .python-version
 71 | .pytype/
 72 | .mypy_cache/
 73 | .dmypy.json
 74 | dmypy.json
 75 | .pyre/
 76 | .ruff_cache/
 77 | *.sage.py
 78 | .hypothesis/
 79 | .scrapy
 80 | 
 81 | # Jupyter Notebooks
 82 | .ipynb_checkpoints
 83 | */.ipynb_checkpoints/*
 84 | profile_default/
 85 | ipython_config.py
 86 | 
 87 | # Logs and databases
 88 | *.log
 89 | *.sql
 90 | *.sqlite
 91 | *.sqlite3
 92 | db.sqlite3
 93 | db.sqlite3-journal
 94 | logs/
 95 | *.pid
 96 | 
 97 | # Security and secrets
 98 | *.key
 99 | *.pem
100 | *.crt
101 | *.csr
102 | .env.local
103 | .env.production
104 | .env.*.local
105 | secrets/
106 | credentials/
107 | 
108 | # AI tooling
109 | CLAUDE.md
110 | .claude/settings.local.json
111 | .aider.chat.history.*
112 | .aider.input.history
113 | .gemini/
114 | GEMINI.md
115 | 
116 | # Package managers
117 | pip-log.txt
118 | pip-delete-this-directory.txt
119 | node_modules/
120 | npm-debug.log*
121 | yarn-debug.log*
122 | yarn-error.log*
123 | .pnpm-debug.log*
124 | package-lock.json
125 | yarn.lock
126 | pnpm-lock.yaml
127 | 
128 | # Local development
129 | local_settings.py
130 | instance/
131 | .webassets-cache
132 | .sass-cache/
133 | *.css.map
134 | *.js.map
135 | .dev/
136 | 
137 | # Temporary files
138 | tmp/
139 | temp/
140 | cache/
141 | *.tmp
142 | *.bak
143 | *.backup
144 | *.orig
145 | .~lock.*#
146 | 
147 | # Archives
148 | *.tar
149 | *.tar.gz
150 | *.zip
151 | *.rar
152 | *.7z
153 | *.dmg
154 | *.iso
155 | *.jar
156 | 
157 | # Media files
158 | *.mp4
159 | *.avi
160 | *.mov
161 | *.wmv
162 | *.flv
163 | *.mp3
164 | *.wav
165 | *.ogg
166 | 


--------------------------------------------------------------------------------
/.pre-commit-config.yaml:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | # Pre-commit hooks for LangExtract
16 | # Install with: pre-commit install
17 | # Run manually: pre-commit run --all-files
18 | 
19 | repos:
20 |   - repo: https://github.com/PyCQA/isort
21 |     rev: 5.13.2
22 |     hooks:
23 |       - id: isort
24 |         name: isort (import sorting)
25 |         # Configuration is in pyproject.toml
26 | 
27 |   - repo: https://github.com/google/pyink
28 |     rev: 24.3.0
29 |     hooks:
30 |       - id: pyink
31 |         name: pyink (Google's Black fork)
32 |         args: ["--config", "pyproject.toml"]
33 | 
34 |   - repo: https://github.com/pre-commit/pre-commit-hooks
35 |     rev: v4.5.0
36 |     hooks:
37 |       - id: end-of-file-fixer
38 |         exclude: \.gif$|\.svg$
39 |       - id: trailing-whitespace
40 |       - id: check-yaml
41 |       - id: check-added-large-files
42 |         args: ['--maxkb=1000']
43 |       - id: check-merge-conflict
44 |       - id: check-case-conflict
45 |       - id: mixed-line-ending
46 |         args: ['--fix=lf']
47 | 


--------------------------------------------------------------------------------
/CITATION.cff:
--------------------------------------------------------------------------------
 1 | # SPDX-FileCopyrightText: 2025 Google LLC
 2 | # SPDX-License-Identifier: Apache-2.0
 3 | #
 4 | # This file contains citation metadata for LangExtract.
 5 | # For more information visit: https://citation-file-format.github.io/
 6 | 
 7 | cff-version: 1.2.0
 8 | title: "LangExtract"
 9 | message: "If you use this software, please cite it as below."
10 | type: software
11 | authors:
12 |   - given-names: Akshay
13 |     family-names: Goel
14 |     email: goelak@google.com
15 |     affiliation: Google LLC
16 | repository-code: "https://github.com/google/langextract"
17 | url: "https://github.com/google/langextract"
18 | repository: "https://github.com/google/langextract"
19 | abstract: "LangExtract: LLM-powered structured information extraction from text with source grounding"
20 | keywords:
21 |   - language-models
22 |   - structured-data-extraction
23 |   - nlp
24 |   - machine-learning
25 |   - python
26 | license: Apache-2.0
27 | version: 1.0.3
28 | date-released: 2025-07-30
29 | 


--------------------------------------------------------------------------------
/CONTRIBUTING.md:
--------------------------------------------------------------------------------
  1 | # How to Contribute
  2 | 
  3 | We would love to accept your patches and contributions to this project.
  4 | 
  5 | ## Before you begin
  6 | 
  7 | ### Sign our Contributor License Agreement
  8 | 
  9 | Contributions to this project must be accompanied by a
 10 | [Contributor License Agreement](https://cla.developers.google.com/about) (CLA).
 11 | You (or your employer) retain the copyright to your contribution; this simply
 12 | gives us permission to use and redistribute your contributions as part of the
 13 | project.
 14 | 
 15 | If you or your current employer have already signed the Google CLA (even if it
 16 | was for a different project), you probably don't need to do it again.
 17 | 
 18 | Visit <https://cla.developers.google.com/> to see your current agreements or to
 19 | sign a new one.
 20 | 
 21 | ### Review our Community Guidelines
 22 | 
 23 | This project follows HAI-DEF's
 24 | [Community guidelines](https://developers.google.com/health-ai-developer-foundations/community-guidelines)
 25 | 
 26 | ## Reporting Issues
 27 | 
 28 | If you encounter a bug or have a feature request, please open an issue on GitHub.
 29 | We have templates to help guide you:
 30 | 
 31 | - **[Bug Report](.github/ISSUE_TEMPLATE/1-bug.md)**: For reporting bugs or unexpected behavior
 32 | - **[Feature Request](.github/ISSUE_TEMPLATE/2-feature-request.md)**: For suggesting new features or improvements
 33 | 
 34 | When creating an issue, GitHub will prompt you to choose the appropriate template.
 35 | Please provide as much detail as possible to help us understand and address your concern.
 36 | 
 37 | ## Contribution Process
 38 | 
 39 | ### 1. Development Setup
 40 | 
 41 | To get started, clone the repository and install the necessary dependencies for development and testing. Detailed instructions can be found in the [Installation from Source](https://github.com/google/langextract#from-source) section of the `README.md`.
 42 | 
 43 | **Windows Users**: The formatting scripts use bash. Please use one of:
 44 | - Git Bash (comes with Git for Windows)
 45 | - WSL (Windows Subsystem for Linux)
 46 | - PowerShell with bash-compatible commands
 47 | 
 48 | ### 2. Code Style and Formatting
 49 | 
 50 | This project uses automated tools to maintain a consistent code style. Before submitting a pull request, please format your code:
 51 | 
 52 | ```bash
 53 | # Run the auto-formatter
 54 | ./autoformat.sh
 55 | ```
 56 | 
 57 | This script uses:
 58 | - `isort` to organize imports with Google style (single-line imports)
 59 | - `pyink` (Google's fork of Black) to format code according to Google's Python Style Guide
 60 | 
 61 | You can also run the formatters manually:
 62 | ```bash
 63 | isort langextract tests
 64 | pyink langextract tests --config pyproject.toml
 65 | ```
 66 | 
 67 | Note: The formatters target only `langextract` and `tests` directories by default to avoid
 68 | formatting virtual environments or other non-source directories.
 69 | 
 70 | ### 3. Pre-commit Hooks (Recommended)
 71 | 
 72 | For automatic formatting checks before each commit:
 73 | 
 74 | ```bash
 75 | # Install pre-commit
 76 | pip install pre-commit
 77 | 
 78 | # Install the git hooks
 79 | pre-commit install
 80 | 
 81 | # Run manually on all files
 82 | pre-commit run --all-files
 83 | ```
 84 | 
 85 | ### 4. Linting and Testing
 86 | 
 87 | All contributions must pass linting checks and unit tests. Please run these locally before submitting your changes:
 88 | 
 89 | ```bash
 90 | # Run linting with Pylint 3.x
 91 | pylint --rcfile=.pylintrc langextract tests
 92 | 
 93 | # Run tests
 94 | pytest tests
 95 | ```
 96 | 
 97 | **Note on Pylint Configuration**: We use a modern, minimal configuration that:
 98 | - Only disables truly noisy checks (not entire categories)
 99 | - Keeps critical error detection enabled
100 | - Uses plugins for enhanced docstring and type checking
101 | - Aligns with our pyink formatter (80-char lines, 2-space indents)
102 | 
103 | For full testing across Python versions:
104 | ```bash
105 | tox  # runs pylint + pytest on Python 3.10 and 3.11
106 | ```
107 | 
108 | ### 5. Adding Custom Model Providers
109 | 
110 | If you want to add support for a new LLM provider, please refer to the [Provider System Documentation](langextract/providers/README.md). The recommended approach is to create an external plugin package rather than modifying the core library. This allows for:
111 | - Independent versioning and releases
112 | - Faster iteration without core review cycles
113 | - Custom dependencies without affecting core users
114 | 
115 | ### 6. Submit Your Pull Request
116 | 
117 | All submissions, including submissions by project members, require review. We
118 | use [GitHub pull requests](https://docs.github.com/articles/about-pull-requests)
119 | for this purpose.
120 | 
121 | When you create a pull request, GitHub will automatically populate it with our
122 | [pull request template](.github/PULL_REQUEST_TEMPLATE/pull_request_template.md).
123 | Please fill out all sections of the template to help reviewers understand your changes.
124 | 
125 | #### Pull Request Guidelines
126 | 
127 | - **Keep PRs focused and small**: Each PR should address a single issue and contain one cohesive change. PRs are automatically labeled by size to help reviewers:
128 |   - **size/XS**: < 50 lines — Small fixes and documentation updates
129 |   - **size/S**: 50-150 lines — Typical features or bug fixes
130 |   - **size/M**: 150-600 lines — Larger features that remain well-scoped
131 |   - **size/L**: 600-1000 lines — Consider splitting into smaller PRs if possible
132 |   - **size/XL**: > 1000 lines — Requires strong justification and may need special review
133 | - **Reference related issues**: All PRs must include "Fixes #123" or "Closes #123" in the description. The linked issue should have at least 5 👍 reactions from the community and include discussion that demonstrates the importance and need for the change.
134 | - **No infrastructure changes**: Contributors cannot modify infrastructure files, build configuration, and core documentation. These files are protected and can only be changed by maintainers. Use `./autoformat.sh` to format code without affecting infrastructure files. In special circumstances, build configuration updates may be considered if they include discussion and evidence of robust testing, ideally with community support.
135 | - **Single-change commits**: A PR should typically comprise a single git commit. Squash multiple commits before submitting.
136 | - **Clear description**: Explain what your change does and why it's needed.
137 | - **Ensure all tests pass**: Check that both formatting and tests are green before requesting review.
138 | - **Respond to feedback promptly**: Address reviewer comments in a timely manner.
139 | 
140 | If your change is large or complex, consider:
141 | - Opening an issue first to discuss the approach
142 | - Breaking it into multiple smaller PRs
143 | - Clearly explaining in the PR description why a larger change is necessary
144 | 
145 | For more details, read HAI-DEF's
146 | [Contributing guidelines](https://developers.google.com/health-ai-developer-foundations/community-guidelines#contributing)
147 | 


--------------------------------------------------------------------------------
/Dockerfile:
--------------------------------------------------------------------------------
 1 | # Production Dockerfile for LangExtract
 2 | FROM python:3.10-slim
 3 | 
 4 | # Set working directory
 5 | WORKDIR /app
 6 | 
 7 | # Install LangExtract from PyPI
 8 | RUN pip install --no-cache-dir langextract
 9 | 
10 | # Set default command
11 | CMD ["python"]
12 | 


--------------------------------------------------------------------------------
/autoformat.sh:
--------------------------------------------------------------------------------
  1 | #!/bin/bash
  2 | # Copyright 2025 Google LLC
  3 | #
  4 | # Licensed under the Apache License, Version 2.0 (the "License");
  5 | # you may not use this file except in compliance with the License.
  6 | # You may obtain a copy of the License at
  7 | #
  8 | #     http://www.apache.org/licenses/LICENSE-2.0
  9 | #
 10 | # Unless required by applicable law or agreed to in writing, software
 11 | # distributed under the License is distributed on an "AS IS" BASIS,
 12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 13 | # See the License for the specific language governing permissions and
 14 | # limitations under the License.
 15 | 
 16 | # Autoformat LangExtract codebase
 17 | #
 18 | # Usage: ./autoformat.sh [target_directory ...]
 19 | #        If no target is specified, formats the current directory
 20 | #
 21 | # This script runs:
 22 | # 1. isort for import sorting
 23 | # 2. pyink (Google's Black fork) for code formatting
 24 | # 3. pre-commit hooks for additional formatting (trailing whitespace, end-of-file, etc.)
 25 | 
 26 | set -e
 27 | 
 28 | echo "LangExtract Auto-formatter"
 29 | echo "=========================="
 30 | echo
 31 | 
 32 | # Check for required tools
 33 | check_tool() {
 34 |     if ! command -v "$1" &> /dev/null; then
 35 |         echo "Error: $1 not found. Please install with: pip install $1"
 36 |         exit 1
 37 |     fi
 38 | }
 39 | 
 40 | check_tool "isort"
 41 | check_tool "pyink"
 42 | check_tool "pre-commit"
 43 | 
 44 | # Parse command line arguments
 45 | show_usage() {
 46 |     echo "Usage: $0 [target_directory ...]"
 47 |     echo
 48 |     echo "Formats Python code using isort and pyink according to Google style."
 49 |     echo
 50 |     echo "Arguments:"
 51 |     echo "  target_directory    One or more directories to format (default: langextract tests)"
 52 |     echo
 53 |     echo "Examples:"
 54 |     echo "  $0                  # Format langextract and tests directories"
 55 |     echo "  $0 langextract      # Format only langextract directory"
 56 |     echo "  $0 src tests        # Format multiple specific directories"
 57 | }
 58 | 
 59 | # Check for help flag
 60 | if [ "$1" = "-h" ] || [ "$1" = "--help" ]; then
 61 |     show_usage
 62 |     exit 0
 63 | fi
 64 | 
 65 | # Determine target directories
 66 | if [ $# -eq 0 ]; then
 67 |     TARGETS="langextract tests"
 68 |     echo "No target specified. Formatting default directories: langextract tests"
 69 | else
 70 |     TARGETS="$@"
 71 |     echo "Formatting targets: $TARGETS"
 72 | fi
 73 | 
 74 | # Find pyproject.toml relative to script location
 75 | SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
 76 | CONFIG_FILE="${SCRIPT_DIR}/pyproject.toml"
 77 | 
 78 | if [ ! -f "$CONFIG_FILE" ]; then
 79 |     echo "Warning: pyproject.toml not found at ${CONFIG_FILE}"
 80 |     echo "Using default configuration."
 81 |     CONFIG_ARG=""
 82 | else
 83 |     CONFIG_ARG="--config $CONFIG_FILE"
 84 | fi
 85 | 
 86 | echo
 87 | 
 88 | # Run isort
 89 | echo "Running isort to organize imports..."
 90 | if isort $TARGETS; then
 91 |     echo "Import sorting complete"
 92 | else
 93 |     echo "Import sorting failed"
 94 |     exit 1
 95 | fi
 96 | 
 97 | echo
 98 | 
 99 | # Run pyink
100 | echo "Running pyink to format code (Google style, 80 chars)..."
101 | if pyink $TARGETS $CONFIG_ARG; then
102 |     echo "Code formatting complete"
103 | else
104 |     echo "Code formatting failed"
105 |     exit 1
106 | fi
107 | 
108 | echo
109 | 
110 | # Run pre-commit hooks for additional formatting
111 | echo "Running pre-commit hooks for additional formatting..."
112 | if pre-commit run --all-files; then
113 |     echo "Pre-commit hooks passed"
114 | else
115 |     echo "Pre-commit hooks made changes - please review"
116 |     # Exit with success since formatting was applied
117 |     exit 0
118 | fi
119 | 
120 | echo
121 | echo "All formatting complete!"
122 | echo
123 | echo "Next steps:"
124 | echo "  - Run: pylint --rcfile=${SCRIPT_DIR}/.pylintrc $TARGETS"
125 | echo "  - Commit your changes"
126 | 


--------------------------------------------------------------------------------
/docs/_static/logo.svg:
--------------------------------------------------------------------------------
 1 | <!-- langextract‑logo.svg  – 128×128 px display size, scalable thanks to viewBox -->
 2 | <svg viewBox="0 0 655 655" width="128" height="128"
 3 |      xmlns="http://www.w3.org/2000/svg">
 4 | 
 5 |   <!-- LOGO -->
 6 |   <rect width="655" height="655" fill="white"/>
 7 |   <rect x="25" y="24" width="418" height="392" rx="44" fill="#DADCE0"/>
 8 |   <path d="M47 112.5H420" stroke="#5F6368" stroke-width="8" stroke-linecap="round"/>
 9 |   <path d="M47 175.5H420" stroke="#5F6368" stroke-width="8" stroke-linecap="round"/>
10 |   <path d="M47 242.5H420" stroke="#5F6368" stroke-width="8" stroke-linecap="round"/>
11 |   <path d="M47 321.5H420" stroke="#5F6368" stroke-width="8" stroke-linecap="round"/>
12 |   <rect x="201" y="92" width="180" height="40" rx="20" fill="#FDE293" stroke="#5F6368" stroke-width="8"/>
13 |   <rect x="93" y="155" width="237" height="40" rx="20" fill="#AECBFA" stroke="#5F6368" stroke-width="8"/>
14 |   <rect x="184" y="222" width="180" height="40" rx="20" fill="white" stroke="#5F6368" stroke-width="8"/>
15 |   <rect x="62" y="301" width="180" height="40" rx="20" fill="#F6AEA9" stroke="#5F6368" stroke-width="8"/>
16 |   <rect x="211" y="238" width="418" height="392" rx="44" fill="#3C4043"/>
17 |   <rect x="318" y="310" width="178" height="38" rx="19" fill="#FDE293" stroke="#FDE293" stroke-width="6"/>
18 |   <rect x="318" y="380" width="235" height="38" rx="19" fill="#AECBFA" stroke="#AECBFA" stroke-width="6"/>
19 |   <rect x="318" y="450" width="178" height="38" rx="19" fill="white" stroke="white" stroke-width="6"/>
20 |   <rect x="318" y="520" width="178" height="38" rx="19" fill="#F6AEA9" stroke="#F6AEA9" stroke-width="6"/>
21 | </svg>
22 | 


--------------------------------------------------------------------------------
/docs/_static/medication_entity.gif:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/google/langextract/d14c7fd4460b7161a2ea3f10c8836743a0260505/docs/_static/medication_entity.gif


--------------------------------------------------------------------------------
/docs/_static/medication_entity_re.gif:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/google/langextract/d14c7fd4460b7161a2ea3f10c8836743a0260505/docs/_static/medication_entity_re.gif


--------------------------------------------------------------------------------
/docs/_static/romeo_juliet_basic.gif:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/google/langextract/d14c7fd4460b7161a2ea3f10c8836743a0260505/docs/_static/romeo_juliet_basic.gif


--------------------------------------------------------------------------------
/docs/_static/romeo_juliet_full.gif:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/google/langextract/d14c7fd4460b7161a2ea3f10c8836743a0260505/docs/_static/romeo_juliet_full.gif


--------------------------------------------------------------------------------
/examples/custom_provider_plugin/README.md:
--------------------------------------------------------------------------------
  1 | # Custom Provider Plugin Example
  2 | 
  3 | This example demonstrates how to create a custom provider plugin that extends LangExtract with your own model backend.
  4 | 
  5 | **Note**: This is an example included in the LangExtract repository for reference. It is not part of the LangExtract package and won't be installed when you `pip install langextract`.
  6 | 
  7 | **Automated Creation**: Instead of manually copying this example, use the [provider plugin generator script](../../scripts/create_provider_plugin.py):
  8 | ```bash
  9 | python scripts/create_provider_plugin.py MyProvider --with-schema
 10 | ```
 11 | This will create a complete plugin structure with all boilerplate code ready for customization.
 12 | 
 13 | ## Structure
 14 | 
 15 | ```
 16 | custom_provider_plugin/
 17 | ├── pyproject.toml                      # Package configuration and metadata
 18 | ├── README.md                            # This file
 19 | ├── langextract_provider_example/        # Package directory
 20 | │   ├── __init__.py                     # Package initialization
 21 | │   ├── provider.py                     # Custom provider implementation
 22 | │   └── schema.py                       # Custom schema implementation (optional)
 23 | └── test_example_provider.py            # Test script
 24 | ```
 25 | 
 26 | ## Key Components
 27 | 
 28 | ### Provider Implementation (`provider.py`)
 29 | 
 30 | ```python
 31 | @lx.providers.registry.register(
 32 |     r'^gemini',  # Pattern for model IDs this provider handles
 33 | )
 34 | class CustomGeminiProvider(lx.inference.BaseLanguageModel):
 35 |     def __init__(self, model_id: str, **kwargs):
 36 |         # Initialize your backend client
 37 | 
 38 |     def infer(self, batch_prompts, **kwargs):
 39 |         # Call your backend API and return results
 40 | ```
 41 | 
 42 | ### Package Configuration (`pyproject.toml`)
 43 | 
 44 | ```toml
 45 | [project.entry-points."langextract.providers"]
 46 | custom_gemini = "langextract_provider_example:CustomGeminiProvider"
 47 | ```
 48 | 
 49 | This entry point allows LangExtract to automatically discover your provider.
 50 | 
 51 | ### Custom Schema Support (`schema.py`)
 52 | 
 53 | Providers can optionally implement custom schemas for structured output:
 54 | 
 55 | **Flow:** Examples → `from_examples()` → `to_provider_config()` → Provider kwargs → Inference
 56 | 
 57 | ```python
 58 | class CustomProviderSchema(lx.schema.BaseSchema):
 59 |     @classmethod
 60 |     def from_examples(cls, examples_data, attribute_suffix="_attributes"):
 61 |         # Analyze examples to find patterns
 62 |         # Build schema based on extraction classes and attributes seen
 63 |         return cls(schema_dict)
 64 | 
 65 |     def to_provider_config(self):
 66 |         # Convert schema to provider kwargs
 67 |         return {
 68 |             "response_schema": self._schema_dict,
 69 |             "enable_structured_output": True
 70 |         }
 71 | 
 72 |     @property
 73 |     def supports_strict_mode(self):
 74 |         # True = valid JSON output, no markdown fences needed
 75 |         return True
 76 | ```
 77 | 
 78 | Then in your provider:
 79 | 
 80 | ```python
 81 | class CustomProvider(lx.inference.BaseLanguageModel):
 82 |     @classmethod
 83 |     def get_schema_class(cls):
 84 |         return CustomProviderSchema  # Tell LangExtract about your schema
 85 | 
 86 |     def __init__(self, **kwargs):
 87 |         # Receive schema config in kwargs when use_schema_constraints=True
 88 |         self.response_schema = kwargs.get('response_schema')
 89 | 
 90 |     def infer(self, batch_prompts, **kwargs):
 91 |         # Use schema during API calls
 92 |         if self.response_schema:
 93 |             config['response_schema'] = self.response_schema
 94 | ```
 95 | 
 96 | ## Installation
 97 | 
 98 | ```bash
 99 | # Navigate to this example directory first
100 | cd examples/custom_provider_plugin
101 | 
102 | # Install in development mode
103 | pip install -e .
104 | 
105 | # Test the provider (must be run from this directory)
106 | python test_example_provider.py
107 | ```
108 | 
109 | ## Usage
110 | 
111 | Since this example registers the same pattern as the default Gemini provider, you must explicitly specify it:
112 | 
113 | ```python
114 | import langextract as lx
115 | 
116 | # Create a configured model with explicit provider selection
117 | config = lx.factory.ModelConfig(
118 |     model_id="gemini-2.5-flash",
119 |     provider="CustomGeminiProvider",
120 |     provider_kwargs={"api_key": "your-api-key"}
121 | )
122 | model = lx.factory.create_model(config)
123 | 
124 | # Note: Passing model directly to extract() is coming soon.
125 | # For now, use the model's infer() method directly or pass parameters individually:
126 | result = lx.extract(
127 |     text_or_documents="Your text here",
128 |     model_id="gemini-2.5-flash",
129 |     api_key="your-api-key",
130 |     prompt_description="Extract key information",
131 |     examples=[...]
132 | )
133 | 
134 | # Coming soon: Direct model passing
135 | # result = lx.extract(
136 | #     text_or_documents="Your text here",
137 | #     model=model,  # Planned feature
138 | #     prompt_description="Extract key information"
139 | # )
140 | ```
141 | 
142 | ## Creating Your Own Provider - Step by Step
143 | 
144 | ### 1. Copy and Rename
145 | ```bash
146 | # Copy this example directory
147 | cp -r examples/custom_provider_plugin/ ~/langextract-myprovider/
148 | 
149 | # Rename the package directory
150 | cd ~/langextract-myprovider/
151 | mv langextract_provider_example langextract_myprovider
152 | ```
153 | 
154 | ### 2. Update Package Configuration
155 | Edit `pyproject.toml`:
156 | - Change `name = "langextract-myprovider"`
157 | - Update description and author information
158 | - Change entry point: `myprovider = "langextract_myprovider:MyProvider"`
159 | 
160 | ### 3. Modify Provider Implementation
161 | Edit `provider.py`:
162 | - Change class name from `CustomGeminiProvider` to `MyProvider`
163 | - Update `@register()` patterns to match your model IDs
164 | - Replace Gemini API calls with your backend
165 | - Add any provider-specific parameters
166 | 
167 | ### 4. Add Schema Support (Optional)
168 | Edit `schema.py`:
169 | - Rename to `MyProviderSchema`
170 | - Customize `from_examples()` for your extraction format
171 | - Update `to_provider_config()` for your API requirements
172 | - Set `supports_strict_mode` based on your capabilities
173 | 
174 | ### 5. Install and Test
175 | ```bash
176 | # Install in development mode
177 | pip install -e .
178 | 
179 | # Test your provider
180 | python -c "
181 | import langextract as lx
182 | lx.providers.load_plugins_once()
183 | print('Provider registered:', any('myprovider' in str(e) for e in lx.providers.registry.list_entries()))
184 | "
185 | ```
186 | 
187 | ### 6. Write Tests
188 | - Test that your provider loads and handles basic inference
189 | - Verify schema support works (if implemented)
190 | - Test error handling for your specific API
191 | 
192 | ### 7. Publish to PyPI and Share with Community
193 | ```bash
194 | # Build package
195 | python -m build
196 | 
197 | # Upload to PyPI
198 | twine upload dist/*
199 | ```
200 | 
201 | **Share with the community:**
202 | - Open an issue on [LangExtract GitHub](https://github.com/google/langextract/issues) to announce your provider and get feedback
203 | - Consider submitting a PR to add your provider to the community providers list (coming soon)
204 | 
205 | ## Common Pitfalls to Avoid
206 | 
207 | 1. **Forgetting to trigger plugin loading** - Plugins load lazily, use `load_plugins_once()` in tests
208 | 2. **Pattern conflicts** - Avoid patterns that conflict with built-in providers
209 | 3. **Missing dependencies** - List all requirements in `pyproject.toml`
210 | 4. **Schema mismatches** - Test schema generation with real examples
211 | 5. **Not handling None schema** - Provider must clear schema when `apply_schema(None)` is called (see provider.py for implementation)
212 | 
213 | ## License
214 | 
215 | Apache License 2.0
216 | 


--------------------------------------------------------------------------------
/examples/custom_provider_plugin/langextract_provider_example/__init__.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Example custom provider plugin for LangExtract."""
16 | 
17 | from langextract_provider_example.provider import CustomGeminiProvider
18 | 
19 | __all__ = ["CustomGeminiProvider"]
20 | __version__ = "0.1.0"
21 | 


--------------------------------------------------------------------------------
/examples/custom_provider_plugin/langextract_provider_example/provider.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Minimal example of a custom provider plugin for LangExtract."""
 16 | 
 17 | from __future__ import annotations
 18 | 
 19 | import dataclasses
 20 | from typing import Any, Iterator, Sequence
 21 | 
 22 | from langextract_provider_example import schema as custom_schema
 23 | 
 24 | import langextract as lx
 25 | 
 26 | 
 27 | @lx.providers.registry.register(
 28 |     r'^gemini',  # Matches Gemini model IDs (same as default provider)
 29 | )
 30 | @dataclasses.dataclass(init=False)
 31 | class CustomGeminiProvider(lx.inference.BaseLanguageModel):
 32 |   """Example custom LangExtract provider implementation.
 33 | 
 34 |   This demonstrates how to create a custom provider for LangExtract
 35 |   that can intercept and handle model requests. This example wraps
 36 |   the actual Gemini API to show how custom schemas integrate, but you
 37 |   would replace the Gemini calls with your own API or model implementation.
 38 | 
 39 |   Note: Since this registers the same pattern as the default Gemini provider,
 40 |   you must explicitly specify this provider when creating a model:
 41 | 
 42 |   config = lx.factory.ModelConfig(
 43 |       model_id="gemini-2.5-flash",
 44 |       provider="CustomGeminiProvider"
 45 |   )
 46 |   model = lx.factory.create_model(config)
 47 |   """
 48 | 
 49 |   model_id: str
 50 |   api_key: str | None
 51 |   temperature: float
 52 |   response_schema: dict[str, Any] | None = None
 53 |   enable_structured_output: bool = False
 54 |   _client: Any = dataclasses.field(repr=False, compare=False)
 55 | 
 56 |   def __init__(
 57 |       self,
 58 |       model_id: str = 'gemini-2.5-flash',
 59 |       api_key: str | None = None,
 60 |       temperature: float = 0.0,
 61 |       **kwargs: Any,
 62 |   ) -> None:
 63 |     """Initialize the custom provider.
 64 | 
 65 |     Args:
 66 |       model_id: The model ID.
 67 |       api_key: API key for the service.
 68 |       temperature: Sampling temperature.
 69 |       **kwargs: Additional parameters.
 70 |     """
 71 |     super().__init__()
 72 | 
 73 |     # TODO: Replace with your own client initialization
 74 |     try:
 75 |       from google import genai  # pylint: disable=import-outside-toplevel
 76 |     except ImportError as e:
 77 |       raise lx.exceptions.InferenceConfigError(
 78 |           'This example requires google-genai package. '
 79 |           'Install with: pip install google-genai'
 80 |       ) from e
 81 | 
 82 |     self.model_id = model_id
 83 |     self.api_key = api_key
 84 |     self.temperature = temperature
 85 | 
 86 |     # Schema kwargs from CustomProviderSchema.to_provider_config()
 87 |     self.response_schema = kwargs.get('response_schema')
 88 |     self.enable_structured_output = kwargs.get(
 89 |         'enable_structured_output', False
 90 |     )
 91 | 
 92 |     # Store any additional kwargs for potential use
 93 |     self._extra_kwargs = kwargs
 94 | 
 95 |     if not self.api_key:
 96 |       raise lx.exceptions.InferenceConfigError(
 97 |           'API key required. Set GEMINI_API_KEY or pass api_key parameter.'
 98 |       )
 99 | 
100 |     self._client = genai.Client(api_key=self.api_key)
101 | 
102 |   @classmethod
103 |   def get_schema_class(cls) -> type[lx.schema.BaseSchema] | None:
104 |     """Return our custom schema class.
105 | 
106 |     This allows LangExtract to use our custom schema implementation
107 |     when use_schema_constraints=True is specified.
108 | 
109 |     Returns:
110 |       Our custom schema class that will be used to generate constraints.
111 |     """
112 |     return custom_schema.CustomProviderSchema
113 | 
114 |   def apply_schema(self, schema_instance: lx.schema.BaseSchema | None) -> None:
115 |     """Apply or clear schema configuration.
116 | 
117 |     This method is called by LangExtract to dynamically apply schema
118 |     constraints after the provider is instantiated. It's important to
119 |     handle both the application of a new schema and clearing (None).
120 | 
121 |     Args:
122 |       schema_instance: The schema to apply, or None to clear existing schema.
123 |     """
124 |     super().apply_schema(schema_instance)
125 | 
126 |     if schema_instance:
127 |       # Apply the new schema configuration
128 |       config = schema_instance.to_provider_config()
129 |       self.response_schema = config.get('response_schema')
130 |       self.enable_structured_output = config.get(
131 |           'enable_structured_output', False
132 |       )
133 |     else:
134 |       # Clear the schema configuration
135 |       self.response_schema = None
136 |       self.enable_structured_output = False
137 | 
138 |   def infer(
139 |       self, batch_prompts: Sequence[str], **kwargs: Any
140 |   ) -> Iterator[Sequence[lx.inference.ScoredOutput]]:
141 |     """Run inference on a batch of prompts.
142 | 
143 |     Args:
144 |       batch_prompts: Input prompts to process.
145 |       **kwargs: Additional generation parameters.
146 | 
147 |     Yields:
148 |       Lists of ScoredOutputs, one per prompt.
149 |     """
150 |     config = {
151 |         'temperature': kwargs.get('temperature', self.temperature),
152 |     }
153 | 
154 |     # Add other parameters if provided
155 |     for key in ['max_output_tokens', 'top_p', 'top_k']:
156 |       if key in kwargs:
157 |         config[key] = kwargs[key]
158 | 
159 |     # Apply schema constraints if configured
160 |     if self.response_schema and self.enable_structured_output:
161 |       # For Gemini, this ensures the model outputs JSON matching our schema
162 |       # Adapt this section based on your actual provider's API requirements
163 |       config['response_schema'] = self.response_schema
164 |       config['response_mime_type'] = 'application/json'
165 | 
166 |     for prompt in batch_prompts:
167 |       try:
168 |         # TODO: Replace this with your own API/model calls
169 |         response = self._client.models.generate_content(
170 |             model=self.model_id, contents=prompt, config=config
171 |         )
172 |         output = response.text.strip()
173 |         yield [lx.inference.ScoredOutput(score=1.0, output=output)]
174 | 
175 |       except Exception as e:
176 |         raise lx.exceptions.InferenceRuntimeError(
177 |             f'API error: {str(e)}', original=e
178 |         ) from e
179 | 


--------------------------------------------------------------------------------
/examples/custom_provider_plugin/langextract_provider_example/schema.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Example custom schema implementation for provider plugins."""
 16 | 
 17 | from __future__ import annotations
 18 | 
 19 | from typing import Any, Sequence
 20 | 
 21 | import langextract as lx
 22 | 
 23 | 
 24 | class CustomProviderSchema(lx.schema.BaseSchema):
 25 |   """Example custom schema implementation for a provider plugin.
 26 | 
 27 |   This demonstrates how plugins can provide their own schema implementations
 28 |   that integrate with LangExtract's schema system. Custom schemas allow
 29 |   providers to:
 30 | 
 31 |   1. Generate provider-specific constraints from examples
 32 |   2. Control output formatting and validation
 33 |   3. Optimize for their specific model capabilities
 34 | 
 35 |   This example generates a JSON schema from the examples and passes it to
 36 |   the Gemini backend (which this example provider wraps) for structured output.
 37 |   """
 38 | 
 39 |   def __init__(self, schema_dict: dict[str, Any], strict_mode: bool = True):
 40 |     """Initialize the custom schema.
 41 | 
 42 |     Args:
 43 |       schema_dict: The generated JSON schema dictionary.
 44 |       strict_mode: Whether the provider guarantees valid output.
 45 |     """
 46 |     self._schema_dict = schema_dict
 47 |     self._strict_mode = strict_mode
 48 | 
 49 |   @classmethod
 50 |   def from_examples(
 51 |       cls,
 52 |       examples_data: Sequence[lx.data.ExampleData],
 53 |       attribute_suffix: str = "_attributes",
 54 |   ) -> CustomProviderSchema:
 55 |     """Generate schema from example data.
 56 | 
 57 |     This method analyzes the provided examples to build a schema that
 58 |     captures the structure of expected extractions. Called automatically
 59 |     by LangExtract when use_schema_constraints=True.
 60 | 
 61 |     Args:
 62 |       examples_data: Example extractions to learn from.
 63 |       attribute_suffix: Suffix for attribute fields (unused in this example).
 64 | 
 65 |     Returns:
 66 |       A configured CustomProviderSchema instance.
 67 | 
 68 |     Example:
 69 |       If examples contain extractions with class "condition" and attribute
 70 |       "severity", the schema will constrain the model to only output those
 71 |       specific classes and attributes.
 72 |     """
 73 |     extraction_classes = set()
 74 |     attribute_keys = set()
 75 | 
 76 |     for example in examples_data:
 77 |       for extraction in example.extractions:
 78 |         extraction_classes.add(extraction.extraction_class)
 79 |         if extraction.attributes:
 80 |           attribute_keys.update(extraction.attributes.keys())
 81 | 
 82 |     schema_dict = {
 83 |         "type": "object",
 84 |         "properties": {
 85 |             "extractions": {
 86 |                 "type": "array",
 87 |                 "items": {
 88 |                     "type": "object",
 89 |                     "properties": {
 90 |                         "extraction_class": {
 91 |                             "type": "string",
 92 |                             "enum": (
 93 |                                 list(extraction_classes)
 94 |                                 if extraction_classes
 95 |                                 else None
 96 |                             ),
 97 |                         },
 98 |                         "extraction_text": {"type": "string"},
 99 |                         "attributes": {
100 |                             "type": "object",
101 |                             "properties": {
102 |                                 key: {"type": "string"}
103 |                                 for key in attribute_keys
104 |                             },
105 |                         },
106 |                     },
107 |                     "required": ["extraction_class", "extraction_text"],
108 |                 },
109 |             },
110 |         },
111 |         "required": ["extractions"],
112 |     }
113 | 
114 |     # Remove enum if no classes found
115 |     if not extraction_classes:
116 |       del schema_dict["properties"]["extractions"]["items"]["properties"][
117 |           "extraction_class"
118 |       ]["enum"]
119 | 
120 |     return cls(schema_dict, strict_mode=True)
121 | 
122 |   def to_provider_config(self) -> dict[str, Any]:
123 |     """Convert schema to provider-specific configuration.
124 | 
125 |     This is called after from_examples() and returns kwargs that will be
126 |     passed to the provider's __init__ method. The provider can then use
127 |     these during inference.
128 | 
129 |     Returns:
130 |       Dictionary of provider kwargs that will be passed to the model.
131 |       In this example, we return both the schema and a flag to enable
132 |       structured output mode.
133 | 
134 |     Note:
135 |       These kwargs are merged with user-provided kwargs, with user values
136 |       taking precedence (caller-wins merge semantics).
137 |     """
138 |     return {
139 |         "response_schema": self._schema_dict,
140 |         "enable_structured_output": True,
141 |         "output_format": "json",
142 |     }
143 | 
144 |   @property
145 |   def supports_strict_mode(self) -> bool:
146 |     """Whether this schema guarantees valid structured output.
147 | 
148 |     Returns:
149 |       True if the provider will emit valid JSON without needing
150 |       Markdown fences for extraction.
151 |     """
152 |     return self._strict_mode
153 | 
154 |   @property
155 |   def schema_dict(self) -> dict[str, Any]:
156 |     """Access the underlying schema dictionary.
157 | 
158 |     Returns:
159 |       The JSON schema dictionary.
160 |     """
161 |     return self._schema_dict
162 | 


--------------------------------------------------------------------------------
/examples/custom_provider_plugin/pyproject.toml:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | [build-system]
16 | requires = ["setuptools>=61.0"]
17 | build-backend = "setuptools.build_meta"
18 | 
19 | [project]
20 | name = "langextract-provider-example"  # Change to your package name
21 | version = "0.1.0"  # Update version for releases
22 | description = "Example custom provider plugin for LangExtract"
23 | readme = "README.md"
24 | requires-python = ">=3.10"
25 | license = {text = "Apache-2.0"}
26 | dependencies = [
27 |     # Uncomment when creating a standalone plugin package:
28 |     # "langextract",  # Will install latest version
29 |     "google-genai>=0.2.0",  # Replace with your backend's SDK
30 | ]
31 | 
32 | # Register the provider with LangExtract's plugin system
33 | [project.entry-points."langextract.providers"]
34 | custom_gemini = "langextract_provider_example:CustomGeminiProvider"
35 | 
36 | [tool.setuptools.packages.find]
37 | where = ["."]
38 | include = ["langextract_provider_example*"]
39 | 


--------------------------------------------------------------------------------
/examples/custom_provider_plugin/test_example_provider.py:
--------------------------------------------------------------------------------
 1 | #!/usr/bin/env python3
 2 | # Copyright 2025 Google LLC.
 3 | #
 4 | # Licensed under the Apache License, Version 2.0 (the "License");
 5 | # you may not use this file except in compliance with the License.
 6 | # You may obtain a copy of the License at
 7 | #
 8 | #     http://www.apache.org/licenses/LICENSE-2.0
 9 | #
10 | # Unless required by applicable law or agreed to in writing, software
11 | # distributed under the License is distributed on an "AS IS" BASIS,
12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13 | # See the License for the specific language governing permissions and
14 | # limitations under the License.
15 | 
16 | """Simple test for the custom provider plugin."""
17 | 
18 | import os
19 | 
20 | # Import the provider to trigger registration with LangExtract
21 | # Note: This manual import is only needed when running without installation.
22 | # After `pip install -e .`, the entry point system handles this automatically.
23 | from langextract_provider_example import CustomGeminiProvider  # noqa: F401
24 | 
25 | import langextract as lx
26 | 
27 | 
28 | def main():
29 |   """Test the custom provider."""
30 |   api_key = os.getenv("GEMINI_API_KEY") or os.getenv("LANGEXTRACT_API_KEY")
31 | 
32 |   if not api_key:
33 |     print("Set GEMINI_API_KEY or LANGEXTRACT_API_KEY to test")
34 |     return
35 | 
36 |   config = lx.factory.ModelConfig(
37 |       model_id="gemini-2.5-flash",
38 |       provider="CustomGeminiProvider",
39 |       provider_kwargs={"api_key": api_key},
40 |   )
41 |   model = lx.factory.create_model(config)
42 | 
43 |   print(f"✓ Created {model.__class__.__name__}")
44 | 
45 |   # Test inference
46 |   prompts = ["Say hello"]
47 |   results = list(model.infer(prompts))
48 | 
49 |   if results and results[0]:
50 |     print(f"✓ Inference worked: {results[0][0].output[:50]}...")
51 |   else:
52 |     print("✗ No response")
53 | 
54 | 
55 | if __name__ == "__main__":
56 |   main()
57 | 


--------------------------------------------------------------------------------
/examples/ollama/.dockerignore:
--------------------------------------------------------------------------------
 1 | # Ignore Python cache
 2 | __pycache__/
 3 | *.pyc
 4 | *.pyo
 5 | *.pyd
 6 | .Python
 7 | 
 8 | # Ignore version control
 9 | .git/
10 | .gitignore
11 | 
12 | # Ignore OS files
13 | .DS_Store
14 | Thumbs.db
15 | 
16 | # Ignore virtual environments
17 | venv/
18 | env/
19 | .venv/
20 | 
21 | # Ignore IDE files
22 | .vscode/
23 | .idea/
24 | *.swp
25 | *.swo
26 | 
27 | # Ignore test artifacts
28 | .pytest_cache/
29 | .coverage
30 | htmlcov/
31 | 
32 | # Ignore build artifacts
33 | build/
34 | dist/
35 | *.egg-info/
36 | 


--------------------------------------------------------------------------------
/examples/ollama/Dockerfile:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | FROM python:3.11-slim-bookworm
16 | 
17 | WORKDIR /app
18 | 
19 | RUN pip install langextract
20 | 
21 | COPY quickstart.py .
22 | 
23 | CMD ["python", "quickstart.py"]
24 | 


--------------------------------------------------------------------------------
/examples/ollama/README.md:
--------------------------------------------------------------------------------
 1 | # Ollama Examples
 2 | 
 3 | This directory contains examples for using LangExtract with Ollama for local LLM inference.
 4 | 
 5 | For setup instructions and documentation, see the [main README's Ollama section](../../README.md#using-local-llms-with-ollama).
 6 | 
 7 | ## Quick Reference
 8 | 
 9 | **Local setup:**
10 | ```bash
11 | ollama pull gemma2:2b
12 | python quickstart.py
13 | ```
14 | 
15 | **Docker setup:**
16 | ```bash
17 | docker-compose up
18 | ```
19 | 
20 | ## Files
21 | 
22 | - `quickstart.py` - Basic extraction example with configurable model
23 | - `docker-compose.yml` - Production-ready Docker setup with health checks
24 | - `Dockerfile` - Container definition for LangExtract
25 | 
26 | ## Configuration Options
27 | 
28 | ### Timeout Settings
29 | 
30 | For slower models or large prompts, you may need to increase the timeout (default: 120 seconds):
31 | 
32 | ```python
33 | import langextract as lx
34 | 
35 | result = lx.extract(
36 |     text_or_documents=input_text,
37 |     prompt_description=prompt,
38 |     examples=examples,
39 |     model_id="llama3.1:70b",  # Larger model may need more time
40 |     timeout=300,  # 5 minutes
41 |     model_url="http://localhost:11434",
42 | )
43 | ```
44 | 
45 | Or using ModelConfig:
46 | 
47 | ```python
48 | config = lx.factory.ModelConfig(
49 |     model_id="llama3.1:70b",
50 |     provider_kwargs={
51 |         "model_url": "http://localhost:11434",
52 |         "timeout": 300,  # 5 minutes
53 |     }
54 | )
55 | ```
56 | 
57 | ## Model License
58 | 
59 | Ollama models come with their own licenses. For example:
60 | - Gemma models: [Gemma Terms of Use](https://ai.google.dev/gemma/terms)
61 | - Llama models: [Meta Llama License](https://llama.meta.com/llama-downloads/)
62 | 
63 | Please review the license for any model you use.
64 | 


--------------------------------------------------------------------------------
/examples/ollama/docker-compose.yml:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | services:
16 |   ollama:
17 |     image: ollama/ollama:0.5.4
18 |     ports:
19 |       - "127.0.0.1:11434:11434"  # Bind only to localhost for security
20 |     volumes:
21 |       - ollama-data:/root/.ollama  # Cross-platform support
22 |     command: serve
23 |     healthcheck:
24 |       test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
25 |       interval: 5s
26 |       timeout: 3s
27 |       retries: 5
28 |       start_period: 10s
29 | 
30 |   langextract:
31 |     build: .
32 |     depends_on:
33 |       ollama:
34 |         condition: service_healthy
35 |     environment:
36 |       - OLLAMA_HOST=http://ollama:11434
37 |     volumes:
38 |       - .:/app
39 |     command: python quickstart.py
40 | 
41 | volumes:
42 |   ollama-data:
43 | 


--------------------------------------------------------------------------------
/examples/ollama/quickstart.py:
--------------------------------------------------------------------------------
  1 | #!/usr/bin/env python3
  2 | # Copyright 2025 Google LLC.
  3 | #
  4 | # Licensed under the Apache License, Version 2.0 (the "License");
  5 | # you may not use this file except in compliance with the License.
  6 | # You may obtain a copy of the License at
  7 | #
  8 | #     http://www.apache.org/licenses/LICENSE-2.0
  9 | #
 10 | # Unless required by applicable law or agreed to in writing, software
 11 | # distributed under the License is distributed on an "AS IS" BASIS,
 12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 13 | # See the License for the specific language governing permissions and
 14 | # limitations under the License.
 15 | 
 16 | """Quick-start example for using Ollama with langextract."""
 17 | 
 18 | import argparse
 19 | import os
 20 | import sys
 21 | 
 22 | import langextract as lx
 23 | 
 24 | 
 25 | def run_extraction(model_id="gemma2:2b", temperature=0.3):
 26 |   """Run a simple extraction example using Ollama."""
 27 |   input_text = "Isaac Asimov was a prolific science fiction writer."
 28 | 
 29 |   prompt = "Extract the author's full name and their primary literary genre."
 30 | 
 31 |   examples = [
 32 |       lx.data.ExampleData(
 33 |           text=(
 34 |               "J.R.R. Tolkien was an English writer, best known for"
 35 |               " high-fantasy."
 36 |           ),
 37 |           extractions=[
 38 |               lx.data.Extraction(
 39 |                   extraction_class="author_details",
 40 |                   extraction_text=(
 41 |                       "J.R.R. Tolkien was an English writer, best known for"
 42 |                       " high-fantasy."
 43 |                   ),
 44 |                   attributes={
 45 |                       "name": "J.R.R. Tolkien",
 46 |                       "genre": "high-fantasy",
 47 |                   },
 48 |               )
 49 |           ],
 50 |       )
 51 |   ]
 52 | 
 53 |   model_config = lx.factory.ModelConfig(
 54 |       model_id=model_id,
 55 |       provider_kwargs={
 56 |           "model_url": os.getenv("OLLAMA_HOST", "http://localhost:11434"),
 57 |           "format_type": lx.data.FormatType.JSON,
 58 |           "temperature": temperature,
 59 |       },
 60 |   )
 61 | 
 62 |   result = lx.extract(
 63 |       text_or_documents=input_text,
 64 |       prompt_description=prompt,
 65 |       examples=examples,
 66 |       config=model_config,
 67 |       use_schema_constraints=True,
 68 |   )
 69 | 
 70 |   # Option 2: Pass model_id directly (simpler)
 71 |   # result = lx.extract(
 72 |   #     text_or_documents=input_text,
 73 |   #     prompt_description=prompt,
 74 |   #     examples=examples,
 75 |   #     model_id=model_id,
 76 |   #     model_url=os.getenv("OLLAMA_HOST", "http://localhost:11434"),
 77 |   #     format_type=lx.data.FormatType.JSON,
 78 |   #     temperature=temperature,
 79 |   #     use_schema_constraints=True,
 80 |   # )
 81 | 
 82 |   return result
 83 | 
 84 | 
 85 | def main():
 86 |   """Main function to run the quick-start example."""
 87 |   parser = argparse.ArgumentParser(
 88 |       description="Run Ollama extraction example",
 89 |       epilog=(
 90 |           "Supported models: gemma2:2b, llama3.2:1b, mistral:7b, qwen2.5:0.5b,"
 91 |           " etc."
 92 |       ),
 93 |   )
 94 |   parser.add_argument(
 95 |       "--model-id",
 96 |       default=os.getenv("MODEL_ID", "gemma2:2b"),
 97 |       help="Ollama model ID (default: gemma2:2b or MODEL_ID env var)",
 98 |   )
 99 |   parser.add_argument(
100 |       "--temperature",
101 |       type=float,
102 |       default=float(os.getenv("TEMPERATURE", "0.3")),
103 |       help="Model temperature (default: 0.3 or TEMPERATURE env var)",
104 |   )
105 |   args = parser.parse_args()
106 | 
107 |   print(f"🚀 Running Ollama quick-start example with {args.model_id}...")
108 |   print("-" * 50)
109 | 
110 |   try:
111 |     result = run_extraction(
112 |         model_id=args.model_id, temperature=args.temperature
113 |     )
114 | 
115 |     if result.extractions:
116 |       print(f"\n📝 Found {len(result.extractions)} extraction(s):\n")
117 |       for extraction in result.extractions:
118 |         print(f"Class: {extraction.extraction_class}")
119 |         print(f"Text: {extraction.extraction_text}")
120 |         print(f"Attributes: {extraction.attributes}")
121 |         print()
122 |     else:
123 |       print("\n⚠️  No extractions found")
124 | 
125 |     print("✅ SUCCESS! Ollama is working with langextract")
126 |     print(f"   Model: {args.model_id}")
127 |     print("   JSON mode: enabled")
128 |     print("   Schema constraints: enabled")
129 |     return True
130 | 
131 |   except ConnectionError as e:
132 |     print(f"\n❌ ConnectionError: {e}")
133 |     print("\n💡 Make sure Ollama is running:")
134 |     print("   ollama serve")
135 |     return False
136 |   except ValueError as e:
137 |     if "Can't find Ollama" in str(e):
138 |       print(f"\n❌ Model not found: {args.model_id}")
139 |       print("\n💡 Install the model first:")
140 |       print(f"   ollama pull {args.model_id}")
141 |     else:
142 |       print(f"\n❌ ValueError: {e}")
143 |     return False
144 |   except Exception as e:
145 |     print(f"\n❌ Error: {type(e).__name__}: {e}")
146 |     return False
147 | 
148 | 
149 | if __name__ == "__main__":
150 |   SUCCESS = main()
151 |   sys.exit(0 if SUCCESS else 1)
152 | 


--------------------------------------------------------------------------------
/langextract/__init__.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """LangExtract: Extract structured information from text with LLMs.
 16 | 
 17 | This package provides the main extract and visualize functions,
 18 | with lazy loading for other submodules accessed via attribute access.
 19 | """
 20 | 
 21 | from __future__ import annotations
 22 | 
 23 | import importlib
 24 | import sys
 25 | from typing import Any, Dict
 26 | 
 27 | from langextract import visualization
 28 | from langextract.extraction import extract as extract_func
 29 | 
 30 | __all__ = [
 31 |     # Public convenience functions (thin wrappers)
 32 |     "extract",
 33 |     "visualize",
 34 |     # Submodules exposed lazily on attribute access for ergonomics:
 35 |     "annotation",
 36 |     "data",
 37 |     "providers",
 38 |     "schema",
 39 |     "inference",
 40 |     "factory",
 41 |     "resolver",
 42 |     "prompting",
 43 |     "io",
 44 |     "visualization",
 45 |     "exceptions",
 46 |     "core",
 47 |     "plugins",
 48 | ]
 49 | 
 50 | _CACHE: Dict[str, Any] = {}
 51 | 
 52 | 
 53 | def extract(*args: Any, **kwargs: Any):
 54 |   """Top-level API: lx.extract(...)."""
 55 |   return extract_func(*args, **kwargs)
 56 | 
 57 | 
 58 | def visualize(*args: Any, **kwargs: Any):
 59 |   """Top-level API: lx.visualize(...)."""
 60 |   return visualization.visualize(*args, **kwargs)
 61 | 
 62 | 
 63 | # PEP 562 lazy loading
 64 | _LAZY_MODULES = {
 65 |     "annotation": "langextract.annotation",
 66 |     "chunking": "langextract.chunking",
 67 |     "data": "langextract.data",
 68 |     "data_lib": "langextract.data_lib",
 69 |     "debug_utils": "langextract.debug_utils",
 70 |     "exceptions": "langextract.exceptions",
 71 |     "factory": "langextract.factory",
 72 |     "inference": "langextract.inference",
 73 |     "io": "langextract.io",
 74 |     "progress": "langextract.progress",
 75 |     "prompting": "langextract.prompting",
 76 |     "providers": "langextract.providers",
 77 |     "resolver": "langextract.resolver",
 78 |     "schema": "langextract.schema",
 79 |     "tokenizer": "langextract.tokenizer",
 80 |     "visualization": "langextract.visualization",
 81 |     "core": "langextract.core",
 82 |     "plugins": "langextract.plugins",
 83 |     "registry": "langextract.registry",  # Backward compat - will emit warning
 84 | }
 85 | 
 86 | 
 87 | def __getattr__(name: str) -> Any:
 88 |   if name in _CACHE:
 89 |     return _CACHE[name]
 90 |   modpath = _LAZY_MODULES.get(name)
 91 |   if modpath is None:
 92 |     raise AttributeError(f"module {__name__!r} has no attribute {name!r}")
 93 |   module = importlib.import_module(modpath)
 94 |   # ensure future 'import langextract.<name>' returns the same module
 95 |   sys.modules[f"{__name__}.{name}"] = module
 96 |   setattr(sys.modules[__name__], name, module)
 97 |   _CACHE[name] = module
 98 |   return module
 99 | 
100 | 
101 | def __dir__():
102 |   return sorted(__all__)
103 | 


--------------------------------------------------------------------------------
/langextract/_compat/README.md:
--------------------------------------------------------------------------------
 1 | # Backward Compatibility Layer
 2 | 
 3 | This directory contains backward compatibility shims for deprecated imports.
 4 | 
 5 | ## Deprecation Timeline
 6 | 
 7 | All code in this directory will be removed in LangExtract v2.0.0.
 8 | 
 9 | ## Migration Guide
10 | 
11 | The following imports are deprecated and should be updated:
12 | 
13 | ### Inference Module
14 | - `from langextract.inference import BaseLanguageModel` → `from langextract.core.base_model import BaseLanguageModel`
15 | - `from langextract.inference import ScoredOutput` → `from langextract.core.types import ScoredOutput`
16 | - `from langextract.inference import InferenceOutputError` → `from langextract.core.exceptions import InferenceOutputError`
17 | - `from langextract.inference import GeminiLanguageModel` → `from langextract.providers.gemini import GeminiLanguageModel`
18 | - `from langextract.inference import OpenAILanguageModel` → `from langextract.providers.openai import OpenAILanguageModel`
19 | - `from langextract.inference import OllamaLanguageModel` → `from langextract.providers.ollama import OllamaLanguageModel`
20 | 
21 | ### Schema Module
22 | - `from langextract.schema import BaseSchema` → `from langextract.core.schema import BaseSchema`
23 | - `from langextract.schema import Constraint` → `from langextract.core.schema import Constraint`
24 | - `from langextract.schema import ConstraintType` → `from langextract.core.schema import ConstraintType`
25 | - `from langextract.schema import EXTRACTIONS_KEY` → `from langextract.core.schema import EXTRACTIONS_KEY`
26 | - `from langextract.schema import GeminiSchema` → `from langextract.providers.schemas.gemini import GeminiSchema`
27 | 
28 | ### Exceptions Module
29 | - All exceptions: `from langextract.exceptions import *` → `from langextract.core.exceptions import *`
30 | 
31 | ### Registry Module
32 | - `from langextract.registry import *` → `from langextract.plugins import *`
33 | - `from langextract.providers.registry import *` → `from langextract.providers.router import *`
34 | 
35 | ## For Contributors
36 | 
37 | Do not add new code to this directory. All new development should use the canonical imports from `core/` and `providers/`.
38 | 


--------------------------------------------------------------------------------
/langextract/_compat/__init__.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Backward compatibility layer for LangExtract.
16 | 
17 | This package contains compatibility shims for deprecated imports. All code
18 | in this directory will be removed in v2.0.0.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | __all__ = ["inference", "schema", "exceptions", "registry"]
24 | 


--------------------------------------------------------------------------------
/langextract/_compat/exceptions.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.exceptions imports."""
16 | # pylint: disable=duplicate-code
17 | 
18 | from __future__ import annotations
19 | 
20 | import warnings
21 | 
22 | from langextract.core import exceptions
23 | 
24 | 
25 | # Re-export exceptions from core.exceptions with a warning-on-first-access
26 | def __getattr__(name: str):
27 |   allowed = {
28 |       "LangExtractError",
29 |       "InferenceError",
30 |       "InferenceConfigError",
31 |       "InferenceRuntimeError",
32 |       "InferenceOutputError",
33 |       "ProviderError",
34 |       "SchemaError",
35 |   }
36 |   if name in allowed:
37 |     warnings.warn(
38 |         "`langextract.exceptions` is deprecated; import from"
39 |         " `langextract.core.exceptions`.",
40 |         FutureWarning,
41 |         stacklevel=2,
42 |     )
43 |     return getattr(exceptions, name)
44 |   raise AttributeError(name)
45 | 


--------------------------------------------------------------------------------
/langextract/_compat/inference.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.inference imports."""
16 | 
17 | from __future__ import annotations
18 | 
19 | import enum
20 | import warnings
21 | 
22 | 
23 | class InferenceType(enum.Enum):
24 |   """Enum for inference types - kept for backward compatibility."""
25 | 
26 |   ITERATIVE = "iterative"
27 |   MULTIPROCESS = "multiprocess"
28 | 
29 | 
30 | def __getattr__(name: str):
31 |   moved = {
32 |       "BaseLanguageModel": ("langextract.core.base_model", "BaseLanguageModel"),
33 |       "ScoredOutput": ("langextract.core.types", "ScoredOutput"),
34 |       "InferenceOutputError": (
35 |           "langextract.core.exceptions",
36 |           "InferenceOutputError",
37 |       ),
38 |       "GeminiLanguageModel": (
39 |           "langextract.providers.gemini",
40 |           "GeminiLanguageModel",
41 |       ),
42 |       "OpenAILanguageModel": (
43 |           "langextract.providers.openai",
44 |           "OpenAILanguageModel",
45 |       ),
46 |       "OllamaLanguageModel": (
47 |           "langextract.providers.ollama",
48 |           "OllamaLanguageModel",
49 |       ),
50 |   }
51 |   if name in moved:
52 |     mod, attr = moved[name]
53 |     warnings.warn(
54 |         f"`langextract.inference.{name}` is deprecated and will be removed in"
55 |         f" v2.0.0; use `{mod}.{attr}` instead.",
56 |         FutureWarning,
57 |         stacklevel=2,
58 |     )
59 |     module = __import__(mod, fromlist=[attr])
60 |     return getattr(module, attr)
61 |   raise AttributeError(name)
62 | 


--------------------------------------------------------------------------------
/langextract/_compat/registry.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.registry imports."""
16 | # pylint: disable=duplicate-code
17 | 
18 | from __future__ import annotations
19 | 
20 | import warnings
21 | 
22 | from langextract import plugins
23 | 
24 | 
25 | def __getattr__(name: str):
26 |   """Forward to plugins module with deprecation warning."""
27 |   warnings.warn(
28 |       "`langextract.registry` is deprecated and will be removed in v2.0.0; "
29 |       "use `langextract.plugins` instead.",
30 |       FutureWarning,
31 |       stacklevel=2,
32 |   )
33 |   return getattr(plugins, name)
34 | 


--------------------------------------------------------------------------------
/langextract/_compat/schema.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.schema imports."""
16 | # pylint: disable=duplicate-code
17 | 
18 | from __future__ import annotations
19 | 
20 | import warnings
21 | 
22 | 
23 | def __getattr__(name: str):
24 |   moved = {
25 |       "BaseSchema": ("langextract.core.schema", "BaseSchema"),
26 |       "Constraint": ("langextract.core.schema", "Constraint"),
27 |       "ConstraintType": ("langextract.core.schema", "ConstraintType"),
28 |       "EXTRACTIONS_KEY": ("langextract.core.schema", "EXTRACTIONS_KEY"),
29 |       "GeminiSchema": ("langextract.providers.schemas.gemini", "GeminiSchema"),
30 |   }
31 |   if name in moved:
32 |     mod, attr = moved[name]
33 |     warnings.warn(
34 |         f"`langextract.schema.{name}` is deprecated and will be removed in"
35 |         f" v2.0.0; use `{mod}.{attr}` instead.",
36 |         FutureWarning,
37 |         stacklevel=2,
38 |     )
39 |     module = __import__(mod, fromlist=[attr])
40 |     return getattr(module, attr)
41 |   raise AttributeError(name)
42 | 


--------------------------------------------------------------------------------
/langextract/core/__init__.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Core abstractions for LangExtract.
16 | 
17 | This package contains the foundational base models and types used throughout
18 | LangExtract. Each module can be imported independently for fine-grained
19 | dependency management in build systems.
20 | """
21 | 
22 | from __future__ import annotations
23 | 
24 | __all__ = [
25 |     "base_model",
26 |     "types",
27 |     "exceptions",
28 |     "schema",
29 |     "data",
30 |     "tokenizer",
31 | ]
32 | 


--------------------------------------------------------------------------------
/langextract/core/base_model.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Base interfaces for language models."""
 16 | from __future__ import annotations
 17 | 
 18 | import abc
 19 | from collections.abc import Iterator, Sequence
 20 | import json
 21 | from typing import Any, Mapping
 22 | 
 23 | import yaml
 24 | 
 25 | from langextract.core import types
 26 | 
 27 | __all__ = ['BaseLanguageModel']
 28 | 
 29 | 
 30 | class BaseLanguageModel(abc.ABC):
 31 |   """An abstract inference class for managing LLM inference.
 32 | 
 33 |   Attributes:
 34 |     _constraint: A `Constraint` object specifying constraints for model output.
 35 |   """
 36 | 
 37 |   def __init__(self, constraint: types.Constraint | None = None, **kwargs: Any):
 38 |     """Initializes the BaseLanguageModel with an optional constraint.
 39 | 
 40 |     Args:
 41 |       constraint: Applies constraints when decoding the output. Defaults to no
 42 |         constraint.
 43 |       **kwargs: Additional keyword arguments passed to the model.
 44 |     """
 45 |     self._constraint = constraint or types.Constraint()
 46 |     self._schema: Any = None  # BaseSchema instance
 47 |     self._fence_output_override: bool | None = None
 48 |     self._extra_kwargs: dict[str, Any] = kwargs.copy()
 49 | 
 50 |   @classmethod
 51 |   def get_schema_class(cls) -> type[Any] | None:
 52 |     """Return the schema class this provider supports."""
 53 |     return None
 54 | 
 55 |   def apply_schema(self, schema_instance: Any) -> None:
 56 |     """Apply a schema instance to this provider.
 57 | 
 58 |     Optional method that providers can override to store the schema instance
 59 |     for runtime use. The default implementation stores it as _schema.
 60 | 
 61 |     Args:
 62 |       schema_instance: The schema instance to apply, or None to clear.
 63 |     """
 64 |     self._schema = schema_instance
 65 | 
 66 |   def set_fence_output(self, fence_output: bool | None) -> None:
 67 |     """Set explicit fence output preference.
 68 | 
 69 |     Args:
 70 |       fence_output: True to force fences, False to disable, None for auto.
 71 |     """
 72 |     if not hasattr(self, '_fence_output_override'):
 73 |       self._fence_output_override = None
 74 |     self._fence_output_override = fence_output
 75 | 
 76 |   @property
 77 |   def requires_fence_output(self) -> bool:
 78 |     """Whether this model requires fence output for parsing.
 79 | 
 80 |     Uses explicit override if set, otherwise computes from schema.
 81 |     Returns True if no schema or schema doesn't support strict mode.
 82 |     """
 83 |     if (
 84 |         hasattr(self, '_fence_output_override')
 85 |         and self._fence_output_override is not None
 86 |     ):
 87 |       return self._fence_output_override
 88 |     if not hasattr(self, '_schema') or self._schema is None:
 89 |       return True
 90 |     return not self._schema.supports_strict_mode
 91 | 
 92 |   def merge_kwargs(
 93 |       self, runtime_kwargs: Mapping[str, Any] | None = None
 94 |   ) -> dict[str, Any]:
 95 |     """Merge stored extra kwargs with runtime kwargs.
 96 | 
 97 |     Runtime kwargs take precedence over stored kwargs.
 98 | 
 99 |     Args:
100 |       runtime_kwargs: Kwargs provided at inference time, or None.
101 | 
102 |     Returns:
103 |       Merged kwargs dictionary.
104 |     """
105 |     base = getattr(self, '_extra_kwargs', {}) or {}
106 |     incoming = dict(runtime_kwargs or {})
107 |     return {**base, **incoming}
108 | 
109 |   @abc.abstractmethod
110 |   def infer(
111 |       self, batch_prompts: Sequence[str], **kwargs
112 |   ) -> Iterator[Sequence[types.ScoredOutput]]:
113 |     """Implements language model inference.
114 | 
115 |     Args:
116 |       batch_prompts: Batch of inputs for inference. Single element list can be
117 |         used for a single input.
118 |       **kwargs: Additional arguments for inference, like temperature and
119 |         max_decode_steps.
120 | 
121 |     Returns: Batch of Sequence of probable output text outputs, sorted by
122 |       descending score.
123 |     """
124 | 
125 |   def infer_batch(
126 |       self, prompts: Sequence[str], batch_size: int = 32  # pylint: disable=unused-argument
127 |   ) -> list[list[types.ScoredOutput]]:
128 |     """Batch inference with configurable batch size.
129 | 
130 |     This is a convenience method that collects all results from infer().
131 | 
132 |     Args:
133 |       prompts: List of prompts to process.
134 |       batch_size: Batch size (currently unused, for future optimization).
135 | 
136 |     Returns:
137 |       List of lists of ScoredOutput objects.
138 |     """
139 |     results = []
140 |     for output in self.infer(prompts):
141 |       results.append(list(output))
142 |     return results
143 | 
144 |   def parse_output(self, output: str) -> Any:
145 |     """Parses model output as JSON or YAML.
146 | 
147 |     Note: This expects raw JSON/YAML without code fences.
148 |     Code fence extraction is handled by resolver.py.
149 | 
150 |     Args:
151 |       output: Raw output string from the model.
152 | 
153 |     Returns:
154 |       Parsed Python object (dict or list).
155 | 
156 |     Raises:
157 |       ValueError: If output cannot be parsed as JSON or YAML.
158 |     """
159 |     # Check if we have a format_type attribute (providers should set this)
160 |     format_type = getattr(self, 'format_type', types.FormatType.JSON)
161 | 
162 |     try:
163 |       if format_type == types.FormatType.JSON:
164 |         return json.loads(output)
165 |       else:
166 |         return yaml.safe_load(output)
167 |     except Exception as e:
168 |       raise ValueError(
169 |           f'Failed to parse output as {format_type.name}: {str(e)}'
170 |       ) from e
171 | 


--------------------------------------------------------------------------------
/langextract/core/data.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Classes used to represent core data types of annotation pipeline."""
 16 | from __future__ import annotations
 17 | 
 18 | import dataclasses
 19 | import enum
 20 | import uuid
 21 | 
 22 | from langextract.core import tokenizer
 23 | from langextract.core import types
 24 | 
 25 | FormatType = types.FormatType  # Backward compat
 26 | 
 27 | 
 28 | class AlignmentStatus(enum.Enum):
 29 |   MATCH_EXACT = "match_exact"
 30 |   MATCH_GREATER = "match_greater"
 31 |   MATCH_LESSER = "match_lesser"
 32 |   MATCH_FUZZY = "match_fuzzy"
 33 | 
 34 | 
 35 | @dataclasses.dataclass
 36 | class CharInterval:
 37 |   """Class for representing a character interval.
 38 | 
 39 |   Attributes:
 40 |     start_pos: The starting position of the interval (inclusive).
 41 |     end_pos: The ending position of the interval (exclusive).
 42 |   """
 43 | 
 44 |   start_pos: int | None = None
 45 |   end_pos: int | None = None
 46 | 
 47 | 
 48 | @dataclasses.dataclass(init=False)
 49 | class Extraction:
 50 |   """Represents an extraction extracted from text.
 51 | 
 52 |   This class encapsulates an extraction's characteristics and its position
 53 |   within the source text. It can represent a diverse range of information for
 54 |   NLP information extraction tasks.
 55 | 
 56 |   Attributes:
 57 |     extraction_class: The class of the extraction.
 58 |     extraction_text: The text of the extraction.
 59 |     char_interval: The character interval of the extraction in the original
 60 |       text.
 61 |     alignment_status: The alignment status of the extraction.
 62 |     extraction_index: The index of the extraction in the list of extractions.
 63 |     group_index: The index of the group the extraction belongs to.
 64 |     description: A description of the extraction.
 65 |     attributes: A list of attributes of the extraction.
 66 |     token_interval: The token interval of the extraction.
 67 |   """
 68 | 
 69 |   extraction_class: str
 70 |   extraction_text: str
 71 |   char_interval: CharInterval | None = None
 72 |   alignment_status: AlignmentStatus | None = None
 73 |   extraction_index: int | None = None
 74 |   group_index: int | None = None
 75 |   description: str | None = None
 76 |   attributes: dict[str, str | list[str]] | None = None
 77 |   _token_interval: tokenizer.TokenInterval | None = dataclasses.field(
 78 |       default=None, repr=False, compare=False
 79 |   )
 80 | 
 81 |   def __init__(
 82 |       self,
 83 |       extraction_class: str,
 84 |       extraction_text: str,
 85 |       *,
 86 |       token_interval: tokenizer.TokenInterval | None = None,
 87 |       char_interval: CharInterval | None = None,
 88 |       alignment_status: AlignmentStatus | None = None,
 89 |       extraction_index: int | None = None,
 90 |       group_index: int | None = None,
 91 |       description: str | None = None,
 92 |       attributes: dict[str, str | list[str]] | None = None,
 93 |   ):
 94 |     self.extraction_class = extraction_class
 95 |     self.extraction_text = extraction_text
 96 |     self.char_interval = char_interval
 97 |     self._token_interval = token_interval
 98 |     self.alignment_status = alignment_status
 99 |     self.extraction_index = extraction_index
100 |     self.group_index = group_index
101 |     self.description = description
102 |     self.attributes = attributes
103 | 
104 |   @property
105 |   def token_interval(self) -> tokenizer.TokenInterval | None:
106 |     return self._token_interval
107 | 
108 |   @token_interval.setter
109 |   def token_interval(self, value: tokenizer.TokenInterval | None) -> None:
110 |     self._token_interval = value
111 | 
112 | 
113 | @dataclasses.dataclass
114 | class Document:
115 |   """Document class for annotating documents.
116 | 
117 |   Attributes:
118 |     text: Raw text representation for the document.
119 |     document_id: Unique identifier for each document and is auto-generated if
120 |       not set.
121 |     additional_context: Additional context to supplement prompt instructions.
122 |     tokenized_text: Tokenized text for the document, computed from `text`.
123 |   """
124 | 
125 |   text: str
126 |   additional_context: str | None = None
127 |   _document_id: str | None = dataclasses.field(
128 |       default=None, init=False, repr=False, compare=False
129 |   )
130 |   _tokenized_text: tokenizer.TokenizedText | None = dataclasses.field(
131 |       init=False, default=None, repr=False, compare=False
132 |   )
133 | 
134 |   def __init__(
135 |       self,
136 |       text: str,
137 |       *,
138 |       document_id: str | None = None,
139 |       additional_context: str | None = None,
140 |   ):
141 |     self.text = text
142 |     self.additional_context = additional_context
143 |     self._document_id = document_id
144 | 
145 |   @property
146 |   def document_id(self) -> str:
147 |     """Returns the document ID, generating a unique one if not set."""
148 |     if self._document_id is None:
149 |       self._document_id = f"doc_{uuid.uuid4().hex[:8]}"
150 |     return self._document_id
151 | 
152 |   @document_id.setter
153 |   def document_id(self, value: str | None) -> None:
154 |     """Sets the document ID."""
155 |     self._document_id = value
156 | 
157 |   @property
158 |   def tokenized_text(self) -> tokenizer.TokenizedText:
159 |     if self._tokenized_text is None:
160 |       self._tokenized_text = tokenizer.tokenize(self.text)
161 |     return self._tokenized_text
162 | 
163 |   @tokenized_text.setter
164 |   def tokenized_text(self, value: tokenizer.TokenizedText) -> None:
165 |     self._tokenized_text = value
166 | 
167 | 
168 | @dataclasses.dataclass
169 | class AnnotatedDocument:
170 |   """Class for representing annotated documents.
171 | 
172 |   Attributes:
173 |     document_id: Unique identifier for each document - autogenerated if not
174 |       set.
175 |     extractions: List of extractions in the document.
176 |     text: Raw text representation of the document.
177 |     tokenized_text: Tokenized text of the document, computed from `text`.
178 |   """
179 | 
180 |   extractions: list[Extraction] | None = None
181 |   text: str | None = None
182 |   _document_id: str | None = dataclasses.field(
183 |       default=None, init=False, repr=False, compare=False
184 |   )
185 |   _tokenized_text: tokenizer.TokenizedText | None = dataclasses.field(
186 |       init=False, default=None, repr=False, compare=False
187 |   )
188 | 
189 |   def __init__(
190 |       self,
191 |       *,
192 |       document_id: str | None = None,
193 |       extractions: list[Extraction] | None = None,
194 |       text: str | None = None,
195 |   ):
196 |     self.extractions = extractions
197 |     self.text = text
198 |     self._document_id = document_id
199 | 
200 |   @property
201 |   def document_id(self) -> str:
202 |     """Returns the document ID, generating a unique one if not set."""
203 |     if self._document_id is None:
204 |       self._document_id = f"doc_{uuid.uuid4().hex[:8]}"
205 |     return self._document_id
206 | 
207 |   @document_id.setter
208 |   def document_id(self, value: str | None) -> None:
209 |     """Sets the document ID."""
210 |     self._document_id = value
211 | 
212 |   @property
213 |   def tokenized_text(self) -> tokenizer.TokenizedText | None:
214 |     if self._tokenized_text is None and self.text is not None:
215 |       self._tokenized_text = tokenizer.tokenize(self.text)
216 |     return self._tokenized_text
217 | 
218 |   @tokenized_text.setter
219 |   def tokenized_text(self, value: tokenizer.TokenizedText) -> None:
220 |     self._tokenized_text = value
221 | 
222 | 
223 | @dataclasses.dataclass
224 | class ExampleData:
225 |   """A single training/example data instance for a structured prompting.
226 | 
227 |   Attributes:
228 |     text: The raw input text (sentence, paragraph, etc.).
229 |     extractions: A list of Extraction objects extracted from the text.
230 |   """
231 | 
232 |   text: str
233 |   extractions: list[Extraction] = dataclasses.field(default_factory=list)
234 | 


--------------------------------------------------------------------------------
/langextract/core/exceptions.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Core error types for LangExtract.
16 | 
17 | This module defines all base exceptions for LangExtract. These are the
18 | foundational error types that are used throughout the codebase.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | __all__ = [
24 |     "LangExtractError",
25 |     "InferenceError",
26 |     "InferenceConfigError",
27 |     "InferenceRuntimeError",
28 |     "InferenceOutputError",
29 |     "ProviderError",
30 |     "SchemaError",
31 | ]
32 | 
33 | 
34 | class LangExtractError(Exception):
35 |   """Base exception for all LangExtract errors.
36 | 
37 |   All exceptions raised by LangExtract should inherit from this class.
38 |   This allows users to catch all LangExtract-specific errors with a single
39 |   except clause.
40 |   """
41 | 
42 | 
43 | class InferenceError(LangExtractError):
44 |   """Base exception for inference-related errors."""
45 | 
46 | 
47 | class InferenceConfigError(InferenceError):
48 |   """Exception raised for configuration errors.
49 | 
50 |   This includes missing API keys, invalid model IDs, or other
51 |   configuration-related issues that prevent model instantiation.
52 |   """
53 | 
54 | 
55 | class InferenceRuntimeError(InferenceError):
56 |   """Exception raised for runtime inference errors.
57 | 
58 |   This includes API call failures, network errors, or other issues
59 |   that occur during inference execution.
60 |   """
61 | 
62 |   def __init__(
63 |       self,
64 |       message: str,
65 |       *,
66 |       original: BaseException | None = None,
67 |       provider: str | None = None,
68 |   ) -> None:
69 |     """Initialize the runtime error.
70 | 
71 |     Args:
72 |       message: Error message.
73 |       original: Original exception from the provider SDK.
74 |       provider: Name of the provider that raised the error.
75 |     """
76 |     super().__init__(message)
77 |     self.original = original
78 |     self.provider = provider
79 | 
80 | 
81 | class InferenceOutputError(LangExtractError):
82 |   """Exception raised when no scored outputs are available from the language model."""
83 | 
84 |   def __init__(self, message: str):
85 |     self.message = message
86 |     super().__init__(self.message)
87 | 
88 | 
89 | class ProviderError(LangExtractError):
90 |   """Provider/backend specific error."""
91 | 
92 | 
93 | class SchemaError(LangExtractError):
94 |   """Schema validation/serialization error."""
95 | 


--------------------------------------------------------------------------------
/langextract/core/schema.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Core schema abstractions for LangExtract."""
 16 | from __future__ import annotations
 17 | 
 18 | import abc
 19 | from collections.abc import Sequence
 20 | from typing import Any, TYPE_CHECKING
 21 | 
 22 | from langextract.core import types
 23 | 
 24 | if TYPE_CHECKING:
 25 |   from langextract.core import data
 26 | 
 27 | __all__ = [
 28 |     "EXTRACTIONS_KEY",
 29 |     "ConstraintType",
 30 |     "Constraint",
 31 |     "BaseSchema",
 32 |     "FormatModeSchema",
 33 | ]
 34 | 
 35 | EXTRACTIONS_KEY = "extractions"  # Shared key for extraction arrays in JSON/YAML
 36 | 
 37 | # Backward compat re-exports
 38 | ConstraintType = types.ConstraintType
 39 | Constraint = types.Constraint
 40 | 
 41 | 
 42 | class BaseSchema(abc.ABC):
 43 |   """Abstract base class for generating structured constraints from examples."""
 44 | 
 45 |   @classmethod
 46 |   @abc.abstractmethod
 47 |   def from_examples(
 48 |       cls,
 49 |       examples_data: Sequence[data.ExampleData],
 50 |       attribute_suffix: str = "_attributes",
 51 |   ) -> BaseSchema:
 52 |     """Factory method to build a schema instance from example data."""
 53 | 
 54 |   @abc.abstractmethod
 55 |   def to_provider_config(self) -> dict[str, Any]:
 56 |     """Convert schema to provider-specific configuration.
 57 | 
 58 |     Returns:
 59 |       Dictionary of provider kwargs (e.g., response_schema for Gemini).
 60 |       Should be a pure data mapping with no side effects.
 61 |     """
 62 | 
 63 |   @property
 64 |   @abc.abstractmethod
 65 |   def supports_strict_mode(self) -> bool:
 66 |     """Whether the provider emits valid output without needing Markdown fences.
 67 | 
 68 |     Returns:
 69 |       True when the provider will emit syntactically valid JSON (or other
 70 |       machine-parseable format) without needing Markdown fences. This says
 71 |       nothing about attribute-level schema enforcement. False otherwise.
 72 |     """
 73 | 
 74 |   def sync_with_provider_kwargs(self, kwargs: dict[str, Any]) -> None:
 75 |     """Hook to update schema state based on provider kwargs.
 76 | 
 77 |     This allows schemas to adjust their behavior based on caller overrides.
 78 |     For example, FormatModeSchema uses this to sync its format when the caller
 79 |     overrides it, ensuring supports_strict_mode stays accurate.
 80 | 
 81 |     Default implementation does nothing. Override if your schema needs to
 82 |     respond to provider kwargs.
 83 | 
 84 |     Args:
 85 |       kwargs: The effective provider kwargs after merging.
 86 |     """
 87 | 
 88 | 
 89 | class FormatModeSchema(BaseSchema):
 90 |   """Generic schema for providers that support format modes (JSON/YAML).
 91 | 
 92 |   This schema doesn't enforce structure, only output format. Useful for
 93 |   providers that can guarantee syntactically valid JSON or YAML but don't
 94 |   support field-level constraints.
 95 |   """
 96 | 
 97 |   def __init__(self, format_type: types.FormatType = types.FormatType.JSON):
 98 |     """Initialize with a format type."""
 99 |     self.format_type = format_type
100 |     # Keep _format for backward compatibility with tests
101 |     self._format = "json" if format_type == types.FormatType.JSON else "yaml"
102 | 
103 |   @classmethod
104 |   def from_examples(
105 |       cls,
106 |       examples_data,
107 |       attribute_suffix: str = "_attributes",
108 |   ) -> FormatModeSchema:
109 |     """Factory method to build a schema instance from example data."""
110 |     # Default to JSON format
111 |     return cls(format_type=types.FormatType.JSON)
112 | 
113 |   def to_provider_config(self) -> dict[str, Any]:
114 |     """Convert schema to provider-specific configuration."""
115 |     return {"format": self._format}
116 | 
117 |   @property
118 |   def supports_strict_mode(self) -> bool:
119 |     """Format mode schemas support strict output.
120 | 
121 |     JSON supports strict mode (no fences needed), YAML does not.
122 |     """
123 |     return self._format == "json"
124 | 
125 |   def sync_with_provider_kwargs(self, kwargs: dict[str, Any]) -> None:
126 |     """Sync format type with provider kwargs."""
127 |     if "format_type" in kwargs:
128 |       self.format_type = kwargs["format_type"]
129 |       self._format = (
130 |           "json" if self.format_type == types.FormatType.JSON else "yaml"
131 |       )
132 |     if "format" in kwargs:
133 |       self._format = kwargs["format"]
134 |       self.format_type = (
135 |           types.FormatType.JSON
136 |           if self._format == "json"
137 |           else types.FormatType.YAML
138 |       )
139 | 


--------------------------------------------------------------------------------
/langextract/core/types.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Core data types for LangExtract."""
16 | from __future__ import annotations
17 | 
18 | import dataclasses
19 | import enum
20 | import textwrap
21 | 
22 | __all__ = ['ScoredOutput', 'FormatType', 'ConstraintType', 'Constraint']
23 | 
24 | 
25 | class FormatType(enum.Enum):
26 |   """Enumeration of prompt output formats."""
27 | 
28 |   YAML = 'yaml'
29 |   JSON = 'json'
30 | 
31 | 
32 | class ConstraintType(enum.Enum):
33 |   """Enumeration of constraint types."""
34 | 
35 |   NONE = 'none'
36 | 
37 | 
38 | @dataclasses.dataclass
39 | class Constraint:
40 |   """Represents a constraint for model output decoding.
41 | 
42 |   Attributes:
43 |     constraint_type: The type of constraint applied.
44 |   """
45 | 
46 |   constraint_type: ConstraintType = ConstraintType.NONE
47 | 
48 | 
49 | @dataclasses.dataclass(frozen=True)
50 | class ScoredOutput:
51 |   """Scored output from language model inference."""
52 | 
53 |   score: float | None = None
54 |   output: str | None = None
55 | 
56 |   def __str__(self) -> str:
57 |     score_str = '-' if self.score is None else f'{self.score:.2f}'
58 |     if self.output is None:
59 |       return f'Score: {score_str}\nOutput: None'
60 |     formatted_lines = textwrap.indent(self.output, prefix='  ')
61 |     return f'Score: {score_str}\nOutput:\n{formatted_lines}'
62 | 


--------------------------------------------------------------------------------
/langextract/data.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.data imports.
16 | 
17 | This module provides backward compatibility for code that imports from
18 | langextract.data. All functionality has moved to langextract.core.data.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | # Re-export everything from core.data for backward compatibility
24 | # pylint: disable=wildcard-import,unused-wildcard-import
25 | from langextract.core.data import *
26 | 


--------------------------------------------------------------------------------
/langextract/data_lib.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Library for data conversion between AnnotatedDocument and JSON."""
 16 | from __future__ import annotations
 17 | 
 18 | import dataclasses
 19 | import enum
 20 | import numbers
 21 | from typing import Any, Iterable, Mapping
 22 | 
 23 | from langextract.core import data
 24 | from langextract.core import tokenizer
 25 | 
 26 | 
 27 | def enum_asdict_factory(items: Iterable[tuple[str, Any]]) -> dict[str, Any]:
 28 |   """Custom dict_factory for dataclasses.asdict.
 29 | 
 30 |   Recursively converts dataclass instances, converts enum values to their
 31 |   underlying values, converts integral numeric types to int, and skips any
 32 |   field whose name starts with an underscore.
 33 | 
 34 |   Args:
 35 |     items: An iterable of (key, value) pairs from fields of a dataclass.
 36 | 
 37 |   Returns:
 38 |     A mapping of field names to their values, with special handling for
 39 |     dataclasses, enums, and numeric types.
 40 |   """
 41 |   result: dict[str, Any] = {}
 42 |   for key, value in items:
 43 |     # Skip internal fields.
 44 |     if key.startswith("_"):
 45 |       continue
 46 |     if dataclasses.is_dataclass(value):
 47 |       result[key] = dataclasses.asdict(value, dict_factory=enum_asdict_factory)
 48 |     elif isinstance(value, enum.Enum):
 49 |       result[key] = value.value
 50 |     elif isinstance(value, numbers.Integral) and not isinstance(value, bool):
 51 |       result[key] = int(value)
 52 |     else:
 53 |       result[key] = value
 54 |   return result
 55 | 
 56 | 
 57 | def annotated_document_to_dict(
 58 |     adoc: data.AnnotatedDocument | None,
 59 | ) -> dict[str, Any]:
 60 |   """Converts an AnnotatedDocument into a Python dict.
 61 | 
 62 |   This function converts an AnnotatedDocument object into a Python dict, making
 63 |   it easier to serialize or deserialize the document. Enum values and NumPy
 64 |   integers are converted to their underlying values, while other data types are
 65 |   left unchanged. Private fields with an underscore prefix are not included in
 66 |   the output.
 67 | 
 68 |   Args:
 69 |     adoc: The AnnotatedDocument object to convert.
 70 | 
 71 |   Returns:
 72 |     A Python dict representing the AnnotatedDocument.
 73 |   """
 74 | 
 75 |   if not adoc:
 76 |     return {}
 77 | 
 78 |   result = dataclasses.asdict(adoc, dict_factory=enum_asdict_factory)
 79 | 
 80 |   result["document_id"] = adoc.document_id
 81 | 
 82 |   return result
 83 | 
 84 | 
 85 | def dict_to_annotated_document(
 86 |     adoc_dic: Mapping[str, Any],
 87 | ) -> data.AnnotatedDocument:
 88 |   """Converts a Python dict back to an AnnotatedDocument.
 89 | 
 90 |   Args:
 91 |     adoc_dic: A Python dict representing an AnnotatedDocument.
 92 | 
 93 |   Returns:
 94 |     An AnnotatedDocument object.
 95 |   """
 96 |   if not adoc_dic:
 97 |     return data.AnnotatedDocument()
 98 | 
 99 |   for extractions in adoc_dic.get("extractions", []):
100 |     token_int = extractions.get("token_interval")
101 |     if token_int:
102 |       extractions["token_interval"] = tokenizer.TokenInterval(**token_int)
103 |     else:
104 |       extractions["token_interval"] = None
105 | 
106 |     char_int = extractions.get("char_interval")
107 |     if char_int:
108 |       extractions["char_interval"] = data.CharInterval(**char_int)
109 |     else:
110 |       extractions["char_interval"] = None
111 | 
112 |     status_str = extractions.get("alignment_status")
113 |     if status_str:
114 |       extractions["alignment_status"] = data.AlignmentStatus(status_str)
115 |     else:
116 |       extractions["alignment_status"] = None
117 | 
118 |   return data.AnnotatedDocument(
119 |       document_id=adoc_dic.get("document_id"),
120 |       text=adoc_dic.get("text"),
121 |       extractions=[
122 |           data.Extraction(**ent) for ent in adoc_dic.get("extractions", [])
123 |       ],
124 |   )
125 | 


--------------------------------------------------------------------------------
/langextract/debug_utils.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Debug utilities for LangExtract."""
 16 | from __future__ import annotations
 17 | 
 18 | import functools
 19 | import inspect
 20 | import logging
 21 | import reprlib
 22 | import time
 23 | from typing import Any, Callable, Mapping
 24 | 
 25 | from absl import logging as absl_logging
 26 | 
 27 | _LOG = logging.getLogger("langextract.debug")
 28 | 
 29 | # Add NullHandler to prevent "No handler found" warnings
 30 | _langextract_logger = logging.getLogger("langextract")
 31 | if not _langextract_logger.handlers:
 32 |   _langextract_logger.addHandler(logging.NullHandler())
 33 | 
 34 | # Sensitive keys to redact
 35 | _REDACT_KEYS = {
 36 |     "api_key",
 37 |     "apikey",
 38 |     "token",
 39 |     "secret",
 40 |     "password",
 41 |     "authorization",
 42 |     "bearer",
 43 |     "jwt",
 44 | }
 45 | _MAX_STR = 500
 46 | _MAX_SEQ = 20
 47 | 
 48 | 
 49 | def _safe_repr(obj: Any) -> str:
 50 |   """Truncate object repr for safe logging."""
 51 |   r = reprlib.Repr()
 52 |   r.maxstring = _MAX_STR
 53 |   r.maxlist = r.maxtuple = r.maxset = r.maxdict = _MAX_SEQ
 54 |   return r.repr(obj)
 55 | 
 56 | 
 57 | def _redact_value(name: str, value: Any) -> str:
 58 |   """Redact sensitive values based on parameter name."""
 59 |   if isinstance(name, str) and name.lower() in _REDACT_KEYS:
 60 |     return "<REDACTED>"
 61 |   # If a nested mapping, redact its sensitive keys too
 62 |   if isinstance(value, Mapping):
 63 |     redacted = {}
 64 |     for k, v in value.items():
 65 |       if isinstance(k, str) and k.lower() in _REDACT_KEYS:
 66 |         redacted[k] = "<REDACTED>"
 67 |       else:
 68 |         redacted[k] = _safe_repr(v)
 69 |     return _safe_repr(redacted)
 70 |   return _safe_repr(value)
 71 | 
 72 | 
 73 | def _redact_mapping(mapping: Mapping[str, Any]) -> dict[str, str]:
 74 |   """Replace sensitive values with <REDACTED>."""
 75 |   out = {}
 76 |   for k, v in mapping.items():
 77 |     out[k] = _redact_value(k, v)
 78 |   return out
 79 | 
 80 | 
 81 | def _format_bound_args(
 82 |     fn: Callable, args: tuple[Any, ...], kwargs: dict[str, Any]
 83 | ) -> str:
 84 |   """Format function arguments using signature inspection."""
 85 |   try:
 86 |     sig = inspect.signature(fn)
 87 |     bound = sig.bind_partial(*args, **kwargs)
 88 |     bound.apply_defaults()
 89 |   except Exception:
 90 |     # Fallback (no names) if binding fails
 91 |     parts = [_safe_repr(a) for a in args]
 92 |     if kwargs:
 93 |       red = _redact_mapping(kwargs)
 94 |       parts += [f"{k}={v}" for k, v in sorted(red.items())]
 95 |     return ", ".join(parts)
 96 | 
 97 |   parts: list[str] = []
 98 |   for name, value in bound.arguments.items():
 99 |     if name in ("self", "cls"):
100 |       parts.append(f"{name}=<{type(value).__name__}>")
101 |     else:
102 |       parts.append(f"{name}={_redact_value(name, value)}")
103 |   return ", ".join(parts)
104 | 
105 | 
106 | def debug_log_calls(fn: Callable) -> Callable:
107 |   """Log function calls with redacted sensitive data and timing.
108 | 
109 |   Automatically redacts api_key, token, etc. and truncates large outputs.
110 |   """
111 | 
112 |   @functools.wraps(fn)
113 |   def wrapper(*args, **kwargs):
114 |     logger = _LOG
115 |     if not logger.isEnabledFor(logging.DEBUG):
116 |       return fn(*args, **kwargs)
117 | 
118 |     fn_qual = getattr(fn, "__qualname__", fn.__name__)
119 |     mod = getattr(fn, "__module__", "")
120 | 
121 |     # Format arguments using signature inspection
122 |     arg_str = _format_bound_args(fn, args, kwargs)
123 | 
124 |     logger.debug("[%s] CALL: %s(%s)", mod, fn_qual, arg_str, stacklevel=2)
125 | 
126 |     start = time.perf_counter()
127 |     try:
128 |       result = fn(*args, **kwargs)
129 |     except Exception:
130 |       dur_ms = (time.perf_counter() - start) * 1000
131 |       logger.exception(
132 |           "[%s] EXCEPTION: %s (%.1f ms)", mod, fn_qual, dur_ms, stacklevel=2
133 |       )
134 |       raise
135 | 
136 |     dur_ms = (time.perf_counter() - start) * 1000
137 |     result_repr = _safe_repr(result)
138 |     logger.debug(
139 |         "[%s] RETURN: %s -> %s (%.1f ms)",
140 |         mod,
141 |         fn_qual,
142 |         result_repr,
143 |         dur_ms,
144 |         stacklevel=2,
145 |     )
146 |     return result
147 | 
148 |   return wrapper
149 | 
150 | 
151 | def configure_debug_logging() -> None:
152 |   """Enable debug logging for the 'langextract' namespace only."""
153 |   logger = logging.getLogger("langextract")
154 | 
155 |   # Skip if we already added our handler
156 |   our_handler_exists = any(
157 |       isinstance(h, logging.StreamHandler)
158 |       and getattr(h, "langextract_debug", False)
159 |       for h in logger.handlers
160 |   )
161 |   if our_handler_exists:
162 |     return
163 | 
164 |   # Respect host handlers - only set level if they exist
165 |   non_null_handlers = [
166 |       h for h in logger.handlers if not isinstance(h, logging.NullHandler)
167 |   ]
168 | 
169 |   if non_null_handlers:
170 |     logger.setLevel(logging.DEBUG)
171 |   else:
172 |     logger.setLevel(logging.DEBUG)
173 |     handler = logging.StreamHandler()
174 |     handler.setLevel(logging.DEBUG)
175 |     fmt = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
176 |     handler.setFormatter(logging.Formatter(fmt))
177 |     handler.langextract_debug = True
178 |     logger.addHandler(handler)
179 |     logger.propagate = False
180 | 
181 |   # Best-effort absl configuration
182 |   try:
183 |     absl_logging.set_verbosity(absl_logging.DEBUG)
184 |   except Exception:
185 |     pass
186 | 


--------------------------------------------------------------------------------
/langextract/exceptions.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Public exceptions API for LangExtract.
16 | 
17 | This module re-exports exceptions from core.exceptions for backward compatibility.
18 | All new code should import directly from langextract.core.exceptions.
19 | """
20 | # pylint: disable=duplicate-code
21 | 
22 | from __future__ import annotations
23 | 
24 | from langextract.core import exceptions as core_exceptions
25 | 
26 | # Backward compat re-exports
27 | InferenceConfigError = core_exceptions.InferenceConfigError
28 | InferenceError = core_exceptions.InferenceError
29 | InferenceOutputError = core_exceptions.InferenceOutputError
30 | InferenceRuntimeError = core_exceptions.InferenceRuntimeError
31 | LangExtractError = core_exceptions.LangExtractError
32 | ProviderError = core_exceptions.ProviderError
33 | SchemaError = core_exceptions.SchemaError
34 | 
35 | __all__ = [
36 |     "LangExtractError",
37 |     "InferenceError",
38 |     "InferenceConfigError",
39 |     "InferenceRuntimeError",
40 |     "InferenceOutputError",
41 |     "ProviderError",
42 |     "SchemaError",
43 | ]
44 | 


--------------------------------------------------------------------------------
/langextract/inference.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Language model inference compatibility layer.
16 | 
17 | This module provides backward compatibility for the inference module.
18 | New code should import from langextract.core.base_model instead.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | from langextract._compat import inference
24 | 
25 | 
26 | def __getattr__(name: str):
27 |   """Forward to _compat.inference for backward compatibility."""
28 |   # Handle InferenceType specially since it's defined in _compat
29 |   if name == "InferenceType":
30 |     return inference.InferenceType
31 | 
32 |   return inference.__getattr__(name)
33 | 


--------------------------------------------------------------------------------
/langextract/plugins.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Provider discovery and registration system.
 16 | 
 17 | This module provides centralized provider discovery without circular imports.
 18 | It supports both built-in providers and third-party providers via entry points.
 19 | """
 20 | from __future__ import annotations
 21 | 
 22 | from functools import lru_cache
 23 | from importlib import import_module
 24 | from importlib.metadata import entry_points
 25 | from typing import Dict, List, Type
 26 | 
 27 | from absl import logging
 28 | 
 29 | from langextract.core import base_model
 30 | 
 31 | __all__ = ["available_providers", "get_provider_class"]
 32 | 
 33 | # Static mapping for built-in providers (always available)
 34 | _BUILTINS: Dict[str, str] = {
 35 |     "gemini": "langextract.providers.gemini:GeminiLanguageModel",
 36 |     "ollama": "langextract.providers.ollama:OllamaLanguageModel",
 37 | }
 38 | 
 39 | # Optional built-in providers (require extra dependencies)
 40 | _OPTIONAL_BUILTINS: Dict[str, str] = {
 41 |     "openai": "langextract.providers.openai:OpenAILanguageModel",
 42 | }
 43 | 
 44 | 
 45 | def _safe_entry_points(group: str) -> List:
 46 |   """Get entry points with Python 3.8-3.12 compatibility.
 47 | 
 48 |   Args:
 49 |     group: Entry point group name.
 50 | 
 51 |   Returns:
 52 |     List of entry points in the specified group.
 53 |   """
 54 |   eps = entry_points()
 55 |   try:
 56 |     # Python 3.10+
 57 |     return list(eps.select(group=group))
 58 |   except AttributeError:
 59 |     # Python 3.8-3.9
 60 |     return list(eps.get(group, []))  # pylint: disable=no-member
 61 | 
 62 | 
 63 | @lru_cache(maxsize=1)
 64 | def _discovered() -> Dict[str, str]:
 65 |   """Cache discovered third-party providers.
 66 | 
 67 |   Returns:
 68 |     Dictionary mapping provider names to import specs.
 69 |   """
 70 |   discovered: Dict[str, str] = {}
 71 |   for ep in _safe_entry_points("langextract.providers"):
 72 |     # Handle both old and new entry_points API
 73 |     if hasattr(ep, "value"):
 74 |       # Modern API
 75 |       discovered.setdefault(ep.name, ep.value)
 76 |     else:
 77 |       # Legacy API - construct from module and attr
 78 |       value = f"{ep.module}:{ep.attr}" if ep.attr else ep.module
 79 |       discovered.setdefault(ep.name, value)
 80 | 
 81 |   if discovered:
 82 |     logging.debug(
 83 |         "Discovered third-party providers: %s", list(discovered.keys())
 84 |     )
 85 | 
 86 |   return discovered
 87 | 
 88 | 
 89 | def available_providers(
 90 |     allow_override: bool = False, include_optional: bool = True
 91 | ) -> Dict[str, str]:
 92 |   """Get all available providers (built-in + optional + third-party).
 93 | 
 94 |   Args:
 95 |     allow_override: If True, third-party providers can override built-ins.
 96 |                    If False (default), built-ins take precedence.
 97 |     include_optional: If True (default), include optional built-in providers
 98 |                      that may require extra dependencies.
 99 | 
100 |   Returns:
101 |     Dictionary mapping provider names to import specifications.
102 |   """
103 |   # Start with third-party providers
104 |   providers = dict(_discovered())
105 | 
106 |   # Add optional built-ins if requested
107 |   if include_optional:
108 |     if allow_override:
109 |       # Third-party can override optional built-ins
110 |       providers.update(_OPTIONAL_BUILTINS)
111 |     else:
112 |       # Optional built-ins override third-party
113 |       providers = {**providers, **_OPTIONAL_BUILTINS}
114 | 
115 |   # Always add core built-ins with highest precedence (unless allow_override)
116 |   if allow_override:
117 |     # Third-party and optional can override core built-ins
118 |     providers.update(_BUILTINS)
119 |   else:
120 |     # Core built-ins take precedence over everything
121 |     providers = {**providers, **_BUILTINS}
122 | 
123 |   return providers
124 | 
125 | 
126 | def _load_class(spec: str) -> Type[base_model.BaseLanguageModel]:
127 |   """Load a provider class from module:Class specification.
128 | 
129 |   Args:
130 |     spec: Import specification in format "module.path:ClassName".
131 | 
132 |   Returns:
133 |     The loaded provider class.
134 | 
135 |   Raises:
136 |     ImportError: If the spec is invalid or module cannot be imported.
137 |     TypeError: If the loaded class is not a BaseLanguageModel.
138 |   """
139 |   module_path, _, class_name = spec.partition(":")
140 |   if not module_path or not class_name:
141 |     raise ImportError(
142 |         f"Invalid provider spec '{spec}' - expected 'module:Class'"
143 |     )
144 | 
145 |   try:
146 |     module = import_module(module_path)
147 |   except ImportError as e:
148 |     raise ImportError(
149 |         f"Failed to import provider module '{module_path}': {e}"
150 |     ) from e
151 | 
152 |   try:
153 |     cls = getattr(module, class_name)
154 |   except AttributeError as e:
155 |     raise ImportError(
156 |         f"Provider class '{class_name}' not found in module '{module_path}'"
157 |     ) from e
158 | 
159 |   # Validate it's a language model
160 |   if not isinstance(cls, type) or not issubclass(
161 |       cls, base_model.BaseLanguageModel
162 |   ):
163 |     # Fallback: check structural compatibility for non-ABC classes
164 |     missing = []
165 |     for method in ("infer", "parse_output"):
166 |       if not hasattr(cls, method):
167 |         missing.append(method)
168 | 
169 |     if missing:
170 |       raise TypeError(
171 |           f"{cls} is not a BaseLanguageModel and missing required methods:"
172 |           f" {missing}"
173 |       )
174 | 
175 |     # Log warning but allow if structurally compatible
176 |     logging.warning(
177 |         "Provider %s does not inherit from BaseLanguageModel but appears"
178 |         " compatible",
179 |         cls,
180 |     )
181 | 
182 |   return cls
183 | 
184 | 
185 | @lru_cache(maxsize=None)  # Cache all loaded classes
186 | def get_provider_class(
187 |     name: str, allow_override: bool = False, include_optional: bool = True
188 | ) -> Type[base_model.BaseLanguageModel]:
189 |   """Get a provider class by name.
190 | 
191 |   Args:
192 |     name: Provider name (e.g., "gemini", "openai", "ollama").
193 |     allow_override: If True, allow third-party providers to override built-ins.
194 |     include_optional: If True (default), include optional providers that
195 |                      may require extra dependencies.
196 | 
197 |   Returns:
198 |     The provider class.
199 | 
200 |   Raises:
201 |     KeyError: If the provider name is not found.
202 |     ImportError: If the provider module cannot be imported (including
203 |                 missing optional dependencies).
204 |     TypeError: If the provider class is not compatible.
205 |   """
206 |   providers = available_providers(allow_override, include_optional)
207 | 
208 |   if name not in providers:
209 |     available = sorted(providers.keys())
210 |     raise KeyError(
211 |         f"Unknown provider '{name}'. Available providers:"
212 |         f" {', '.join(available) if available else 'none'}.\nHint: Did you"
213 |         " install the necessary extras (e.g., pip install"
214 |         f" langextract[{name}])?"
215 |     )
216 | 
217 |   return _load_class(providers[name])
218 | 


--------------------------------------------------------------------------------
/langextract/prompting.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Library for building prompts."""
 16 | from __future__ import annotations
 17 | 
 18 | import dataclasses
 19 | import json
 20 | import os
 21 | import pathlib
 22 | 
 23 | import pydantic
 24 | import yaml
 25 | 
 26 | from langextract.core import data
 27 | from langextract.core import exceptions
 28 | from langextract.core import schema
 29 | 
 30 | 
 31 | class PromptBuilderError(exceptions.LangExtractError):
 32 |   """Failure to build prompt."""
 33 | 
 34 | 
 35 | class ParseError(PromptBuilderError):
 36 |   """Prompt template cannot be parsed."""
 37 | 
 38 | 
 39 | @dataclasses.dataclass
 40 | class PromptTemplateStructured:
 41 |   """A structured prompt template for few-shot examples.
 42 | 
 43 |   Attributes:
 44 |     description: Instructions or guidelines for the LLM.
 45 |     examples: ExampleData objects demonstrating expected input→output behavior.
 46 |   """
 47 | 
 48 |   description: str
 49 |   examples: list[data.ExampleData] = dataclasses.field(default_factory=list)
 50 | 
 51 | 
 52 | def read_prompt_template_structured_from_file(
 53 |     prompt_path: str,
 54 |     format_type: data.FormatType = data.FormatType.YAML,
 55 | ) -> PromptTemplateStructured:
 56 |   """Reads a structured prompt template from a file.
 57 | 
 58 |   Args:
 59 |     prompt_path: Path to a file containing PromptTemplateStructured data.
 60 |     format_type: The format of the file; YAML or JSON.
 61 | 
 62 |   Returns:
 63 |     A PromptTemplateStructured object loaded from the file.
 64 | 
 65 |   Raises:
 66 |     ParseError: If the file cannot be parsed successfully.
 67 |   """
 68 |   adapter = pydantic.TypeAdapter(PromptTemplateStructured)
 69 |   try:
 70 |     with pathlib.Path(prompt_path).open("rt") as f:
 71 |       data_dict = {}
 72 |       prompt_content = f.read()
 73 |       if format_type == data.FormatType.YAML:
 74 |         data_dict = yaml.safe_load(prompt_content)
 75 |       elif format_type == data.FormatType.JSON:
 76 |         data_dict = json.loads(prompt_content)
 77 |       return adapter.validate_python(data_dict)
 78 |   except Exception as e:
 79 |     raise ParseError(
 80 |         f"Failed to parse prompt template from file: {prompt_path}"
 81 |     ) from e
 82 | 
 83 | 
 84 | @dataclasses.dataclass
 85 | class QAPromptGenerator:
 86 |   """Generates question-answer prompts from the provided template."""
 87 | 
 88 |   template: PromptTemplateStructured
 89 |   format_type: data.FormatType = data.FormatType.YAML
 90 |   attribute_suffix: str = "_attributes"
 91 |   examples_heading: str = "Examples"
 92 |   question_prefix: str = "Q: "
 93 |   answer_prefix: str = "A: "
 94 |   fence_output: bool = True  # whether to wrap answers in ```json/```yaml fences
 95 | 
 96 |   def __str__(self) -> str:
 97 |     """Returns a string representation of the prompt with an empty question."""
 98 |     return self.render("")
 99 | 
100 |   def format_example_as_text(self, example: data.ExampleData) -> str:
101 |     """Formats a single example for the prompt.
102 | 
103 |     Args:
104 |       example: The example data to format.
105 | 
106 |     Returns:
107 |       A string representation of the example, including the question and answer.
108 |     """
109 |     question = example.text
110 | 
111 |     # Build a dictionary for serialization
112 |     data_dict: dict[str, list] = {schema.EXTRACTIONS_KEY: []}
113 |     for extraction in example.extractions:
114 |       data_entry = {
115 |           f"{extraction.extraction_class}": extraction.extraction_text,
116 |           f"{extraction.extraction_class}{self.attribute_suffix}": (
117 |               extraction.attributes or {}
118 |           ),
119 |       }
120 |       data_dict[schema.EXTRACTIONS_KEY].append(data_entry)
121 | 
122 |     if self.format_type == data.FormatType.YAML:
123 |       formatted_content = yaml.dump(
124 |           data_dict, default_flow_style=False, sort_keys=False
125 |       )
126 |       if self.fence_output:
127 |         answer = f"```yaml\n{formatted_content.strip()}\n```"
128 |       else:
129 |         answer = formatted_content.strip()
130 |     elif self.format_type == data.FormatType.JSON:
131 |       formatted_content = json.dumps(data_dict, indent=2, ensure_ascii=False)
132 |       if self.fence_output:
133 |         answer = f"```json\n{formatted_content.strip()}\n```"
134 |       else:
135 |         answer = formatted_content.strip()
136 |     else:
137 |       raise ValueError(f"Unsupported format type: {self.format_type}")
138 | 
139 |     return "\n".join([
140 |         f"{self.question_prefix}{question}",
141 |         f"{self.answer_prefix}{answer}\n",
142 |     ])
143 | 
144 |   def render(self, question: str, additional_context: str | None = None) -> str:
145 |     """Generate a text representation of the prompt.
146 | 
147 |     Args:
148 |       question: That will be presented to the model.
149 |       additional_context: Additional context to include in the prompt. An empty
150 |         string is ignored.
151 | 
152 |     Returns:
153 |       Text prompt with a question to be presented to a language model.
154 |     """
155 |     prompt_lines: list[str] = [f"{self.template.description}\n"]
156 | 
157 |     if additional_context:
158 |       prompt_lines.append(f"{additional_context}\n")
159 | 
160 |     if self.template.examples:
161 |       prompt_lines.append(self.examples_heading)
162 |       for ex in self.template.examples:
163 |         prompt_lines.append(self.format_example_as_text(ex))
164 | 
165 |     prompt_lines.append(f"{self.question_prefix}{question}")
166 |     prompt_lines.append(self.answer_prefix)
167 |     return "\n".join(prompt_lines)
168 | 


--------------------------------------------------------------------------------
/langextract/providers/__init__.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Provider package for LangExtract.
 16 | 
 17 | This package contains provider implementations for various LLM backends.
 18 | Each provider can be imported independently for fine-grained dependency
 19 | management in build systems.
 20 | """
 21 | 
 22 | import importlib
 23 | from importlib import metadata
 24 | import os
 25 | 
 26 | from absl import logging
 27 | 
 28 | from langextract.providers import router
 29 | from langextract.providers.builtin_registry import BUILTIN_PROVIDERS
 30 | from langextract.providers.router import register
 31 | from langextract.providers.router import register_lazy
 32 | 
 33 | registry = router  # Backward compat alias
 34 | 
 35 | __all__ = [
 36 |     'gemini',
 37 |     'openai',
 38 |     'ollama',
 39 |     'router',
 40 |     'registry',  # Backward compat
 41 |     'schemas',
 42 |     'load_plugins_once',
 43 |     'load_builtins_once',
 44 | ]
 45 | 
 46 | # Track provider loading for lazy initialization
 47 | _PLUGINS_LOADED = False
 48 | _BUILTINS_LOADED = False
 49 | 
 50 | 
 51 | def load_builtins_once() -> None:
 52 |   """Load built-in providers to register their patterns.
 53 | 
 54 |   Idempotent function that ensures provider patterns are available
 55 |   for model resolution. Uses lazy registration to ensure providers
 56 |   can be re-registered after registry.clear() even if their modules
 57 |   are already in sys.modules.
 58 |   """
 59 |   global _BUILTINS_LOADED  # pylint: disable=global-statement
 60 | 
 61 |   if _BUILTINS_LOADED:
 62 |     return
 63 | 
 64 |   # Register built-ins lazily so they can be re-registered after a registry.clear()
 65 |   # even if their modules were already imported earlier in the test run.
 66 |   for config in BUILTIN_PROVIDERS:
 67 |     register_lazy(
 68 |         *config['patterns'],
 69 |         target=config['target'],
 70 |         priority=config['priority'],
 71 |     )
 72 | 
 73 |   _BUILTINS_LOADED = True
 74 | 
 75 | 
 76 | def load_plugins_once() -> None:
 77 |   """Load provider plugins from installed packages.
 78 | 
 79 |   Discovers and loads langextract provider plugins using entry points.
 80 |   This function is idempotent - multiple calls have no effect.
 81 |   """
 82 |   global _PLUGINS_LOADED  # pylint: disable=global-statement
 83 |   if _PLUGINS_LOADED:
 84 |     return
 85 | 
 86 |   # Check if plugin loading is disabled
 87 |   if os.environ.get('LANGEXTRACT_DISABLE_PLUGINS', '').lower() in (
 88 |       '1',
 89 |       'true',
 90 |       'yes',
 91 |   ):
 92 |     logging.info('Plugin loading disabled via LANGEXTRACT_DISABLE_PLUGINS')
 93 |     _PLUGINS_LOADED = True
 94 |     return
 95 | 
 96 |   # Load built-in providers first
 97 |   load_builtins_once()
 98 | 
 99 |   try:
100 |     # Get entry points using the metadata API
101 |     eps = metadata.entry_points()
102 | 
103 |     # Try different APIs based on what's available
104 |     if hasattr(eps, 'select'):
105 |       # Python 3.10+ API
106 |       provider_eps = eps.select(group='langextract.providers')
107 |     elif hasattr(eps, 'get'):
108 |       # Python 3.9 API
109 |       provider_eps = eps.get('langextract.providers', [])
110 |     else:
111 |       # Fallback for older versions
112 |       provider_eps = [
113 |           ep
114 |           for ep in eps
115 |           if getattr(ep, 'group', None) == 'langextract.providers'
116 |       ]
117 | 
118 |     for entry_point in provider_eps:
119 |       try:
120 |         # Load the entry point
121 |         provider_class = entry_point.load()
122 |         logging.info('Loaded provider plugin: %s', entry_point.name)
123 | 
124 |         # Register if it has pattern information
125 |         if hasattr(provider_class, 'get_model_patterns'):
126 |           patterns = provider_class.get_model_patterns()
127 |           for pattern in patterns:
128 |             register(
129 |                 pattern,
130 |                 priority=getattr(
131 |                     provider_class,
132 |                     'pattern_priority',
133 |                     20,  # Default plugin priority
134 |                 ),
135 |             )(provider_class)
136 |           logging.info(
137 |               'Registered %d patterns for %s', len(patterns), entry_point.name
138 |           )
139 |       except Exception as e:
140 |         logging.warning(
141 |             'Failed to load provider plugin %s: %s', entry_point.name, e
142 |         )
143 | 
144 |   except Exception as e:
145 |     logging.warning('Error discovering provider plugins: %s', e)
146 | 
147 |   _PLUGINS_LOADED = True
148 | 
149 | 
150 | def _reset_for_testing() -> None:
151 |   """Reset plugin loading state for testing. Should only be used in tests."""
152 |   global _PLUGINS_LOADED, _BUILTINS_LOADED  # pylint: disable=global-statement
153 |   _PLUGINS_LOADED = False
154 |   _BUILTINS_LOADED = False
155 | 
156 | 
157 | def __getattr__(name: str):
158 |   """Lazy loading for submodules."""
159 |   if name == 'router':
160 |     return importlib.import_module('langextract.providers.router')
161 |   elif name == 'schemas':
162 |     return importlib.import_module('langextract.providers.schemas')
163 |   elif name == '_PLUGINS_LOADED':
164 |     return _PLUGINS_LOADED
165 |   elif name == '_BUILTINS_LOADED':
166 |     return _BUILTINS_LOADED
167 |   raise AttributeError(f'module {__name__!r} has no attribute {name!r}')
168 | 


--------------------------------------------------------------------------------
/langextract/providers/builtin_registry.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Built-in provider registration configuration.
16 | 
17 | This module defines the registration details for all built-in providers,
18 | using patterns from the centralized patterns module.
19 | """
20 | 
21 | from typing import TypedDict
22 | 
23 | from langextract.providers import patterns
24 | 
25 | 
26 | class ProviderConfig(TypedDict):
27 |   """Configuration for a provider registration."""
28 | 
29 |   patterns: tuple[str, ...]
30 |   target: str
31 |   priority: int
32 | 
33 | 
34 | # Built-in provider configurations using centralized patterns
35 | BUILTIN_PROVIDERS: list[ProviderConfig] = [
36 |     {
37 |         'patterns': patterns.GEMINI_PATTERNS,
38 |         'target': 'langextract.providers.gemini:GeminiLanguageModel',
39 |         'priority': patterns.GEMINI_PRIORITY,
40 |     },
41 |     {
42 |         'patterns': patterns.OLLAMA_PATTERNS,
43 |         'target': 'langextract.providers.ollama:OllamaLanguageModel',
44 |         'priority': patterns.OLLAMA_PRIORITY,
45 |     },
46 |     {
47 |         'patterns': patterns.OPENAI_PATTERNS,
48 |         'target': 'langextract.providers.openai:OpenAILanguageModel',
49 |         'priority': patterns.OPENAI_PRIORITY,
50 |     },
51 | ]
52 | 


--------------------------------------------------------------------------------
/langextract/providers/patterns.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Centralized pattern definitions for built-in providers.
16 | 
17 | This module defines all patterns and priorities for built-in providers
18 | in one place to avoid duplication.
19 | """
20 | 
21 | # Gemini provider patterns
22 | GEMINI_PATTERNS = (r'^gemini',)
23 | GEMINI_PRIORITY = 10
24 | 
25 | # OpenAI provider patterns
26 | OPENAI_PATTERNS = (
27 |     r'^gpt-4',
28 |     r'^gpt4\.',
29 |     r'^gpt-5',
30 |     r'^gpt5\.',
31 | )
32 | OPENAI_PRIORITY = 10
33 | 
34 | # Ollama provider patterns
35 | OLLAMA_PATTERNS = (
36 |     # Standard Ollama naming patterns
37 |     r'^gemma',  # gemma2:2b, gemma2:9b, etc.
38 |     r'^llama',  # llama3.2:1b, llama3.1:8b, etc.
39 |     r'^mistral',  # mistral:7b, mistral-nemo:12b, etc.
40 |     r'^mixtral',  # mixtral:8x7b, mixtral:8x22b, etc.
41 |     r'^phi',  # phi3:3.8b, phi3:14b, etc.
42 |     r'^qwen',  # qwen2.5:0.5b to 72b
43 |     r'^deepseek',  # deepseek-coder-v2, etc.
44 |     r'^command-r',  # command-r:35b, command-r-plus:104b
45 |     r'^starcoder',  # starcoder2:3b, starcoder2:7b, etc.
46 |     r'^codellama',  # codellama:7b, codellama:13b, etc.
47 |     r'^codegemma',  # codegemma:2b, codegemma:7b
48 |     r'^tinyllama',  # tinyllama:1.1b
49 |     r'^wizardcoder',  # wizardcoder:7b, wizardcoder:13b, etc.
50 |     r'^gpt-oss',  # Open source GPT variants
51 |     # HuggingFace model patterns
52 |     r'^meta-llama/[Ll]lama',
53 |     r'^google/gemma',
54 |     r'^mistralai/[Mm]istral',
55 |     r'^mistralai/[Mm]ixtral',
56 |     r'^microsoft/phi',
57 |     r'^Qwen/',
58 |     r'^deepseek-ai/',
59 |     r'^bigcode/starcoder',
60 |     r'^codellama/',
61 |     r'^TinyLlama/',
62 |     r'^WizardLM/',
63 | )
64 | OLLAMA_PRIORITY = 10
65 | 


--------------------------------------------------------------------------------
/langextract/providers/router.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Runtime registry that maps model-ID patterns to provider classes.
 16 | 
 17 | This module provides a lazy registration system for LLM providers, allowing
 18 | providers to be registered without importing their dependencies until needed.
 19 | """
 20 | # pylint: disable=duplicate-code
 21 | 
 22 | from __future__ import annotations
 23 | 
 24 | import dataclasses
 25 | import functools
 26 | import importlib
 27 | import re
 28 | import typing
 29 | 
 30 | from absl import logging
 31 | 
 32 | from langextract.core import base_model
 33 | from langextract.core import exceptions
 34 | 
 35 | 
 36 | @dataclasses.dataclass(frozen=True, slots=True)
 37 | class _Entry:
 38 |   """Registry entry for a provider."""
 39 | 
 40 |   patterns: tuple[re.Pattern[str], ...]
 41 |   loader: typing.Callable[[], type[base_model.BaseLanguageModel]]
 42 |   priority: int
 43 | 
 44 | 
 45 | _ENTRIES: list[_Entry] = []
 46 | _ENTRY_KEYS: set[tuple[str, tuple[str, ...], int]] = (
 47 |     set()
 48 | )  # (provider_id, patterns, priority)
 49 | 
 50 | 
 51 | def _add_entry(
 52 |     *,
 53 |     provider_id: str,
 54 |     patterns: tuple[re.Pattern[str], ...],
 55 |     loader: typing.Callable[[], type[base_model.BaseLanguageModel]],
 56 |     priority: int,
 57 | ) -> None:
 58 |   """Add an entry to the registry with deduplication."""
 59 |   key = (provider_id, tuple(p.pattern for p in patterns), priority)
 60 |   if key in _ENTRY_KEYS:
 61 |     logging.debug(
 62 |         "Skipping duplicate registration for %s with patterns %s at"
 63 |         " priority %d",
 64 |         provider_id,
 65 |         [p.pattern for p in patterns],
 66 |         priority,
 67 |     )
 68 |     return
 69 |   _ENTRY_KEYS.add(key)
 70 |   _ENTRIES.append(_Entry(patterns=patterns, loader=loader, priority=priority))
 71 |   logging.debug(
 72 |       "Registered provider %s with patterns %s at priority %d",
 73 |       provider_id,
 74 |       [p.pattern for p in patterns],
 75 |       priority,
 76 |   )
 77 | 
 78 | 
 79 | def register_lazy(
 80 |     *patterns: str | re.Pattern[str], target: str, priority: int = 0
 81 | ) -> None:
 82 |   """Register a provider lazily using string import path.
 83 | 
 84 |   Args:
 85 |     *patterns: One or more regex patterns to match model IDs.
 86 |     target: Import path in format "module.path:ClassName".
 87 |     priority: Priority for resolution (higher wins on conflicts).
 88 |   """
 89 |   compiled = tuple(re.compile(p) if isinstance(p, str) else p for p in patterns)
 90 | 
 91 |   def _loader() -> type[base_model.BaseLanguageModel]:
 92 |     module_path, class_name = target.rsplit(":", 1)
 93 |     module = importlib.import_module(module_path)
 94 |     return getattr(module, class_name)
 95 | 
 96 |   _add_entry(
 97 |       provider_id=target,
 98 |       patterns=compiled,
 99 |       loader=_loader,
100 |       priority=priority,
101 |   )
102 | 
103 | 
104 | def register(
105 |     *patterns: str | re.Pattern[str], priority: int = 0
106 | ) -> typing.Callable[
107 |     [type[base_model.BaseLanguageModel]], type[base_model.BaseLanguageModel]
108 | ]:
109 |   """Decorator to register a provider class directly.
110 | 
111 |   Args:
112 |     *patterns: One or more regex patterns to match model IDs.
113 |     priority: Priority for resolution (higher wins on conflicts).
114 | 
115 |   Returns:
116 |     Decorator function that registers the class.
117 |   """
118 |   compiled = tuple(re.compile(p) if isinstance(p, str) else p for p in patterns)
119 | 
120 |   def _decorator(
121 |       cls: type[base_model.BaseLanguageModel],
122 |   ) -> type[base_model.BaseLanguageModel]:
123 |     def _loader() -> type[base_model.BaseLanguageModel]:
124 |       return cls
125 | 
126 |     provider_id = f"{cls.__module__}:{cls.__name__}"
127 |     _add_entry(
128 |         provider_id=provider_id,
129 |         patterns=compiled,
130 |         loader=_loader,
131 |         priority=priority,
132 |     )
133 |     return cls
134 | 
135 |   return _decorator
136 | 
137 | 
138 | @functools.lru_cache(maxsize=128)
139 | def resolve(model_id: str) -> type[base_model.BaseLanguageModel]:
140 |   """Resolve a model ID to a provider class.
141 | 
142 |   Args:
143 |     model_id: The model identifier to resolve.
144 | 
145 |   Returns:
146 |     The provider class that handles this model ID.
147 | 
148 |   Raises:
149 |     ValueError: If no provider is registered for the model ID.
150 |   """
151 |   # Providers should be loaded by the caller (e.g., factory.create_model)
152 |   # Router doesn't load providers to avoid circular dependencies
153 | 
154 |   sorted_entries = sorted(_ENTRIES, key=lambda e: e.priority, reverse=True)
155 | 
156 |   for entry in sorted_entries:
157 |     if any(pattern.search(model_id) for pattern in entry.patterns):
158 |       return entry.loader()
159 | 
160 |   available_patterns = [str(p.pattern) for e in _ENTRIES for p in e.patterns]
161 |   raise exceptions.InferenceConfigError(
162 |       f"No provider registered for model_id={model_id!r}. "
163 |       f"Available patterns: {available_patterns}\n"
164 |       "Tip: You can explicitly specify a provider using 'config' parameter "
165 |       "with factory.ModelConfig and a provider class."
166 |   )
167 | 
168 | 
169 | @functools.lru_cache(maxsize=128)
170 | def resolve_provider(provider_name: str) -> type[base_model.BaseLanguageModel]:
171 |   """Resolve a provider name to a provider class.
172 | 
173 |   This allows explicit provider selection by name or class name.
174 | 
175 |   Args:
176 |     provider_name: The provider name (e.g., "gemini", "openai") or
177 |       class name (e.g., "GeminiLanguageModel").
178 | 
179 |   Returns:
180 |     The provider class.
181 | 
182 |   Raises:
183 |     ValueError: If no provider matches the name.
184 |   """
185 |   # Providers should be loaded by the caller (e.g., factory.create_model)
186 |   # Router doesn't load providers to avoid circular dependencies
187 | 
188 |   for entry in _ENTRIES:
189 |     for pattern in entry.patterns:
190 |       if pattern.pattern == f"^{re.escape(provider_name)}
quot;:
191 |         return entry.loader()
192 | 
193 |   for entry in _ENTRIES:
194 |     try:
195 |       provider_class = entry.loader()
196 |       class_name = provider_class.__name__
197 |       if provider_name.lower() in class_name.lower():
198 |         return provider_class
199 |     except (ImportError, AttributeError):
200 |       continue
201 | 
202 |   try:
203 |     pattern = re.compile(f"^{provider_name}
quot;, re.IGNORECASE)
204 |     for entry in _ENTRIES:
205 |       for entry_pattern in entry.patterns:
206 |         if pattern.pattern == entry_pattern.pattern:
207 |           return entry.loader()
208 |   except re.error:
209 |     pass
210 | 
211 |   raise exceptions.InferenceConfigError(
212 |       f"No provider found matching: {provider_name!r}. "
213 |       "Available providers can be listed with list_providers()"
214 |   )
215 | 
216 | 
217 | def clear() -> None:
218 |   """Clear all registered providers. Mainly for testing."""
219 |   global _ENTRIES  # pylint: disable=global-statement
220 |   _ENTRIES = []
221 |   _ENTRY_KEYS.clear()  # Also clear dedup keys to allow re-registration
222 |   resolve.cache_clear()
223 |   resolve_provider.cache_clear()
224 | 
225 | 
226 | def list_providers() -> list[tuple[tuple[str, ...], int]]:
227 |   """List all registered providers with their patterns and priorities.
228 | 
229 |   Returns:
230 |     List of (patterns, priority) tuples for debugging.
231 |   """
232 |   return [
233 |       (tuple(p.pattern for p in entry.patterns), entry.priority)
234 |       for entry in _ENTRIES
235 |   ]
236 | 
237 | 
238 | def list_entries() -> list[tuple[list[str], int]]:
239 |   """List all registered patterns and priorities. Mainly for debugging.
240 | 
241 |   Returns:
242 |     List of (patterns, priority) tuples.
243 |   """
244 |   return [([p.pattern for p in e.patterns], e.priority) for e in _ENTRIES]
245 | 


--------------------------------------------------------------------------------
/langextract/providers/schemas/__init__.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Provider-specific schema implementations."""
16 | from __future__ import annotations
17 | 
18 | from langextract.providers.schemas import gemini
19 | 
20 | GeminiSchema = gemini.GeminiSchema  # Backward compat
21 | 
22 | __all__ = ["GeminiSchema"]
23 | 


--------------------------------------------------------------------------------
/langextract/providers/schemas/gemini.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Gemini provider schema implementation."""
 16 | # pylint: disable=duplicate-code
 17 | 
 18 | from __future__ import annotations
 19 | 
 20 | from collections.abc import Sequence
 21 | import dataclasses
 22 | from typing import Any
 23 | 
 24 | from langextract.core import data
 25 | from langextract.core import schema
 26 | 
 27 | EXTRACTIONS_KEY = schema.EXTRACTIONS_KEY
 28 | 
 29 | 
 30 | @dataclasses.dataclass
 31 | class GeminiSchema(schema.BaseSchema):
 32 |   """Schema implementation for Gemini structured output.
 33 | 
 34 |   Converts ExampleData objects into an OpenAPI/JSON-schema definition
 35 |   that Gemini can interpret via 'response_schema'.
 36 |   """
 37 | 
 38 |   _schema_dict: dict
 39 | 
 40 |   @property
 41 |   def schema_dict(self) -> dict:
 42 |     """Returns the schema dictionary."""
 43 |     return self._schema_dict
 44 | 
 45 |   @schema_dict.setter
 46 |   def schema_dict(self, schema_dict: dict) -> None:
 47 |     """Sets the schema dictionary."""
 48 |     self._schema_dict = schema_dict
 49 | 
 50 |   def to_provider_config(self) -> dict[str, Any]:
 51 |     """Convert schema to Gemini-specific configuration.
 52 | 
 53 |     Returns:
 54 |       Dictionary with response_schema and response_mime_type for Gemini API.
 55 |     """
 56 |     return {
 57 |         "response_schema": self._schema_dict,
 58 |         "response_mime_type": "application/json",
 59 |     }
 60 | 
 61 |   @property
 62 |   def supports_strict_mode(self) -> bool:
 63 |     """Gemini enforces strict JSON schema constraints.
 64 | 
 65 |     Returns:
 66 |       True, as Gemini can enforce structure strictly via response_schema.
 67 |     """
 68 |     return True
 69 | 
 70 |   @classmethod
 71 |   def from_examples(
 72 |       cls,
 73 |       examples_data: Sequence[data.ExampleData],
 74 |       attribute_suffix: str = "_attributes",
 75 |   ) -> GeminiSchema:
 76 |     """Creates a GeminiSchema from example extractions.
 77 | 
 78 |     Builds a JSON-based schema with a top-level "extractions" array. Each
 79 |     element in that array is an object containing the extraction class name
 80 |     and an accompanying "<class>_attributes" object for its attributes.
 81 | 
 82 |     Args:
 83 |       examples_data: A sequence of ExampleData objects containing extraction
 84 |         classes and attributes.
 85 |       attribute_suffix: String appended to each class name to form the
 86 |         attributes field name (defaults to "_attributes").
 87 | 
 88 |     Returns:
 89 |       A GeminiSchema with internal dictionary represents the JSON constraint.
 90 |     """
 91 |     # Track attribute types for each category
 92 |     extraction_categories: dict[str, dict[str, set[type]]] = {}
 93 |     for example in examples_data:
 94 |       for extraction in example.extractions:
 95 |         category = extraction.extraction_class
 96 |         if category not in extraction_categories:
 97 |           extraction_categories[category] = {}
 98 | 
 99 |         if extraction.attributes:
100 |           for attr_name, attr_value in extraction.attributes.items():
101 |             if attr_name not in extraction_categories[category]:
102 |               extraction_categories[category][attr_name] = set()
103 |             extraction_categories[category][attr_name].add(type(attr_value))
104 | 
105 |     extraction_properties: dict[str, dict[str, Any]] = {}
106 | 
107 |     for category, attrs in extraction_categories.items():
108 |       extraction_properties[category] = {"type": "string"}
109 | 
110 |       attributes_field = f"{category}{attribute_suffix}"
111 |       attr_properties = {}
112 | 
113 |       # Default property for categories without attributes
114 |       if not attrs:
115 |         attr_properties["_unused"] = {"type": "string"}
116 |       else:
117 |         for attr_name, attr_types in attrs.items():
118 |           # List attributes become arrays
119 |           if list in attr_types:
120 |             attr_properties[attr_name] = {
121 |                 "type": "array",
122 |                 "items": {"type": "string"},
123 |             }
124 |           else:
125 |             attr_properties[attr_name] = {"type": "string"}
126 | 
127 |       extraction_properties[attributes_field] = {
128 |           "type": "object",
129 |           "properties": attr_properties,
130 |           "nullable": True,
131 |       }
132 | 
133 |     extraction_schema = {
134 |         "type": "object",
135 |         "properties": extraction_properties,
136 |     }
137 | 
138 |     schema_dict = {
139 |         "type": "object",
140 |         "properties": {
141 |             EXTRACTIONS_KEY: {"type": "array", "items": extraction_schema}
142 |         },
143 |         "required": [EXTRACTIONS_KEY],
144 |     }
145 | 
146 |     return cls(_schema_dict=schema_dict)
147 | 


--------------------------------------------------------------------------------
/langextract/py.typed:
--------------------------------------------------------------------------------
https://raw.githubusercontent.com/google/langextract/d14c7fd4460b7161a2ea3f10c8836743a0260505/langextract/py.typed


--------------------------------------------------------------------------------
/langextract/registry.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.registry imports.
16 | 
17 | This module redirects to langextract.plugins for backward compatibility.
18 | Will be removed in v2.0.0.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | import warnings
24 | 
25 | from langextract import plugins
26 | 
27 | 
28 | def __getattr__(name: str):
29 |   """Redirect to plugins module with deprecation warning."""
30 |   warnings.warn(
31 |       "`langextract.registry` is deprecated and will be removed in v2.0.0; "
32 |       "use `langextract.plugins` instead.",
33 |       FutureWarning,
34 |       stacklevel=2,
35 |   )
36 |   return getattr(plugins, name)
37 | 


--------------------------------------------------------------------------------
/langextract/schema.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Schema compatibility layer.
16 | 
17 | This module provides backward compatibility for the schema module.
18 | New code should import from langextract.core.schema instead.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | # Re-export core schema items with deprecation warnings
24 | import warnings
25 | 
26 | from langextract._compat import schema
27 | 
28 | 
29 | def __getattr__(name: str):
30 |   """Handle imports with appropriate warnings."""
31 |   core_items = {
32 |       "BaseSchema": ("langextract.core.schema", "BaseSchema"),
33 |       "Constraint": ("langextract.core.schema", "Constraint"),
34 |       "ConstraintType": ("langextract.core.schema", "ConstraintType"),
35 |       "EXTRACTIONS_KEY": ("langextract.core.schema", "EXTRACTIONS_KEY"),
36 |       "FormatModeSchema": ("langextract.core.schema", "FormatModeSchema"),
37 |   }
38 | 
39 |   if name in core_items:
40 |     mod, attr = core_items[name]
41 |     warnings.warn(
42 |         f"`langextract.schema.{name}` has moved to `{mod}.{attr}`. Please"
43 |         " update your imports. This compatibility layer will be removed in"
44 |         " v2.0.0.",
45 |         FutureWarning,
46 |         stacklevel=2,
47 |     )
48 |     module = __import__(mod, fromlist=[attr])
49 |     return getattr(module, attr)
50 |   elif name == "GeminiSchema":
51 |     return schema.__getattr__(name)
52 | 
53 |   raise AttributeError(f"module 'langextract.schema' has no attribute '{name}'")
54 | 


--------------------------------------------------------------------------------
/langextract/tokenizer.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Compatibility shim for langextract.tokenizer imports.
16 | 
17 | This module provides backward compatibility for code that imports from
18 | langextract.tokenizer. All functionality has moved to langextract.core.tokenizer.
19 | """
20 | 
21 | from __future__ import annotations
22 | 
23 | # Re-export everything from core.tokenizer for backward compatibility
24 | # pylint: disable=wildcard-import,unused-wildcard-import
25 | from langextract.core.tokenizer import *
26 | 


--------------------------------------------------------------------------------
/pyproject.toml:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | [build-system]
 16 | requires = ["setuptools>=67.0.0", "wheel"]
 17 | build-backend = "setuptools.build_meta"
 18 | 
 19 | 
 20 | [project]
 21 | name = "langextract"
 22 | version = "1.0.8"
 23 | description = "LangExtract: A library for extracting structured data from language models"
 24 | readme = "README.md"
 25 | requires-python = ">=3.10"
 26 | license = "Apache-2.0"
 27 | authors = [
 28 |     {name = "Akshay Goel", email = "goelak@google.com"}
 29 | ]
 30 | dependencies = [
 31 |     "absl-py>=1.0.0",
 32 |     "aiohttp>=3.8.0",
 33 |     "async_timeout>=4.0.0",
 34 |     "exceptiongroup>=1.1.0",
 35 |     "google-genai>=0.1.0",
 36 |     "ml-collections>=0.1.0",
 37 |     "more-itertools>=8.0.0",
 38 |     "numpy>=1.20.0",
 39 |     "pandas>=1.3.0",
 40 |     "pydantic>=1.8.0",
 41 |     "python-dotenv>=0.19.0",
 42 |     "PyYAML>=6.0",
 43 |     "requests>=2.25.0",
 44 |     "tqdm>=4.64.0",
 45 |     "typing-extensions>=4.0.0"
 46 | ]
 47 | 
 48 | [project.urls]
 49 | "Homepage" = "https://github.com/google/langextract"
 50 | "Repository" = "https://github.com/google/langextract"
 51 | "Documentation" = "https://github.com/google/langextract/blob/main/README.md"
 52 | "Bug Tracker" = "https://github.com/google/langextract/issues"
 53 | 
 54 | [project.optional-dependencies]
 55 | openai = ["openai>=1.50.0"]
 56 | all = ["openai>=1.50.0"]
 57 | dev = [
 58 |     "pyink~=24.3.0",
 59 |     "isort>=5.13.0",
 60 |     "pylint>=3.0.0",
 61 |     "pytype>=2024.10.11",
 62 |     "tox>=4.0.0",
 63 |     "import-linter>=2.0"
 64 | ]
 65 | test = [
 66 |     "pytest>=7.4.0",
 67 |     "tomli>=2.0.0"
 68 | ]
 69 | notebook = [
 70 |     "ipython>=7.0.0",
 71 |     "notebook>=6.0.0"
 72 | ]
 73 | 
 74 | [tool.setuptools]
 75 | packages = [
 76 |     "langextract",
 77 |     "langextract._compat",
 78 |     "langextract.core",
 79 |     "langextract.providers",
 80 |     "langextract.providers.schemas"
 81 | ]
 82 | include-package-data = true
 83 | 
 84 | [tool.setuptools.package-data]
 85 | langextract = ["py.typed"]
 86 | 
 87 | # Provider discovery mechanism for built-in and third-party providers
 88 | [project.entry-points."langextract.providers"]
 89 | gemini = "langextract.providers.gemini:GeminiLanguageModel"
 90 | ollama = "langextract.providers.ollama:OllamaLanguageModel"
 91 | openai = "langextract.providers.openai:OpenAILanguageModel"
 92 | 
 93 | [tool.setuptools.exclude-package-data]
 94 | "*" = [
 95 |     "docs*",
 96 |     "tests*",
 97 |     "kokoro*",
 98 |     "*.gif",
 99 |     "*.svg",
100 | ]
101 | 
102 | [tool.pytest.ini_options]
103 | testpaths = ["tests"]
104 | python_files = "*_test.py"
105 | python_classes = "Test*"
106 | python_functions = "test_*"
107 | # Show extra test summary info
108 | addopts = "-ra"
109 | markers = [
110 |     "live_api: marks tests as requiring live API access",
111 |     "requires_pip: marks tests that perform pip install/uninstall operations",
112 |     "integration: marks integration tests that test multiple components together",
113 | ]
114 | 
115 | [tool.pyink]
116 | # Configuration for Google's style guide
117 | line-length = 80
118 | unstable = true
119 | pyink-indentation = 2
120 | pyink-use-majority-quotes = true
121 | 
122 | [tool.isort]
123 | # Configuration for Google's style guide
124 | profile = "google"
125 | line_length = 80
126 | force_sort_within_sections = true
127 | # Allow multiple imports on one line for these modules
128 | single_line_exclusions = ["typing", "typing_extensions", "collections.abc"]
129 | 
130 | [tool.importlinter]
131 | root_package = "langextract"
132 | 
133 | 
134 | [[tool.importlinter.contracts]]
135 | name = "Providers must not import inference"
136 | type = "forbidden"
137 | source_modules = ["langextract.providers"]
138 | forbidden_modules = ["langextract.inference"]
139 | 
140 | [[tool.importlinter.contracts]]
141 | name = "Core must not import providers"
142 | type = "forbidden"
143 | source_modules = ["langextract.core"]
144 | forbidden_modules = ["langextract.providers"]
145 | 
146 | [[tool.importlinter.contracts]]
147 | name = "Core must not import high-level modules"
148 | type = "forbidden"
149 | source_modules = ["langextract.core"]
150 | forbidden_modules = [
151 |   "langextract.annotation",
152 |   "langextract.chunking",
153 |   "langextract.prompting",
154 |   "langextract.resolver",
155 | ]
156 | 


--------------------------------------------------------------------------------
/tests/.pylintrc:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | # Test-specific Pylint configuration
16 | # Inherits from parent ../.pylintrc and adds test-specific relaxations
17 | 
18 | [MASTER]
19 | # Python will merge with parent; no need to repeat plugins.
20 | 
21 | [MESSAGES CONTROL]
22 | # Additional disables for test code only
23 | disable=
24 |     # --- Test-specific relaxations ---
25 |     duplicate-code,           # Test fixtures often have similar patterns
26 |     too-many-lines,           # Large test files are common
27 |     missing-module-docstring, # Tests don't need module docs
28 |     missing-class-docstring,  # Test classes are self-explanatory
29 |     missing-function-docstring, # Test method names describe intent
30 |     line-too-long,            # Golden strings and test data
31 |     invalid-name,             # setUp, tearDown, maxDiff, etc.
32 |     protected-access,         # Tests often access private members
33 |     use-dict-literal,         # Parametrized tests benefit from dict()
34 |     bad-indentation,          # pyink 2-space style conflicts with pylint
35 |     unused-argument,          # Mock callbacks often have unused args
36 |     import-error,             # Test dependencies may not be installed
37 |     unused-import,            # Some imports are for test fixtures
38 |     too-many-positional-arguments  # Test methods can have many args
39 | 
40 | [DESIGN]
41 | # Relax complexity limits for tests
42 | max-args = 10                 # Fixtures often take many params
43 | max-locals = 25               # Complex test setups
44 | max-statements = 75           # Detailed test scenarios
45 | max-branches = 15             # Multiple test conditions
46 | 
47 | [BASIC]
48 | # Allow common test naming patterns
49 | good-names=i,j,k,ex,Run,_,id,ok,fd,fp,maxDiff,setUp,tearDown
50 | 
51 | # Include test-specific naming patterns
52 | method-rgx=[a-z_][a-z0-9_]{2,50}$|test[A-Z_][a-zA-Z0-9]*$|assert[A-Z][a-zA-Z0-9]*$
53 | 


--------------------------------------------------------------------------------
/tests/init_test.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Tests for the main package functions in __init__.py."""
 16 | 
 17 | import textwrap
 18 | from unittest import mock
 19 | 
 20 | from absl.testing import absltest
 21 | 
 22 | from langextract import inference
 23 | from langextract import prompting
 24 | from langextract import schema
 25 | import langextract as lx
 26 | from langextract.core import data
 27 | from langextract.providers.schemas import gemini as gemini_schemas
 28 | 
 29 | 
 30 | class InitTest(absltest.TestCase):
 31 |   """Test cases for the main package functions."""
 32 | 
 33 |   @mock.patch.object(
 34 |       gemini_schemas.GeminiSchema, "from_examples", autospec=True
 35 |   )
 36 |   @mock.patch("langextract.extraction.factory.create_model")
 37 |   def test_lang_extract_as_lx_extract(
 38 |       self, mock_create_model, mock_gemini_schema
 39 |   ):
 40 | 
 41 |     input_text = "Patient takes Aspirin 100mg every morning."
 42 | 
 43 |     mock_model = mock.MagicMock()
 44 |     mock_model.infer.return_value = [[
 45 |         inference.ScoredOutput(
 46 |             output=textwrap.dedent("""\
 47 |             ```json
 48 |             {
 49 |               "extractions": [
 50 |                 {
 51 |                   "entity": "Aspirin",
 52 |                   "entity_attributes": {
 53 |                     "class": "medication"
 54 |                   }
 55 |                 },
 56 |                 {
 57 |                   "entity": "100mg",
 58 |                   "entity_attributes": {
 59 |                     "frequency": "every morning",
 60 |                     "class": "dosage"
 61 |                   }
 62 |                 }
 63 |               ]
 64 |             }
 65 |             ```"""),
 66 |             score=0.9,
 67 |         )
 68 |     ]]
 69 | 
 70 |     mock_model.requires_fence_output = True
 71 |     mock_create_model.return_value = mock_model
 72 | 
 73 |     mock_gemini_schema.return_value = None
 74 | 
 75 |     expected_result = data.AnnotatedDocument(
 76 |         document_id=None,
 77 |         extractions=[
 78 |             data.Extraction(
 79 |                 extraction_class="entity",
 80 |                 extraction_text="Aspirin",
 81 |                 char_interval=data.CharInterval(start_pos=14, end_pos=21),
 82 |                 alignment_status=data.AlignmentStatus.MATCH_EXACT,
 83 |                 extraction_index=1,
 84 |                 group_index=0,
 85 |                 description=None,
 86 |                 attributes={"class": "medication"},
 87 |             ),
 88 |             data.Extraction(
 89 |                 extraction_class="entity",
 90 |                 extraction_text="100mg",
 91 |                 char_interval=data.CharInterval(start_pos=22, end_pos=27),
 92 |                 alignment_status=data.AlignmentStatus.MATCH_EXACT,
 93 |                 extraction_index=2,
 94 |                 group_index=1,
 95 |                 description=None,
 96 |                 attributes={"frequency": "every morning", "class": "dosage"},
 97 |             ),
 98 |         ],
 99 |         text="Patient takes Aspirin 100mg every morning.",
100 |     )
101 | 
102 |     mock_description = textwrap.dedent("""\
103 |         Extract medication and dosage information in order of occurrence.
104 |         """)
105 | 
106 |     mock_examples = [
107 |         lx.data.ExampleData(
108 |             text="Patient takes Tylenol 500mg daily.",
109 |             extractions=[
110 |                 lx.data.Extraction(
111 |                     extraction_class="entity",
112 |                     extraction_text="Tylenol",
113 |                     attributes={
114 |                         "type": "analgesic",
115 |                         "class": "medication",
116 |                     },
117 |                 ),
118 |             ],
119 |         )
120 |     ]
121 |     mock_prompt_template = prompting.PromptTemplateStructured(
122 |         description=mock_description, examples=mock_examples
123 |     )
124 | 
125 |     prompt_generator = prompting.QAPromptGenerator(
126 |         template=mock_prompt_template, format_type=lx.data.FormatType.JSON
127 |     )
128 | 
129 |     actual_result = lx.extract(
130 |         text_or_documents=input_text,
131 |         prompt_description=mock_description,
132 |         examples=mock_examples,
133 |         api_key="some_api_key",
134 |         fence_output=True,
135 |         use_schema_constraints=False,
136 |     )
137 | 
138 |     mock_gemini_schema.assert_not_called()
139 |     mock_create_model.assert_called_once()
140 |     mock_model.infer.assert_called_once_with(
141 |         batch_prompts=[prompt_generator.render(input_text)],
142 |         max_workers=10,  # Default value from extract()
143 |     )
144 | 
145 |     self.assertDataclassEqual(expected_result, actual_result)
146 | 
147 |   @mock.patch.object(
148 |       gemini_schemas.GeminiSchema, "from_examples", autospec=True
149 |   )
150 |   @mock.patch("langextract.extraction.factory.create_model")
151 |   def test_extract_custom_params_reach_inference(
152 |       self, mock_create_model, mock_gemini_schema
153 |   ):
154 |     """Sanity check that custom parameters reach the inference layer."""
155 |     input_text = "Test text"
156 | 
157 |     mock_model = mock.MagicMock()
158 |     mock_model.infer.return_value = [[
159 |         inference.ScoredOutput(
160 |             output='```json\n{"extractions": []}\n```',
161 |             score=0.9,
162 |         )
163 |     ]]
164 | 
165 |     mock_model.requires_fence_output = True
166 |     mock_create_model.return_value = mock_model
167 |     mock_gemini_schema.return_value = None
168 | 
169 |     mock_examples = [
170 |         lx.data.ExampleData(
171 |             text="Example",
172 |             extractions=[
173 |                 lx.data.Extraction(
174 |                     extraction_class="test",
175 |                     extraction_text="example",
176 |                 ),
177 |             ],
178 |         )
179 |     ]
180 | 
181 |     lx.extract(
182 |         text_or_documents=input_text,
183 |         prompt_description="Test extraction",
184 |         examples=mock_examples,
185 |         api_key="test_key",
186 |         max_workers=5,
187 |         fence_output=True,
188 |         use_schema_constraints=False,
189 |     )
190 | 
191 |     mock_model.infer.assert_called_once()
192 |     _, kwargs = mock_model.infer.call_args
193 |     self.assertEqual(kwargs.get("max_workers"), 5)
194 | 
195 | 
196 | if __name__ == "__main__":
197 |   absltest.main()
198 | 


--------------------------------------------------------------------------------
/tests/progress_test.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Tests for langextract.progress module."""
16 | 
17 | import unittest
18 | from unittest import mock
19 | 
20 | import tqdm
21 | 
22 | from langextract import progress
23 | 
24 | 
25 | class ProgressTest(unittest.TestCase):
26 | 
27 |   def test_download_progress_bar(self):
28 |     """Test download progress bar creation."""
29 |     pbar = progress.create_download_progress_bar(
30 |         1024, "https://example.com/file.txt"
31 |     )
32 | 
33 |     self.assertIsInstance(pbar, tqdm.tqdm)
34 |     self.assertEqual(pbar.total, 1024)
35 |     self.assertIn("Downloading", pbar.desc)
36 | 
37 |   def test_extraction_progress_bar(self):
38 |     """Test extraction progress bar creation."""
39 |     pbar = progress.create_extraction_progress_bar(
40 |         range(10), "gemini-2.0-flash"
41 |     )
42 | 
43 |     self.assertIsInstance(pbar, tqdm.tqdm)
44 |     self.assertIn("LangExtract", pbar.desc)
45 |     self.assertIn("gemini-2.0-flash", pbar.desc)
46 | 
47 |   def test_save_load_progress_bars(self):
48 |     """Test save and load progress bar creation."""
49 |     save_pbar = progress.create_save_progress_bar("/path/file.json")
50 |     load_pbar = progress.create_load_progress_bar("/path/file.json")
51 | 
52 |     self.assertIsInstance(save_pbar, tqdm.tqdm)
53 |     self.assertIsInstance(load_pbar, tqdm.tqdm)
54 |     self.assertIn("Saving", save_pbar.desc)
55 |     self.assertIn("Loading", load_pbar.desc)
56 | 
57 |   def test_model_info_extraction(self):
58 |     """Test extracting model info from objects."""
59 |     mock_model = mock.MagicMock()
60 |     mock_model.model_id = "gemini-1.5-pro"
61 |     self.assertEqual(progress.get_model_info(mock_model), "gemini-1.5-pro")
62 | 
63 |     mock_model = mock.MagicMock()
64 |     del mock_model.model_id
65 |     del mock_model.model_url
66 |     self.assertIsNone(progress.get_model_info(mock_model))
67 | 
68 |   def test_formatting_functions(self):
69 |     """Test message formatting functions."""
70 |     stats = progress.format_extraction_stats(1500, 5000)
71 |     self.assertIn("1,500", stats)
72 |     self.assertIn("5,000", stats)
73 | 
74 |     desc = progress.format_extraction_progress("gemini-2.0-flash")
75 |     self.assertIn("LangExtract", desc)
76 |     self.assertIn("gemini-2.0-flash", desc)
77 | 
78 |     desc_no_model = progress.format_extraction_progress(None)
79 |     self.assertIn("Processing", desc_no_model)
80 | 
81 | 
82 | if __name__ == "__main__":
83 |   unittest.main()
84 | 


--------------------------------------------------------------------------------
/tests/test_ollama_integration.py:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | """Integration tests for Ollama functionality."""
16 | import socket
17 | 
18 | import pytest
19 | import requests
20 | 
21 | import langextract as lx
22 | 
23 | 
24 | def _ollama_available():
25 |   """Check if Ollama is running on localhost:11434."""
26 |   with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
27 |     result = sock.connect_ex(("localhost", 11434))
28 |     return result == 0
29 | 
30 | 
31 | @pytest.mark.skipif(not _ollama_available(), reason="Ollama not running")
32 | def test_ollama_extraction():
33 |   """Test extraction using Ollama when available."""
34 |   input_text = "Isaac Asimov was a prolific science fiction writer."
35 |   prompt = "Extract the author's full name and their primary literary genre."
36 | 
37 |   examples = [
38 |       lx.data.ExampleData(
39 |           text=(
40 |               "J.R.R. Tolkien was an English writer, best known for"
41 |               " high-fantasy."
42 |           ),
43 |           extractions=[
44 |               lx.data.Extraction(
45 |                   extraction_class="author_details",
46 |                   extraction_text="J.R.R. Tolkien was an English writer...",
47 |                   attributes={
48 |                       "name": "J.R.R. Tolkien",
49 |                       "genre": "high-fantasy",
50 |                   },
51 |               )
52 |           ],
53 |       )
54 |   ]
55 | 
56 |   model_id = "gemma2:2b"
57 | 
58 |   try:
59 |     result = lx.extract(
60 |         text_or_documents=input_text,
61 |         prompt_description=prompt,
62 |         examples=examples,
63 |         model_id=model_id,
64 |         model_url="http://localhost:11434",
65 |         temperature=0.3,
66 |         fence_output=False,
67 |         use_schema_constraints=False,
68 |     )
69 | 
70 |     assert len(result.extractions) > 0
71 |     extraction = result.extractions[0]
72 |     assert extraction.extraction_class == "author_details"
73 |     if extraction.attributes:
74 |       assert "asimov" in extraction.attributes.get("name", "").lower()
75 | 
76 |   except ValueError as e:
77 |     if "Can't find Ollama" in str(e):
78 |       pytest.skip(f"Ollama model {model_id} not available")
79 |     raise
80 | 


--------------------------------------------------------------------------------
/tests/visualization_test.py:
--------------------------------------------------------------------------------
  1 | # Copyright 2025 Google LLC.
  2 | #
  3 | # Licensed under the Apache License, Version 2.0 (the "License");
  4 | # you may not use this file except in compliance with the License.
  5 | # You may obtain a copy of the License at
  6 | #
  7 | #     http://www.apache.org/licenses/LICENSE-2.0
  8 | #
  9 | # Unless required by applicable law or agreed to in writing, software
 10 | # distributed under the License is distributed on an "AS IS" BASIS,
 11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 12 | # See the License for the specific language governing permissions and
 13 | # limitations under the License.
 14 | 
 15 | """Tests for langextract.visualization."""
 16 | 
 17 | from unittest import mock
 18 | 
 19 | from absl.testing import absltest
 20 | 
 21 | from langextract import visualization
 22 | from langextract.core import data as lx_data
 23 | 
 24 | _PALETTE = visualization._PALETTE
 25 | _VISUALIZATION_CSS = visualization._VISUALIZATION_CSS
 26 | 
 27 | 
 28 | class VisualizationTest(absltest.TestCase):
 29 | 
 30 |   def test_assign_colors_basic_assignment(self):
 31 | 
 32 |     extractions = [
 33 |         lx_data.Extraction(
 34 |             extraction_class="CLASS_A",
 35 |             extraction_text="text_a",
 36 |             char_interval=lx_data.CharInterval(start_pos=0, end_pos=1),
 37 |         ),
 38 |         lx_data.Extraction(
 39 |             extraction_class="CLASS_B",
 40 |             extraction_text="text_b",
 41 |             char_interval=lx_data.CharInterval(start_pos=1, end_pos=2),
 42 |         ),
 43 |     ]
 44 |     # Classes are sorted alphabetically before color assignment.
 45 |     expected_color_map = {
 46 |         "CLASS_A": _PALETTE[0],
 47 |         "CLASS_B": _PALETTE[1],
 48 |     }
 49 | 
 50 |     actual_color_map = visualization._assign_colors(extractions)
 51 | 
 52 |     self.assertDictEqual(actual_color_map, expected_color_map)
 53 | 
 54 |   def test_build_highlighted_text_single_span_correct_html(self):
 55 | 
 56 |     text = "Hello world"
 57 |     extraction = lx_data.Extraction(
 58 |         extraction_class="GREETING",
 59 |         extraction_text="Hello",
 60 |         char_interval=lx_data.CharInterval(start_pos=0, end_pos=5),
 61 |     )
 62 |     extractions = [extraction]
 63 |     color_map = {"GREETING": "#ff0000"}
 64 |     expected_html = (
 65 |         '<span class="lx-highlight lx-current-highlight" data-idx="0" '
 66 |         'style="background-color:#ff0000;">Hello</span> world'
 67 |     )
 68 | 
 69 |     actual_html = visualization._build_highlighted_text(
 70 |         text, extractions, color_map
 71 |     )
 72 | 
 73 |     self.assertEqual(actual_html, expected_html)
 74 | 
 75 |   def test_build_highlighted_text_escapes_html_in_text_and_tooltip(self):
 76 | 
 77 |     text = "Text with <unsafe> content & ampersand."
 78 |     extraction = lx_data.Extraction(
 79 |         extraction_class="UNSAFE_CLASS",
 80 |         extraction_text="<unsafe> content & ampersand.",
 81 |         char_interval=lx_data.CharInterval(start_pos=10, end_pos=39),
 82 |         attributes={"detail": "Attribute with <tag> & 'quote'"},
 83 |     )
 84 |     # Highlighting "<unsafe> content & ampersand"
 85 |     extractions = [extraction]
 86 |     color_map = {"UNSAFE_CLASS": "#00ff00"}
 87 |     expected_highlighted_segment = "&lt;unsafe&gt; content &amp; ampersand."
 88 |     expected_html = (
 89 |         'Text with <span class="lx-highlight lx-current-highlight"'
 90 |         ' data-idx="0" '
 91 |         f'style="background-color:#00ff00;">{expected_highlighted_segment}</span>'
 92 |     )
 93 | 
 94 |     actual_html = visualization._build_highlighted_text(
 95 |         text, extractions, color_map
 96 |     )
 97 | 
 98 |     self.assertEqual(actual_html, expected_html)
 99 | 
100 |   @mock.patch.object(
101 |       visualization, "HTML", new=None
102 |   )  # Ensures visualize returns str
103 |   def test_visualize_basic_document_renders_correctly(self):
104 | 
105 |     doc = lx_data.AnnotatedDocument(
106 |         text="Patient needs Aspirin.",
107 |         extractions=[
108 |             lx_data.Extraction(
109 |                 extraction_class="MEDICATION",
110 |                 extraction_text="Aspirin",
111 |                 char_interval=lx_data.CharInterval(
112 |                     start_pos=14, end_pos=21
113 |                 ),  # "Aspirin"
114 |             )
115 |         ],
116 |     )
117 |     # Predictable color based on sorted class name "MEDICATION"
118 |     med_color = _PALETTE[0]
119 |     body_html = (
120 |         'Patient needs <span class="lx-highlight lx-current-highlight"'
121 |         f' data-idx="0" style="background-color:{med_color};">Aspirin</span>.'
122 |     )
123 |     legend_html = (
124 |         '<div class="lx-legend">Highlights Legend: <span class="lx-label" '
125 |         f'style="background-color:{med_color};">MEDICATION</span></div>'
126 |     )
127 |     css_html = _VISUALIZATION_CSS
128 |     expected_components = [
129 |         css_html,
130 |         "lx-animated-wrapper",
131 |         body_html,
132 |         legend_html,
133 |     ]
134 | 
135 |     actual_html = visualization.visualize(doc)
136 | 
137 |     # Verify expected components appear in output
138 |     for component in expected_components:
139 |       self.assertIn(component, actual_html)
140 | 
141 |   @mock.patch.object(
142 |       visualization, "HTML", new=None
143 |   )  # Ensures visualize returns str
144 |   def test_visualize_no_extractions_renders_text_and_empty_legend(self):
145 | 
146 |     doc = lx_data.AnnotatedDocument(text="No entities here.", extractions=[])
147 |     body_html = (
148 |         '<div class="lx-animated-wrapper"><p>No valid extractions to'
149 |         " animate.</p></div>"
150 |     )
151 |     css_html = _VISUALIZATION_CSS
152 |     expected_html = css_html + body_html
153 | 
154 |     actual_html = visualization.visualize(doc)
155 | 
156 |     self.assertEqual(actual_html, expected_html)
157 | 
158 | 
159 | if __name__ == "__main__":
160 |   absltest.main()
161 | 


--------------------------------------------------------------------------------
/tox.ini:
--------------------------------------------------------------------------------
 1 | # Copyright 2025 Google LLC.
 2 | #
 3 | # Licensed under the Apache License, Version 2.0 (the "License");
 4 | # you may not use this file except in compliance with the License.
 5 | # You may obtain a copy of the License at
 6 | #
 7 | #     http://www.apache.org/licenses/LICENSE-2.0
 8 | #
 9 | # Unless required by applicable law or agreed to in writing, software
10 | # distributed under the License is distributed on an "AS IS" BASIS,
11 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
12 | # See the License for the specific language governing permissions and
13 | # limitations under the License.
14 | 
15 | [tox]
16 | envlist = py310, py311, py312, format, lint-src, lint-tests
17 | skip_missing_interpreters = True
18 | 
19 | [testenv]
20 | setenv =
21 |     PYTHONWARNINGS = ignore
22 | deps =
23 |     .[openai,dev,test]
24 | commands =
25 |     pytest -ra -m "not live_api and not requires_pip"
26 | 
27 | [testenv:format]
28 | skip_install = true
29 | deps =
30 |     isort>=5.13.2
31 |     pyink~=24.3.0
32 | commands =
33 |     isort langextract tests --check-only --diff
34 |     pyink langextract tests --check --diff --config pyproject.toml
35 | 
36 | [testenv:lint-src]
37 | deps =
38 |     pylint>=3.0.0
39 | commands =
40 |     pylint --rcfile=.pylintrc langextract
41 | 
42 | [testenv:lint-tests]
43 | deps =
44 |     pylint>=3.0.0
45 | commands =
46 |     pylint --rcfile=tests/.pylintrc tests
47 | 
48 | [testenv:live-api]
49 | basepython = python3.11
50 | passenv =
51 |     GEMINI_API_KEY
52 |     LANGEXTRACT_API_KEY
53 |     OPENAI_API_KEY
54 | deps = .[all,dev,test]
55 | commands =
56 |     pytest tests/test_live_api.py -v -m live_api --maxfail=1
57 | 
58 | [testenv:ollama-integration]
59 | basepython = python3.11
60 | deps =
61 |     .[openai,dev,test]
62 |     requests>=2.25.0
63 | commands =
64 |     pytest tests/test_ollama_integration.py -v --tb=short
65 | 
66 | [testenv:plugin-integration]
67 | basepython = python3.11
68 | setenv =
69 |     PIP_NO_INPUT = 1
70 |     PIP_DISABLE_PIP_VERSION_CHECK = 1
71 | deps =
72 |     .[dev,test]
73 | commands =
74 |     pytest tests/provider_plugin_test.py::PluginE2ETest -v -m "requires_pip"
75 | 
76 | [testenv:plugin-smoke]
77 | basepython = python3.11
78 | deps =
79 |     .[dev,test]
80 | commands =
81 |     pytest tests/provider_plugin_test.py::PluginSmokeTest -v
82 | 


--------------------------------------------------------------------------------